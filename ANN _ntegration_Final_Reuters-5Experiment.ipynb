{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acq\n",
      "crude\n",
      "earn\n",
      "grain\n",
      "interest\n",
      "money-fx\n",
      "ship\n",
      "trade\n",
      "7691\n",
      "7691\n",
      "7691\n",
      "vectorize\n",
      "fit transform\n",
      "[0, 1, 2, 3, 4, 5, 6, 7]\n",
      "###############\n",
      "###############\n",
      "prob 0\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 5383, 30)          549270    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 5383, 30)          0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 5383, 8)           248       \n",
      "=================================================================\n",
      "Total params: 549,518\n",
      "Trainable params: 549,518\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 5383, 18308) for input Tensor(\"dense_input:0\", shape=(None, 5383, 18308), dtype=float32), but it was called on an input with incompatible shape (None, 18308).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 5383, 18308) for input Tensor(\"dense_input:0\", shape=(None, 5383, 18308), dtype=float32), but it was called on an input with incompatible shape (None, 18308).\n",
      "166/169 [============================>.] - ETA: 0s - loss: 1.6403 - accuracy: 0.6254WARNING:tensorflow:Model was constructed with shape (None, 5383, 18308) for input Tensor(\"dense_input:0\", shape=(None, 5383, 18308), dtype=float32), but it was called on an input with incompatible shape (None, 18308).\n",
      "169/169 [==============================] - 2s 11ms/step - loss: 1.6336 - accuracy: 0.6259 - val_loss: 1.2149 - val_accuracy: 0.5893\n",
      "Epoch 2/100\n",
      "169/169 [==============================] - 1s 8ms/step - loss: 1.1635 - accuracy: 0.6675 - val_loss: 1.0594 - val_accuracy: 0.7795\n",
      "Epoch 3/100\n",
      "169/169 [==============================] - 1s 8ms/step - loss: 1.0666 - accuracy: 0.7184 - val_loss: 0.9911 - val_accuracy: 0.7881\n",
      "Epoch 4/100\n",
      "169/169 [==============================] - 2s 9ms/step - loss: 1.0155 - accuracy: 0.7433 - val_loss: 0.9500 - val_accuracy: 0.8033\n",
      "Epoch 5/100\n",
      "169/169 [==============================] - 1s 8ms/step - loss: 0.9736 - accuracy: 0.7648 - val_loss: 0.9085 - val_accuracy: 0.8159\n",
      "Epoch 6/100\n",
      "169/169 [==============================] - 2s 11ms/step - loss: 0.9497 - accuracy: 0.7739 - val_loss: 0.8779 - val_accuracy: 0.8263\n",
      "Epoch 7/100\n",
      "169/169 [==============================] - 3s 19ms/step - loss: 0.9181 - accuracy: 0.7880 - val_loss: 0.8500 - val_accuracy: 0.8336\n",
      "Epoch 8/100\n",
      "169/169 [==============================] - 2s 10ms/step - loss: 0.8986 - accuracy: 0.7975 - val_loss: 0.8279 - val_accuracy: 0.8453\n",
      "Epoch 9/100\n",
      "169/169 [==============================] - 2s 10ms/step - loss: 0.8695 - accuracy: 0.8126 - val_loss: 0.8029 - val_accuracy: 0.8549\n",
      "Epoch 10/100\n",
      "169/169 [==============================] - 2s 13ms/step - loss: 0.8407 - accuracy: 0.8157 - val_loss: 0.7809 - val_accuracy: 0.8692\n",
      "Epoch 11/100\n",
      "169/169 [==============================] - 1s 8ms/step - loss: 0.8268 - accuracy: 0.8241 - val_loss: 0.7580 - val_accuracy: 0.8731\n",
      "Epoch 12/100\n",
      "169/169 [==============================] - 1s 8ms/step - loss: 0.8070 - accuracy: 0.8250 - val_loss: 0.7455 - val_accuracy: 0.8882\n",
      "Epoch 13/100\n",
      "169/169 [==============================] - 2s 10ms/step - loss: 0.7958 - accuracy: 0.8317 - val_loss: 0.7282 - val_accuracy: 0.8951\n",
      "Epoch 14/100\n",
      "169/169 [==============================] - 2s 10ms/step - loss: 0.7737 - accuracy: 0.8395 - val_loss: 0.7146 - val_accuracy: 0.8977\n",
      "Epoch 15/100\n",
      "169/169 [==============================] - 2s 11ms/step - loss: 0.7596 - accuracy: 0.8438 - val_loss: 0.6931 - val_accuracy: 0.8964\n",
      "Epoch 16/100\n",
      "169/169 [==============================] - 2s 11ms/step - loss: 0.7466 - accuracy: 0.8460 - val_loss: 0.6814 - val_accuracy: 0.9029\n",
      "Epoch 17/100\n",
      "169/169 [==============================] - 2s 12ms/step - loss: 0.7365 - accuracy: 0.8475 - val_loss: 0.6682 - val_accuracy: 0.9073\n",
      "Epoch 18/100\n",
      "169/169 [==============================] - 2s 13ms/step - loss: 0.7136 - accuracy: 0.8571 - val_loss: 0.6608 - val_accuracy: 0.9064\n",
      "Epoch 19/100\n",
      "169/169 [==============================] - 2s 11ms/step - loss: 0.7104 - accuracy: 0.8588 - val_loss: 0.6427 - val_accuracy: 0.9181\n",
      "Epoch 20/100\n",
      "169/169 [==============================] - 3s 18ms/step - loss: 0.6927 - accuracy: 0.8662 - val_loss: 0.6357 - val_accuracy: 0.9164\n",
      "Epoch 21/100\n",
      "169/169 [==============================] - 2s 11ms/step - loss: 0.6817 - accuracy: 0.8705 - val_loss: 0.6212 - val_accuracy: 0.9177\n",
      "Epoch 22/100\n",
      "169/169 [==============================] - 2s 10ms/step - loss: 0.6738 - accuracy: 0.8713 - val_loss: 0.6051 - val_accuracy: 0.9181\n",
      "Epoch 23/100\n",
      "169/169 [==============================] - 2s 10ms/step - loss: 0.6619 - accuracy: 0.8776 - val_loss: 0.5993 - val_accuracy: 0.9194\n",
      "Epoch 24/100\n",
      "169/169 [==============================] - 2s 10ms/step - loss: 0.6543 - accuracy: 0.8824 - val_loss: 0.5906 - val_accuracy: 0.9268\n",
      "Epoch 25/100\n",
      "169/169 [==============================] - 2s 10ms/step - loss: 0.6472 - accuracy: 0.8848 - val_loss: 0.5856 - val_accuracy: 0.9311\n",
      "Epoch 26/100\n",
      "169/169 [==============================] - 2s 11ms/step - loss: 0.6328 - accuracy: 0.8872 - val_loss: 0.5702 - val_accuracy: 0.9268\n",
      "Epoch 27/100\n",
      "169/169 [==============================] - 3s 16ms/step - loss: 0.6273 - accuracy: 0.8917 - val_loss: 0.5651 - val_accuracy: 0.9242\n",
      "Epoch 28/100\n",
      "169/169 [==============================] - 2s 10ms/step - loss: 0.6153 - accuracy: 0.8911 - val_loss: 0.5590 - val_accuracy: 0.9328\n",
      "Epoch 29/100\n",
      "169/169 [==============================] - 2s 10ms/step - loss: 0.6059 - accuracy: 0.8989 - val_loss: 0.5483 - val_accuracy: 0.9359\n",
      "Epoch 30/100\n",
      "169/169 [==============================] - 3s 15ms/step - loss: 0.5984 - accuracy: 0.8975 - val_loss: 0.5432 - val_accuracy: 0.9359\n",
      "Epoch 31/100\n",
      "169/169 [==============================] - 2s 14ms/step - loss: 0.5927 - accuracy: 0.9001 - val_loss: 0.5379 - val_accuracy: 0.9350\n",
      "Epoch 32/100\n",
      "169/169 [==============================] - 2s 12ms/step - loss: 0.5887 - accuracy: 0.8965 - val_loss: 0.5285 - val_accuracy: 0.9385\n",
      "Epoch 33/100\n",
      "169/169 [==============================] - 2s 9ms/step - loss: 0.5819 - accuracy: 0.9030 - val_loss: 0.5197 - val_accuracy: 0.9298\n",
      "Epoch 34/100\n",
      "169/169 [==============================] - 2s 10ms/step - loss: 0.5758 - accuracy: 0.9054 - val_loss: 0.5141 - val_accuracy: 0.9372\n",
      "Epoch 35/100\n",
      "169/169 [==============================] - 2s 12ms/step - loss: 0.5620 - accuracy: 0.9060 - val_loss: 0.5134 - val_accuracy: 0.9372\n",
      "Epoch 36/100\n",
      "169/169 [==============================] - 2s 11ms/step - loss: 0.5651 - accuracy: 0.9045 - val_loss: 0.5070 - val_accuracy: 0.9389\n",
      "Epoch 37/100\n",
      "169/169 [==============================] - 2s 10ms/step - loss: 0.5537 - accuracy: 0.9086 - val_loss: 0.4975 - val_accuracy: 0.9402\n",
      "Epoch 38/100\n",
      "169/169 [==============================] - 2s 10ms/step - loss: 0.5395 - accuracy: 0.9147 - val_loss: 0.4913 - val_accuracy: 0.9393\n",
      "Epoch 39/100\n",
      "169/169 [==============================] - 2s 11ms/step - loss: 0.5409 - accuracy: 0.9103 - val_loss: 0.4904 - val_accuracy: 0.9398\n",
      "Epoch 40/100\n",
      "169/169 [==============================] - 2s 12ms/step - loss: 0.5406 - accuracy: 0.9101 - val_loss: 0.4870 - val_accuracy: 0.9424\n",
      "Epoch 41/100\n",
      "169/169 [==============================] - 2s 9ms/step - loss: 0.5211 - accuracy: 0.9183 - val_loss: 0.4790 - val_accuracy: 0.9380\n",
      "Epoch 42/100\n",
      "169/169 [==============================] - 2s 11ms/step - loss: 0.5234 - accuracy: 0.9140 - val_loss: 0.4744 - val_accuracy: 0.9415\n",
      "Epoch 43/100\n",
      "169/169 [==============================] - 2s 10ms/step - loss: 0.5213 - accuracy: 0.9147 - val_loss: 0.4710 - val_accuracy: 0.9411\n",
      "Epoch 44/100\n",
      "169/169 [==============================] - 2s 9ms/step - loss: 0.5103 - accuracy: 0.9190 - val_loss: 0.4615 - val_accuracy: 0.9424\n",
      "Epoch 45/100\n",
      "169/169 [==============================] - 3s 18ms/step - loss: 0.5110 - accuracy: 0.9162 - val_loss: 0.4669 - val_accuracy: 0.9445\n",
      "Epoch 46/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "169/169 [==============================] - 2s 10ms/step - loss: 0.5090 - accuracy: 0.9149 - val_loss: 0.4630 - val_accuracy: 0.9441\n",
      "Epoch 47/100\n",
      "169/169 [==============================] - 2s 10ms/step - loss: 0.5005 - accuracy: 0.9192 - val_loss: 0.4514 - val_accuracy: 0.9419\n",
      "Epoch 48/100\n",
      "169/169 [==============================] - 2s 9ms/step - loss: 0.4979 - accuracy: 0.9238 - val_loss: 0.4521 - val_accuracy: 0.9393\n",
      "Epoch 49/100\n",
      "169/169 [==============================] - 2s 10ms/step - loss: 0.4931 - accuracy: 0.9214 - val_loss: 0.4418 - val_accuracy: 0.9432\n",
      "Epoch 50/100\n",
      "169/169 [==============================] - 2s 10ms/step - loss: 0.4821 - accuracy: 0.9240 - val_loss: 0.4432 - val_accuracy: 0.9393\n",
      "Epoch 51/100\n",
      "169/169 [==============================] - 3s 17ms/step - loss: 0.4831 - accuracy: 0.9236 - val_loss: 0.4369 - val_accuracy: 0.9419\n",
      "Epoch 52/100\n",
      "169/169 [==============================] - 2s 13ms/step - loss: 0.4728 - accuracy: 0.9251 - val_loss: 0.4312 - val_accuracy: 0.9480\n",
      "Epoch 53/100\n",
      "169/169 [==============================] - 3s 17ms/step - loss: 0.4729 - accuracy: 0.9270 - val_loss: 0.4315 - val_accuracy: 0.9484\n",
      "Epoch 54/100\n",
      "169/169 [==============================] - 2s 10ms/step - loss: 0.4730 - accuracy: 0.9287 - val_loss: 0.4275 - val_accuracy: 0.9458\n",
      "Epoch 55/100\n",
      "169/169 [==============================] - 3s 18ms/step - loss: 0.4680 - accuracy: 0.9262 - val_loss: 0.4271 - val_accuracy: 0.9458\n",
      "Epoch 56/100\n",
      "169/169 [==============================] - 2s 10ms/step - loss: 0.4648 - accuracy: 0.9264 - val_loss: 0.4271 - val_accuracy: 0.9471\n",
      "Epoch 57/100\n",
      "169/169 [==============================] - 1s 7ms/step - loss: 0.4599 - accuracy: 0.9283 - val_loss: 0.4184 - val_accuracy: 0.9458\n",
      "Epoch 58/100\n",
      "169/169 [==============================] - 1s 7ms/step - loss: 0.4509 - accuracy: 0.9272 - val_loss: 0.4128 - val_accuracy: 0.9489\n",
      "Epoch 59/100\n",
      "169/169 [==============================] - 1s 9ms/step - loss: 0.4532 - accuracy: 0.9318 - val_loss: 0.4153 - val_accuracy: 0.9506\n",
      "Epoch 60/100\n",
      "169/169 [==============================] - 1s 7ms/step - loss: 0.4564 - accuracy: 0.9305 - val_loss: 0.4133 - val_accuracy: 0.9541\n",
      "Epoch 61/100\n",
      "169/169 [==============================] - 1s 7ms/step - loss: 0.4527 - accuracy: 0.9290 - val_loss: 0.4051 - val_accuracy: 0.9545\n",
      "Epoch 62/100\n",
      "169/169 [==============================] - 1s 6ms/step - loss: 0.4522 - accuracy: 0.9320 - val_loss: 0.4118 - val_accuracy: 0.9554\n",
      "Epoch 63/100\n",
      "169/169 [==============================] - 1s 6ms/step - loss: 0.4403 - accuracy: 0.9335 - val_loss: 0.4000 - val_accuracy: 0.9558\n",
      "Epoch 64/100\n",
      "169/169 [==============================] - 1s 8ms/step - loss: 0.4399 - accuracy: 0.9294 - val_loss: 0.4030 - val_accuracy: 0.9536\n",
      "Epoch 65/100\n",
      "169/169 [==============================] - 1s 8ms/step - loss: 0.4304 - accuracy: 0.9363 - val_loss: 0.4010 - val_accuracy: 0.9515\n",
      "Epoch 66/100\n",
      "169/169 [==============================] - 2s 10ms/step - loss: 0.4289 - accuracy: 0.9378 - val_loss: 0.3923 - val_accuracy: 0.9575\n",
      "Epoch 67/100\n",
      "169/169 [==============================] - 2s 10ms/step - loss: 0.4279 - accuracy: 0.9359 - val_loss: 0.3969 - val_accuracy: 0.9558\n",
      "Epoch 68/100\n",
      "169/169 [==============================] - 2s 9ms/step - loss: 0.4262 - accuracy: 0.9389 - val_loss: 0.3916 - val_accuracy: 0.9584\n",
      "Epoch 69/100\n",
      "169/169 [==============================] - 1s 8ms/step - loss: 0.4257 - accuracy: 0.9372 - val_loss: 0.3943 - val_accuracy: 0.9519\n",
      "Epoch 70/100\n",
      "169/169 [==============================] - 2s 11ms/step - loss: 0.4147 - accuracy: 0.9404 - val_loss: 0.3933 - val_accuracy: 0.9493\n",
      "Epoch 71/100\n",
      "169/169 [==============================] - 2s 9ms/step - loss: 0.4210 - accuracy: 0.9393 - val_loss: 0.3937 - val_accuracy: 0.9545\n",
      "Epoch 72/100\n",
      "169/169 [==============================] - 2s 9ms/step - loss: 0.4224 - accuracy: 0.9426 - val_loss: 0.3852 - val_accuracy: 0.9562\n",
      "Epoch 73/100\n",
      "169/169 [==============================] - 2s 10ms/step - loss: 0.4207 - accuracy: 0.9413 - val_loss: 0.3882 - val_accuracy: 0.9528\n",
      "Epoch 74/100\n",
      "169/169 [==============================] - 3s 18ms/step - loss: 0.4146 - accuracy: 0.9433 - val_loss: 0.3830 - val_accuracy: 0.9506\n",
      "Epoch 75/100\n",
      "169/169 [==============================] - 2s 11ms/step - loss: 0.4085 - accuracy: 0.9411 - val_loss: 0.3853 - val_accuracy: 0.9580\n",
      "Epoch 76/100\n",
      "169/169 [==============================] - 2s 10ms/step - loss: 0.4112 - accuracy: 0.9402 - val_loss: 0.3773 - val_accuracy: 0.9580\n",
      "Epoch 77/100\n",
      "169/169 [==============================] - 2s 10ms/step - loss: 0.4077 - accuracy: 0.9430 - val_loss: 0.3783 - val_accuracy: 0.9580\n",
      "Epoch 78/100\n",
      "169/169 [==============================] - 2s 10ms/step - loss: 0.3997 - accuracy: 0.9435 - val_loss: 0.3679 - val_accuracy: 0.9623\n",
      "Epoch 79/100\n",
      "169/169 [==============================] - 2s 11ms/step - loss: 0.4027 - accuracy: 0.9424 - val_loss: 0.3727 - val_accuracy: 0.9597\n",
      "Epoch 80/100\n",
      "169/169 [==============================] - 3s 17ms/step - loss: 0.3966 - accuracy: 0.9471 - val_loss: 0.3679 - val_accuracy: 0.9575\n",
      "Epoch 81/100\n",
      "169/169 [==============================] - 3s 18ms/step - loss: 0.3931 - accuracy: 0.9489 - val_loss: 0.3666 - val_accuracy: 0.9571\n",
      "Epoch 82/100\n",
      "169/169 [==============================] - 2s 10ms/step - loss: 0.3949 - accuracy: 0.9471 - val_loss: 0.3643 - val_accuracy: 0.9580\n",
      "Epoch 83/100\n",
      "169/169 [==============================] - 2s 11ms/step - loss: 0.4077 - accuracy: 0.9428 - val_loss: 0.3716 - val_accuracy: 0.9545\n",
      "Epoch 84/100\n",
      "169/169 [==============================] - 2s 10ms/step - loss: 0.3921 - accuracy: 0.9474 - val_loss: 0.3670 - val_accuracy: 0.9567\n",
      "Epoch 85/100\n",
      "169/169 [==============================] - 2s 10ms/step - loss: 0.3881 - accuracy: 0.9508 - val_loss: 0.3591 - val_accuracy: 0.9549\n",
      "Epoch 86/100\n",
      "169/169 [==============================] - 2s 10ms/step - loss: 0.3836 - accuracy: 0.9515 - val_loss: 0.3552 - val_accuracy: 0.9593\n",
      "Epoch 87/100\n",
      "169/169 [==============================] - 2s 10ms/step - loss: 0.3802 - accuracy: 0.9511 - val_loss: 0.3574 - val_accuracy: 0.9597\n",
      "Epoch 88/100\n",
      "169/169 [==============================] - 2s 10ms/step - loss: 0.3839 - accuracy: 0.9521 - val_loss: 0.3611 - val_accuracy: 0.9584\n",
      "Epoch 89/100\n",
      "169/169 [==============================] - 2s 11ms/step - loss: 0.3843 - accuracy: 0.9467 - val_loss: 0.3564 - val_accuracy: 0.9593\n",
      "Epoch 90/100\n",
      "169/169 [==============================] - 2s 11ms/step - loss: 0.3852 - accuracy: 0.9480 - val_loss: 0.3611 - val_accuracy: 0.9601\n",
      "Epoch 91/100\n",
      "169/169 [==============================] - 2s 12ms/step - loss: 0.3805 - accuracy: 0.9484 - val_loss: 0.3534 - val_accuracy: 0.9584\n",
      "Epoch 92/100\n",
      "169/169 [==============================] - 3s 15ms/step - loss: 0.3793 - accuracy: 0.9508 - val_loss: 0.3571 - val_accuracy: 0.9571\n",
      "Epoch 93/100\n",
      "169/169 [==============================] - 2s 12ms/step - loss: 0.3780 - accuracy: 0.9519 - val_loss: 0.3531 - val_accuracy: 0.9593\n",
      "Epoch 94/100\n",
      "169/169 [==============================] - 2s 13ms/step - loss: 0.3714 - accuracy: 0.9523 - val_loss: 0.3449 - val_accuracy: 0.9580\n",
      "Epoch 95/100\n",
      "169/169 [==============================] - 3s 17ms/step - loss: 0.3586 - accuracy: 0.9543 - val_loss: 0.3461 - val_accuracy: 0.9597\n",
      "Epoch 96/100\n",
      "169/169 [==============================] - 2s 11ms/step - loss: 0.3721 - accuracy: 0.9498 - val_loss: 0.3494 - val_accuracy: 0.9593\n",
      "Epoch 97/100\n",
      "169/169 [==============================] - 3s 16ms/step - loss: 0.3670 - accuracy: 0.9562 - val_loss: 0.3473 - val_accuracy: 0.9567\n",
      "Epoch 98/100\n",
      "169/169 [==============================] - 2s 12ms/step - loss: 0.3717 - accuracy: 0.9541 - val_loss: 0.3480 - val_accuracy: 0.9597\n",
      "Epoch 99/100\n",
      "169/169 [==============================] - 2s 11ms/step - loss: 0.3651 - accuracy: 0.9556 - val_loss: 0.3445 - val_accuracy: 0.9627\n",
      "Epoch 100/100\n",
      "169/169 [==============================] - 2s 11ms/step - loss: 0.3705 - accuracy: 0.9547 - val_loss: 0.3508 - val_accuracy: 0.9567\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 5383, 30)          549270    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 5383, 30)          0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 5383, 8)           248       \n",
      "=================================================================\n",
      "Total params: 549,518\n",
      "Trainable params: 549,518\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73/73 [==============================] - 0s 5ms/step - loss: 0.3508 - accuracy: 0.9567\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 5383, 18308) for input Tensor(\"dense_input:0\", shape=(None, 5383, 18308), dtype=float32), but it was called on an input with incompatible shape (None, 18308).\n",
      "prob 0\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_2 (Dense)              (None, 5383, 30)          549270    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 5383, 30)          0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 5383, 8)           248       \n",
      "=================================================================\n",
      "Total params: 549,518\n",
      "Trainable params: 549,518\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 5383, 18308) for input Tensor(\"dense_2_input:0\", shape=(None, 5383, 18308), dtype=float32), but it was called on an input with incompatible shape (None, 18308).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 5383, 18308) for input Tensor(\"dense_2_input:0\", shape=(None, 5383, 18308), dtype=float32), but it was called on an input with incompatible shape (None, 18308).\n",
      "167/169 [============================>.] - ETA: 0s - loss: 1.6625 - accuracy: 0.6572WARNING:tensorflow:Model was constructed with shape (None, 5383, 18308) for input Tensor(\"dense_2_input:0\", shape=(None, 5383, 18308), dtype=float32), but it was called on an input with incompatible shape (None, 18308).\n",
      "169/169 [==============================] - 1s 8ms/step - loss: 1.6588 - accuracy: 0.6573 - val_loss: 1.2251 - val_accuracy: 0.6763\n",
      "Epoch 2/100\n",
      "169/169 [==============================] - 1s 9ms/step - loss: 1.1672 - accuracy: 0.6864 - val_loss: 1.0574 - val_accuracy: 0.7829\n",
      "Epoch 3/100\n",
      "169/169 [==============================] - 2s 10ms/step - loss: 1.0821 - accuracy: 0.7247 - val_loss: 0.9968 - val_accuracy: 0.7868\n",
      "Epoch 4/100\n",
      "169/169 [==============================] - 1s 7ms/step - loss: 1.0257 - accuracy: 0.7358 - val_loss: 0.9555 - val_accuracy: 0.7873\n",
      "Epoch 5/100\n",
      "169/169 [==============================] - 1s 8ms/step - loss: 0.9922 - accuracy: 0.7446 - val_loss: 0.9232 - val_accuracy: 0.7894\n",
      "Epoch 6/100\n",
      "169/169 [==============================] - 2s 12ms/step - loss: 0.9693 - accuracy: 0.7561 - val_loss: 0.8944 - val_accuracy: 0.7938\n",
      "Epoch 7/100\n",
      "169/169 [==============================] - 2s 10ms/step - loss: 0.9416 - accuracy: 0.7624 - val_loss: 0.8691 - val_accuracy: 0.8046\n",
      "Epoch 8/100\n",
      "169/169 [==============================] - 2s 9ms/step - loss: 0.9144 - accuracy: 0.7776 - val_loss: 0.8452 - val_accuracy: 0.8072\n",
      "Epoch 9/100\n",
      "169/169 [==============================] - 1s 7ms/step - loss: 0.8950 - accuracy: 0.7793 - val_loss: 0.8270 - val_accuracy: 0.8228\n",
      "Epoch 10/100\n",
      "169/169 [==============================] - 1s 8ms/step - loss: 0.8699 - accuracy: 0.7871 - val_loss: 0.8014 - val_accuracy: 0.8289\n",
      "Epoch 11/100\n",
      "169/169 [==============================] - 1s 8ms/step - loss: 0.8556 - accuracy: 0.7879 - val_loss: 0.7863 - val_accuracy: 0.8440\n",
      "Epoch 12/100\n",
      "169/169 [==============================] - 2s 13ms/step - loss: 0.8358 - accuracy: 0.8003 - val_loss: 0.7668 - val_accuracy: 0.8440\n",
      "Epoch 13/100\n",
      "169/169 [==============================] - 2s 12ms/step - loss: 0.8237 - accuracy: 0.8005 - val_loss: 0.7505 - val_accuracy: 0.8609\n",
      "Epoch 14/100\n",
      "169/169 [==============================] - 2s 11ms/step - loss: 0.8031 - accuracy: 0.8111 - val_loss: 0.7372 - val_accuracy: 0.8709\n",
      "Epoch 15/100\n",
      "169/169 [==============================] - 1s 9ms/step - loss: 0.7864 - accuracy: 0.8233 - val_loss: 0.7188 - val_accuracy: 0.8644\n",
      "Epoch 16/100\n",
      "169/169 [==============================] - 2s 9ms/step - loss: 0.7710 - accuracy: 0.8230 - val_loss: 0.7078 - val_accuracy: 0.8843\n",
      "Epoch 17/100\n",
      "169/169 [==============================] - 2s 9ms/step - loss: 0.7565 - accuracy: 0.8285 - val_loss: 0.6920 - val_accuracy: 0.8843\n",
      "Epoch 18/100\n",
      "169/169 [==============================] - 2s 9ms/step - loss: 0.7502 - accuracy: 0.8311 - val_loss: 0.6802 - val_accuracy: 0.8908\n",
      "Epoch 19/100\n",
      "169/169 [==============================] - 2s 9ms/step - loss: 0.7336 - accuracy: 0.8373 - val_loss: 0.6663 - val_accuracy: 0.8895\n",
      "Epoch 20/100\n",
      "169/169 [==============================] - 1s 8ms/step - loss: 0.7222 - accuracy: 0.8445 - val_loss: 0.6574 - val_accuracy: 0.8986\n",
      "Epoch 21/100\n",
      "169/169 [==============================] - 1s 8ms/step - loss: 0.7147 - accuracy: 0.8477 - val_loss: 0.6459 - val_accuracy: 0.8925\n",
      "Epoch 22/100\n",
      "169/169 [==============================] - 2s 10ms/step - loss: 0.7021 - accuracy: 0.8536 - val_loss: 0.6319 - val_accuracy: 0.9090\n",
      "Epoch 23/100\n",
      "169/169 [==============================] - 1s 9ms/step - loss: 0.6908 - accuracy: 0.8597 - val_loss: 0.6225 - val_accuracy: 0.9038\n",
      "Epoch 24/100\n",
      "169/169 [==============================] - 1s 7ms/step - loss: 0.6798 - accuracy: 0.8616 - val_loss: 0.6094 - val_accuracy: 0.9090\n",
      "Epoch 25/100\n",
      "169/169 [==============================] - 1s 7ms/step - loss: 0.6631 - accuracy: 0.8692 - val_loss: 0.6019 - val_accuracy: 0.9120\n",
      "Epoch 26/100\n",
      "169/169 [==============================] - 1s 6ms/step - loss: 0.6606 - accuracy: 0.8714 - val_loss: 0.5947 - val_accuracy: 0.9129\n",
      "Epoch 27/100\n",
      "169/169 [==============================] - 1s 6ms/step - loss: 0.6492 - accuracy: 0.8748 - val_loss: 0.5868 - val_accuracy: 0.9142\n",
      "Epoch 28/100\n",
      "169/169 [==============================] - 1s 7ms/step - loss: 0.6438 - accuracy: 0.8755 - val_loss: 0.5763 - val_accuracy: 0.9190\n",
      "Epoch 29/100\n",
      "169/169 [==============================] - 2s 9ms/step - loss: 0.6364 - accuracy: 0.8781 - val_loss: 0.5677 - val_accuracy: 0.9185\n",
      "Epoch 30/100\n",
      "169/169 [==============================] - 1s 8ms/step - loss: 0.6277 - accuracy: 0.8822 - val_loss: 0.5623 - val_accuracy: 0.9272\n",
      "Epoch 31/100\n",
      "169/169 [==============================] - 1s 7ms/step - loss: 0.6171 - accuracy: 0.8856 - val_loss: 0.5523 - val_accuracy: 0.9185\n",
      "Epoch 32/100\n",
      "169/169 [==============================] - 1s 7ms/step - loss: 0.6143 - accuracy: 0.8872 - val_loss: 0.5443 - val_accuracy: 0.9242\n",
      "Epoch 33/100\n",
      "169/169 [==============================] - 2s 9ms/step - loss: 0.5994 - accuracy: 0.8919 - val_loss: 0.5364 - val_accuracy: 0.9242\n",
      "Epoch 34/100\n",
      "169/169 [==============================] - 2s 10ms/step - loss: 0.5975 - accuracy: 0.8943 - val_loss: 0.5325 - val_accuracy: 0.9237\n",
      "Epoch 35/100\n",
      "169/169 [==============================] - 2s 12ms/step - loss: 0.5918 - accuracy: 0.8911 - val_loss: 0.5299 - val_accuracy: 0.9250\n",
      "Epoch 36/100\n",
      "169/169 [==============================] - 2s 10ms/step - loss: 0.5801 - accuracy: 0.8945 - val_loss: 0.5259 - val_accuracy: 0.9294\n",
      "Epoch 37/100\n",
      "169/169 [==============================] - 2s 9ms/step - loss: 0.5831 - accuracy: 0.8976 - val_loss: 0.5176 - val_accuracy: 0.9263\n",
      "Epoch 38/100\n",
      "169/169 [==============================] - 2s 9ms/step - loss: 0.5680 - accuracy: 0.8989 - val_loss: 0.5164 - val_accuracy: 0.9250\n",
      "Epoch 39/100\n",
      "169/169 [==============================] - 2s 9ms/step - loss: 0.5631 - accuracy: 0.8999 - val_loss: 0.5049 - val_accuracy: 0.9307\n",
      "Epoch 40/100\n",
      "169/169 [==============================] - 2s 11ms/step - loss: 0.5621 - accuracy: 0.8999 - val_loss: 0.4969 - val_accuracy: 0.9285\n",
      "Epoch 41/100\n",
      "169/169 [==============================] - 2s 14ms/step - loss: 0.5471 - accuracy: 0.9071 - val_loss: 0.4984 - val_accuracy: 0.9276\n",
      "Epoch 42/100\n",
      "169/169 [==============================] - 2s 13ms/step - loss: 0.5426 - accuracy: 0.9064 - val_loss: 0.4933 - val_accuracy: 0.9289\n",
      "Epoch 43/100\n",
      "169/169 [==============================] - 2s 13ms/step - loss: 0.5397 - accuracy: 0.9051 - val_loss: 0.4919 - val_accuracy: 0.9307\n",
      "Epoch 44/100\n",
      "169/169 [==============================] - 2s 12ms/step - loss: 0.5345 - accuracy: 0.9086 - val_loss: 0.4756 - val_accuracy: 0.9346\n",
      "Epoch 45/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "169/169 [==============================] - 2s 10ms/step - loss: 0.5223 - accuracy: 0.9131 - val_loss: 0.4680 - val_accuracy: 0.9354\n",
      "Epoch 46/100\n",
      "169/169 [==============================] - 2s 14ms/step - loss: 0.5175 - accuracy: 0.9132 - val_loss: 0.4728 - val_accuracy: 0.9328\n",
      "Epoch 47/100\n",
      "169/169 [==============================] - 2s 10ms/step - loss: 0.5227 - accuracy: 0.9112 - val_loss: 0.4654 - val_accuracy: 0.9333\n",
      "Epoch 48/100\n",
      "169/169 [==============================] - 2s 13ms/step - loss: 0.5120 - accuracy: 0.9125 - val_loss: 0.4654 - val_accuracy: 0.9337\n",
      "Epoch 49/100\n",
      "169/169 [==============================] - 2s 14ms/step - loss: 0.5050 - accuracy: 0.9171 - val_loss: 0.4625 - val_accuracy: 0.9372\n",
      "Epoch 50/100\n",
      "169/169 [==============================] - 2s 11ms/step - loss: 0.5046 - accuracy: 0.9181 - val_loss: 0.4523 - val_accuracy: 0.9393\n",
      "Epoch 51/100\n",
      "169/169 [==============================] - 2s 13ms/step - loss: 0.5010 - accuracy: 0.9173 - val_loss: 0.4511 - val_accuracy: 0.9363\n",
      "Epoch 52/100\n",
      "169/169 [==============================] - 2s 13ms/step - loss: 0.5002 - accuracy: 0.9138 - val_loss: 0.4492 - val_accuracy: 0.9411\n",
      "Epoch 53/100\n",
      "169/169 [==============================] - 1s 8ms/step - loss: 0.4939 - accuracy: 0.9209 - val_loss: 0.4439 - val_accuracy: 0.9432\n",
      "Epoch 54/100\n",
      "169/169 [==============================] - 1s 9ms/step - loss: 0.4880 - accuracy: 0.9246 - val_loss: 0.4368 - val_accuracy: 0.9411\n",
      "Epoch 55/100\n",
      "169/169 [==============================] - 1s 8ms/step - loss: 0.4883 - accuracy: 0.9203 - val_loss: 0.4355 - val_accuracy: 0.9428\n",
      "Epoch 56/100\n",
      "169/169 [==============================] - 1s 7ms/step - loss: 0.4812 - accuracy: 0.9233 - val_loss: 0.4353 - val_accuracy: 0.9385\n",
      "Epoch 57/100\n",
      "169/169 [==============================] - 1s 9ms/step - loss: 0.4767 - accuracy: 0.9272 - val_loss: 0.4305 - val_accuracy: 0.9458\n",
      "Epoch 58/100\n",
      "169/169 [==============================] - 2s 9ms/step - loss: 0.4710 - accuracy: 0.9277 - val_loss: 0.4261 - val_accuracy: 0.9428\n",
      "Epoch 59/100\n",
      "169/169 [==============================] - 2s 9ms/step - loss: 0.4698 - accuracy: 0.9268 - val_loss: 0.4198 - val_accuracy: 0.9432\n",
      "Epoch 60/100\n",
      "169/169 [==============================] - 2s 9ms/step - loss: 0.4667 - accuracy: 0.9290 - val_loss: 0.4170 - val_accuracy: 0.9454\n",
      "Epoch 61/100\n",
      "169/169 [==============================] - 1s 8ms/step - loss: 0.4642 - accuracy: 0.9311 - val_loss: 0.4229 - val_accuracy: 0.9432\n",
      "Epoch 62/100\n",
      "169/169 [==============================] - 1s 8ms/step - loss: 0.4537 - accuracy: 0.9318 - val_loss: 0.4118 - val_accuracy: 0.9437\n",
      "Epoch 63/100\n",
      "169/169 [==============================] - 2s 11ms/step - loss: 0.4575 - accuracy: 0.9290 - val_loss: 0.4167 - val_accuracy: 0.9432\n",
      "Epoch 64/100\n",
      "169/169 [==============================] - 2s 11ms/step - loss: 0.4549 - accuracy: 0.9277 - val_loss: 0.4161 - val_accuracy: 0.9437\n",
      "Epoch 65/100\n",
      "169/169 [==============================] - 1s 8ms/step - loss: 0.4488 - accuracy: 0.9331 - val_loss: 0.4106 - val_accuracy: 0.9467\n",
      "Epoch 66/100\n",
      "169/169 [==============================] - 1s 7ms/step - loss: 0.4469 - accuracy: 0.9383 - val_loss: 0.4032 - val_accuracy: 0.9493\n",
      "Epoch 67/100\n",
      "169/169 [==============================] - 1s 7ms/step - loss: 0.4460 - accuracy: 0.9331 - val_loss: 0.4057 - val_accuracy: 0.9467\n",
      "Epoch 68/100\n",
      "169/169 [==============================] - 1s 8ms/step - loss: 0.4483 - accuracy: 0.9303 - val_loss: 0.3992 - val_accuracy: 0.9489\n",
      "Epoch 69/100\n",
      "169/169 [==============================] - 1s 8ms/step - loss: 0.4496 - accuracy: 0.9324 - val_loss: 0.4014 - val_accuracy: 0.9493\n",
      "Epoch 70/100\n",
      "169/169 [==============================] - 1s 7ms/step - loss: 0.4404 - accuracy: 0.9350 - val_loss: 0.4029 - val_accuracy: 0.9476\n",
      "Epoch 71/100\n",
      "169/169 [==============================] - 1s 7ms/step - loss: 0.4393 - accuracy: 0.9326 - val_loss: 0.4003 - val_accuracy: 0.9506\n",
      "Epoch 72/100\n",
      "169/169 [==============================] - 1s 7ms/step - loss: 0.4350 - accuracy: 0.9368 - val_loss: 0.3952 - val_accuracy: 0.9458\n",
      "Epoch 73/100\n",
      "169/169 [==============================] - 1s 7ms/step - loss: 0.4254 - accuracy: 0.9402 - val_loss: 0.3939 - val_accuracy: 0.9441\n",
      "Epoch 74/100\n",
      "169/169 [==============================] - 1s 8ms/step - loss: 0.4294 - accuracy: 0.9352 - val_loss: 0.3928 - val_accuracy: 0.9493\n",
      "Epoch 75/100\n",
      "169/169 [==============================] - 2s 9ms/step - loss: 0.4244 - accuracy: 0.9402 - val_loss: 0.3864 - val_accuracy: 0.9480\n",
      "Epoch 76/100\n",
      "169/169 [==============================] - 1s 7ms/step - loss: 0.4211 - accuracy: 0.9407 - val_loss: 0.3891 - val_accuracy: 0.9454\n",
      "Epoch 77/100\n",
      "169/169 [==============================] - 1s 7ms/step - loss: 0.4163 - accuracy: 0.9446 - val_loss: 0.3838 - val_accuracy: 0.9532\n",
      "Epoch 78/100\n",
      "169/169 [==============================] - 1s 6ms/step - loss: 0.4160 - accuracy: 0.9400 - val_loss: 0.3843 - val_accuracy: 0.9510\n",
      "Epoch 79/100\n",
      "169/169 [==============================] - 1s 8ms/step - loss: 0.4233 - accuracy: 0.9385 - val_loss: 0.3814 - val_accuracy: 0.9519\n",
      "Epoch 80/100\n",
      "169/169 [==============================] - 1s 8ms/step - loss: 0.4123 - accuracy: 0.9435 - val_loss: 0.3743 - val_accuracy: 0.9506\n",
      "Epoch 81/100\n",
      "169/169 [==============================] - 1s 9ms/step - loss: 0.4135 - accuracy: 0.9396 - val_loss: 0.3739 - val_accuracy: 0.9519\n",
      "Epoch 82/100\n",
      "169/169 [==============================] - 2s 11ms/step - loss: 0.4108 - accuracy: 0.9404 - val_loss: 0.3818 - val_accuracy: 0.9467\n",
      "Epoch 83/100\n",
      "169/169 [==============================] - 3s 16ms/step - loss: 0.4085 - accuracy: 0.9391 - val_loss: 0.3734 - val_accuracy: 0.9484\n",
      "Epoch 84/100\n",
      "169/169 [==============================] - 2s 10ms/step - loss: 0.4020 - accuracy: 0.9465 - val_loss: 0.3783 - val_accuracy: 0.9480\n",
      "Epoch 85/100\n",
      "169/169 [==============================] - 2s 9ms/step - loss: 0.3952 - accuracy: 0.9476 - val_loss: 0.3672 - val_accuracy: 0.9489\n",
      "Epoch 86/100\n",
      "169/169 [==============================] - 2s 11ms/step - loss: 0.3986 - accuracy: 0.9441 - val_loss: 0.3826 - val_accuracy: 0.9441\n",
      "Epoch 87/100\n",
      "169/169 [==============================] - 2s 9ms/step - loss: 0.4005 - accuracy: 0.9467 - val_loss: 0.3701 - val_accuracy: 0.9528\n",
      "Epoch 88/100\n",
      "169/169 [==============================] - 2s 11ms/step - loss: 0.3890 - accuracy: 0.9508 - val_loss: 0.3608 - val_accuracy: 0.9523\n",
      "Epoch 89/100\n",
      "169/169 [==============================] - 2s 12ms/step - loss: 0.3953 - accuracy: 0.9474 - val_loss: 0.3657 - val_accuracy: 0.9515\n",
      "Epoch 90/100\n",
      "169/169 [==============================] - 2s 11ms/step - loss: 0.3887 - accuracy: 0.9448 - val_loss: 0.3639 - val_accuracy: 0.9523\n",
      "Epoch 91/100\n",
      "169/169 [==============================] - 2s 9ms/step - loss: 0.3909 - accuracy: 0.9463 - val_loss: 0.3619 - val_accuracy: 0.9515\n",
      "Epoch 92/100\n",
      "169/169 [==============================] - 2s 9ms/step - loss: 0.3934 - accuracy: 0.9465 - val_loss: 0.3646 - val_accuracy: 0.9480\n",
      "Epoch 93/100\n",
      "169/169 [==============================] - 2s 11ms/step - loss: 0.3856 - accuracy: 0.9524 - val_loss: 0.3629 - val_accuracy: 0.9515\n",
      "Epoch 94/100\n",
      "169/169 [==============================] - 2s 10ms/step - loss: 0.3875 - accuracy: 0.9471 - val_loss: 0.3683 - val_accuracy: 0.9510\n",
      "Epoch 95/100\n",
      "169/169 [==============================] - 2s 10ms/step - loss: 0.3874 - accuracy: 0.9476 - val_loss: 0.3590 - val_accuracy: 0.9510\n",
      "Epoch 96/100\n",
      "169/169 [==============================] - 2s 9ms/step - loss: 0.3841 - accuracy: 0.9487 - val_loss: 0.3602 - val_accuracy: 0.9510\n",
      "Epoch 97/100\n",
      "169/169 [==============================] - 1s 8ms/step - loss: 0.3715 - accuracy: 0.9534 - val_loss: 0.3601 - val_accuracy: 0.9515\n",
      "Epoch 98/100\n",
      "169/169 [==============================] - 2s 10ms/step - loss: 0.3833 - accuracy: 0.9498 - val_loss: 0.3543 - val_accuracy: 0.9497\n",
      "Epoch 99/100\n",
      "169/169 [==============================] - 2s 10ms/step - loss: 0.3743 - accuracy: 0.9493 - val_loss: 0.3575 - val_accuracy: 0.9528\n",
      "Epoch 100/100\n",
      "169/169 [==============================] - 2s 9ms/step - loss: 0.3832 - accuracy: 0.9459 - val_loss: 0.3617 - val_accuracy: 0.9519\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_2 (Dense)              (None, 5383, 30)          549270    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 5383, 30)          0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 5383, 8)           248       \n",
      "=================================================================\n",
      "Total params: 549,518\n",
      "Trainable params: 549,518\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73/73 [==============================] - 0s 3ms/step - loss: 0.3617 - accuracy: 0.9519\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 5383, 18308) for input Tensor(\"dense_2_input:0\", shape=(None, 5383, 18308), dtype=float32), but it was called on an input with incompatible shape (None, 18308).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hassa\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prob 0\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 5383, 30)          549270    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 5383, 30)          0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 5383, 8)           248       \n",
      "=================================================================\n",
      "Total params: 549,518\n",
      "Trainable params: 549,518\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 5383, 18308) for input Tensor(\"dense_4_input:0\", shape=(None, 5383, 18308), dtype=float32), but it was called on an input with incompatible shape (None, 18308).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 5383, 18308) for input Tensor(\"dense_4_input:0\", shape=(None, 5383, 18308), dtype=float32), but it was called on an input with incompatible shape (None, 18308).\n",
      "165/169 [============================>.] - ETA: 0s - loss: 1.6467 - accuracy: 0.5680WARNING:tensorflow:Model was constructed with shape (None, 5383, 18308) for input Tensor(\"dense_4_input:0\", shape=(None, 5383, 18308), dtype=float32), but it was called on an input with incompatible shape (None, 18308).\n",
      "169/169 [==============================] - 2s 10ms/step - loss: 1.6404 - accuracy: 0.5688 - val_loss: 1.2160 - val_accuracy: 0.6508\n",
      "Epoch 2/100\n",
      "169/169 [==============================] - 2s 9ms/step - loss: 1.1543 - accuracy: 0.6979 - val_loss: 1.0375 - val_accuracy: 0.7829\n",
      "Epoch 3/100\n",
      "169/169 [==============================] - 1s 8ms/step - loss: 1.0613 - accuracy: 0.7306 - val_loss: 0.9743 - val_accuracy: 0.7881\n",
      "Epoch 4/100\n",
      "169/169 [==============================] - 2s 9ms/step - loss: 1.0145 - accuracy: 0.7481 - val_loss: 0.9292 - val_accuracy: 0.7860\n",
      "Epoch 5/100\n",
      "169/169 [==============================] - 1s 8ms/step - loss: 0.9721 - accuracy: 0.7591 - val_loss: 0.8967 - val_accuracy: 0.8007\n",
      "Epoch 6/100\n",
      "169/169 [==============================] - 2s 9ms/step - loss: 0.9429 - accuracy: 0.7708 - val_loss: 0.8688 - val_accuracy: 0.8107\n",
      "Epoch 7/100\n",
      "169/169 [==============================] - 2s 10ms/step - loss: 0.9100 - accuracy: 0.7782 - val_loss: 0.8348 - val_accuracy: 0.8198\n",
      "Epoch 8/100\n",
      "169/169 [==============================] - 1s 7ms/step - loss: 0.8822 - accuracy: 0.7944 - val_loss: 0.8106 - val_accuracy: 0.8250\n",
      "Epoch 9/100\n",
      "169/169 [==============================] - 1s 7ms/step - loss: 0.8644 - accuracy: 0.7994 - val_loss: 0.7897 - val_accuracy: 0.8345\n",
      "Epoch 10/100\n",
      "169/169 [==============================] - 1s 9ms/step - loss: 0.8473 - accuracy: 0.8007 - val_loss: 0.7666 - val_accuracy: 0.8406\n",
      "Epoch 11/100\n",
      "169/169 [==============================] - 1s 8ms/step - loss: 0.8192 - accuracy: 0.8168 - val_loss: 0.7482 - val_accuracy: 0.8592\n",
      "Epoch 12/100\n",
      "169/169 [==============================] - 1s 8ms/step - loss: 0.8067 - accuracy: 0.8181 - val_loss: 0.7325 - val_accuracy: 0.8648\n",
      "Epoch 13/100\n",
      "169/169 [==============================] - 2s 10ms/step - loss: 0.7855 - accuracy: 0.8270 - val_loss: 0.7166 - val_accuracy: 0.8791\n",
      "Epoch 14/100\n",
      "169/169 [==============================] - 2s 11ms/step - loss: 0.7773 - accuracy: 0.8315 - val_loss: 0.7057 - val_accuracy: 0.8839\n",
      "Epoch 15/100\n",
      "169/169 [==============================] - 2s 9ms/step - loss: 0.7654 - accuracy: 0.8283 - val_loss: 0.6894 - val_accuracy: 0.8951\n",
      "Epoch 16/100\n",
      "169/169 [==============================] - 1s 9ms/step - loss: 0.7473 - accuracy: 0.8434 - val_loss: 0.6731 - val_accuracy: 0.8930\n",
      "Epoch 17/100\n",
      "169/169 [==============================] - 2s 9ms/step - loss: 0.7353 - accuracy: 0.8443 - val_loss: 0.6606 - val_accuracy: 0.8878\n",
      "Epoch 18/100\n",
      "169/169 [==============================] - 2s 11ms/step - loss: 0.7264 - accuracy: 0.8460 - val_loss: 0.6526 - val_accuracy: 0.8999\n",
      "Epoch 19/100\n",
      "169/169 [==============================] - 2s 9ms/step - loss: 0.7094 - accuracy: 0.8549 - val_loss: 0.6394 - val_accuracy: 0.9029\n",
      "Epoch 20/100\n",
      "169/169 [==============================] - 2s 10ms/step - loss: 0.6971 - accuracy: 0.8584 - val_loss: 0.6287 - val_accuracy: 0.9012\n",
      "Epoch 21/100\n",
      "169/169 [==============================] - 2s 14ms/step - loss: 0.6843 - accuracy: 0.8618 - val_loss: 0.6230 - val_accuracy: 0.9068\n",
      "Epoch 22/100\n",
      "169/169 [==============================] - 2s 11ms/step - loss: 0.6728 - accuracy: 0.8666 - val_loss: 0.6032 - val_accuracy: 0.9086\n",
      "Epoch 23/100\n",
      "169/169 [==============================] - 1s 9ms/step - loss: 0.6660 - accuracy: 0.8657 - val_loss: 0.5971 - val_accuracy: 0.9116\n",
      "Epoch 24/100\n",
      "169/169 [==============================] - 1s 9ms/step - loss: 0.6505 - accuracy: 0.8737 - val_loss: 0.5866 - val_accuracy: 0.9177\n",
      "Epoch 25/100\n",
      "169/169 [==============================] - 2s 9ms/step - loss: 0.6506 - accuracy: 0.8778 - val_loss: 0.5826 - val_accuracy: 0.9168\n",
      "Epoch 26/100\n",
      "169/169 [==============================] - 1s 7ms/step - loss: 0.6351 - accuracy: 0.8798 - val_loss: 0.5717 - val_accuracy: 0.9112\n",
      "Epoch 27/100\n",
      "169/169 [==============================] - 1s 6ms/step - loss: 0.6316 - accuracy: 0.8770 - val_loss: 0.5674 - val_accuracy: 0.9216\n",
      "Epoch 28/100\n",
      "169/169 [==============================] - 1s 7ms/step - loss: 0.6165 - accuracy: 0.8859 - val_loss: 0.5556 - val_accuracy: 0.9211\n",
      "Epoch 29/100\n",
      "169/169 [==============================] - 1s 9ms/step - loss: 0.6154 - accuracy: 0.8856 - val_loss: 0.5486 - val_accuracy: 0.9246\n",
      "Epoch 30/100\n",
      "169/169 [==============================] - 1s 9ms/step - loss: 0.6015 - accuracy: 0.8904 - val_loss: 0.5389 - val_accuracy: 0.9237\n",
      "Epoch 31/100\n",
      "169/169 [==============================] - 1s 9ms/step - loss: 0.5997 - accuracy: 0.8900 - val_loss: 0.5390 - val_accuracy: 0.9216\n",
      "Epoch 32/100\n",
      "169/169 [==============================] - 2s 9ms/step - loss: 0.5942 - accuracy: 0.8910 - val_loss: 0.5330 - val_accuracy: 0.9203\n",
      "Epoch 33/100\n",
      "169/169 [==============================] - 2s 10ms/step - loss: 0.5844 - accuracy: 0.8945 - val_loss: 0.5224 - val_accuracy: 0.9268\n",
      "Epoch 34/100\n",
      "169/169 [==============================] - 1s 8ms/step - loss: 0.5779 - accuracy: 0.9008 - val_loss: 0.5211 - val_accuracy: 0.9198\n",
      "Epoch 35/100\n",
      "169/169 [==============================] - 1s 9ms/step - loss: 0.5738 - accuracy: 0.8993 - val_loss: 0.5139 - val_accuracy: 0.9276\n",
      "Epoch 36/100\n",
      "169/169 [==============================] - 1s 7ms/step - loss: 0.5604 - accuracy: 0.9043 - val_loss: 0.5060 - val_accuracy: 0.9315\n",
      "Epoch 37/100\n",
      "169/169 [==============================] - 1s 9ms/step - loss: 0.5573 - accuracy: 0.9032 - val_loss: 0.5000 - val_accuracy: 0.9272\n",
      "Epoch 38/100\n",
      "169/169 [==============================] - 1s 8ms/step - loss: 0.5557 - accuracy: 0.8988 - val_loss: 0.4936 - val_accuracy: 0.9285\n",
      "Epoch 39/100\n",
      "169/169 [==============================] - 2s 10ms/step - loss: 0.5441 - accuracy: 0.9064 - val_loss: 0.4913 - val_accuracy: 0.9328\n",
      "Epoch 40/100\n",
      "169/169 [==============================] - 2s 14ms/step - loss: 0.5437 - accuracy: 0.9043 - val_loss: 0.4895 - val_accuracy: 0.9359\n",
      "Epoch 41/100\n",
      "169/169 [==============================] - 2s 10ms/step - loss: 0.5259 - accuracy: 0.9088 - val_loss: 0.4817 - val_accuracy: 0.9302\n",
      "Epoch 42/100\n",
      "169/169 [==============================] - 2s 10ms/step - loss: 0.5273 - accuracy: 0.9092 - val_loss: 0.4797 - val_accuracy: 0.9333\n",
      "Epoch 43/100\n",
      "169/169 [==============================] - 1s 8ms/step - loss: 0.5289 - accuracy: 0.9075 - val_loss: 0.4753 - val_accuracy: 0.9346\n",
      "Epoch 44/100\n",
      "169/169 [==============================] - 1s 9ms/step - loss: 0.5234 - accuracy: 0.9093 - val_loss: 0.4712 - val_accuracy: 0.9328\n",
      "Epoch 45/100\n",
      "169/169 [==============================] - 1s 9ms/step - loss: 0.5191 - accuracy: 0.9101 - val_loss: 0.4663 - val_accuracy: 0.9350\n",
      "Epoch 46/100\n",
      "169/169 [==============================] - 2s 11ms/step - loss: 0.5096 - accuracy: 0.9123 - val_loss: 0.4598 - val_accuracy: 0.9328\n",
      "Epoch 47/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "169/169 [==============================] - 2s 9ms/step - loss: 0.5114 - accuracy: 0.9093 - val_loss: 0.4562 - val_accuracy: 0.9376\n",
      "Epoch 48/100\n",
      "169/169 [==============================] - 2s 10ms/step - loss: 0.4958 - accuracy: 0.9157 - val_loss: 0.4581 - val_accuracy: 0.9385\n",
      "Epoch 49/100\n",
      "169/169 [==============================] - 2s 10ms/step - loss: 0.4988 - accuracy: 0.9153 - val_loss: 0.4468 - val_accuracy: 0.9372\n",
      "Epoch 50/100\n",
      "169/169 [==============================] - 2s 14ms/step - loss: 0.4948 - accuracy: 0.9183 - val_loss: 0.4440 - val_accuracy: 0.9389\n",
      "Epoch 51/100\n",
      "169/169 [==============================] - 3s 17ms/step - loss: 0.4926 - accuracy: 0.9184 - val_loss: 0.4507 - val_accuracy: 0.9419\n",
      "Epoch 52/100\n",
      "169/169 [==============================] - 2s 12ms/step - loss: 0.4843 - accuracy: 0.9218 - val_loss: 0.4390 - val_accuracy: 0.9406\n",
      "Epoch 53/100\n",
      "169/169 [==============================] - 2s 9ms/step - loss: 0.4802 - accuracy: 0.9233 - val_loss: 0.4407 - val_accuracy: 0.9432\n",
      "Epoch 54/100\n",
      "169/169 [==============================] - 2s 10ms/step - loss: 0.4829 - accuracy: 0.9249 - val_loss: 0.4335 - val_accuracy: 0.9463\n",
      "Epoch 55/100\n",
      "169/169 [==============================] - 2s 12ms/step - loss: 0.4766 - accuracy: 0.9244 - val_loss: 0.4310 - val_accuracy: 0.9450\n",
      "Epoch 56/100\n",
      "169/169 [==============================] - 2s 9ms/step - loss: 0.4676 - accuracy: 0.9242 - val_loss: 0.4241 - val_accuracy: 0.9437\n",
      "Epoch 57/100\n",
      "169/169 [==============================] - 1s 9ms/step - loss: 0.4738 - accuracy: 0.9259 - val_loss: 0.4240 - val_accuracy: 0.9476\n",
      "Epoch 58/100\n",
      "169/169 [==============================] - 1s 8ms/step - loss: 0.4621 - accuracy: 0.9313 - val_loss: 0.4215 - val_accuracy: 0.9467\n",
      "Epoch 59/100\n",
      "169/169 [==============================] - 1s 8ms/step - loss: 0.4570 - accuracy: 0.9302 - val_loss: 0.4212 - val_accuracy: 0.9437\n",
      "Epoch 60/100\n",
      "169/169 [==============================] - 2s 9ms/step - loss: 0.4567 - accuracy: 0.9333 - val_loss: 0.4123 - val_accuracy: 0.9471\n",
      "Epoch 61/100\n",
      "169/169 [==============================] - 1s 9ms/step - loss: 0.4487 - accuracy: 0.9348 - val_loss: 0.4090 - val_accuracy: 0.9476\n",
      "Epoch 62/100\n",
      "169/169 [==============================] - 2s 9ms/step - loss: 0.4468 - accuracy: 0.9294 - val_loss: 0.4106 - val_accuracy: 0.9497\n",
      "Epoch 63/100\n",
      "169/169 [==============================] - 2s 9ms/step - loss: 0.4543 - accuracy: 0.9300 - val_loss: 0.4058 - val_accuracy: 0.9506\n",
      "Epoch 64/100\n",
      "169/169 [==============================] - 1s 8ms/step - loss: 0.4459 - accuracy: 0.9348 - val_loss: 0.4161 - val_accuracy: 0.9437\n",
      "Epoch 65/100\n",
      "169/169 [==============================] - 1s 7ms/step - loss: 0.4457 - accuracy: 0.9322 - val_loss: 0.4064 - val_accuracy: 0.9484\n",
      "Epoch 66/100\n",
      "169/169 [==============================] - 1s 6ms/step - loss: 0.4427 - accuracy: 0.9370 - val_loss: 0.4079 - val_accuracy: 0.9489\n",
      "Epoch 67/100\n",
      "169/169 [==============================] - 1s 7ms/step - loss: 0.4394 - accuracy: 0.9352 - val_loss: 0.4073 - val_accuracy: 0.9506\n",
      "Epoch 68/100\n",
      "169/169 [==============================] - 1s 7ms/step - loss: 0.4299 - accuracy: 0.9415 - val_loss: 0.3973 - val_accuracy: 0.9471\n",
      "Epoch 69/100\n",
      "169/169 [==============================] - 1s 9ms/step - loss: 0.4324 - accuracy: 0.9376 - val_loss: 0.4010 - val_accuracy: 0.9493\n",
      "Epoch 70/100\n",
      "169/169 [==============================] - 2s 11ms/step - loss: 0.4341 - accuracy: 0.9359 - val_loss: 0.3889 - val_accuracy: 0.9484\n",
      "Epoch 71/100\n",
      "169/169 [==============================] - 2s 11ms/step - loss: 0.4325 - accuracy: 0.9372 - val_loss: 0.3935 - val_accuracy: 0.9528\n",
      "Epoch 72/100\n",
      "169/169 [==============================] - 1s 8ms/step - loss: 0.4177 - accuracy: 0.9428 - val_loss: 0.3830 - val_accuracy: 0.9515\n",
      "Epoch 73/100\n",
      "169/169 [==============================] - 2s 11ms/step - loss: 0.4306 - accuracy: 0.9344 - val_loss: 0.3928 - val_accuracy: 0.9467\n",
      "Epoch 74/100\n",
      "169/169 [==============================] - 2s 11ms/step - loss: 0.4192 - accuracy: 0.9385 - val_loss: 0.3901 - val_accuracy: 0.9519\n",
      "Epoch 75/100\n",
      "169/169 [==============================] - 2s 14ms/step - loss: 0.4207 - accuracy: 0.9402 - val_loss: 0.3804 - val_accuracy: 0.9519\n",
      "Epoch 76/100\n",
      "169/169 [==============================] - 2s 9ms/step - loss: 0.4162 - accuracy: 0.9393 - val_loss: 0.3794 - val_accuracy: 0.9523\n",
      "Epoch 77/100\n",
      "169/169 [==============================] - 2s 11ms/step - loss: 0.4213 - accuracy: 0.9391 - val_loss: 0.3846 - val_accuracy: 0.9497\n",
      "Epoch 78/100\n",
      "169/169 [==============================] - 2s 9ms/step - loss: 0.4166 - accuracy: 0.9458 - val_loss: 0.3841 - val_accuracy: 0.9467\n",
      "Epoch 79/100\n",
      "169/169 [==============================] - 2s 10ms/step - loss: 0.4056 - accuracy: 0.9489 - val_loss: 0.3738 - val_accuracy: 0.9528\n",
      "Epoch 80/100\n",
      "169/169 [==============================] - 2s 9ms/step - loss: 0.4022 - accuracy: 0.9448 - val_loss: 0.3715 - val_accuracy: 0.9515\n",
      "Epoch 81/100\n",
      "169/169 [==============================] - 1s 7ms/step - loss: 0.3961 - accuracy: 0.9458 - val_loss: 0.3753 - val_accuracy: 0.9519\n",
      "Epoch 82/100\n",
      "169/169 [==============================] - 1s 8ms/step - loss: 0.4049 - accuracy: 0.9413 - val_loss: 0.3721 - val_accuracy: 0.9480\n",
      "Epoch 83/100\n",
      "169/169 [==============================] - 2s 9ms/step - loss: 0.4058 - accuracy: 0.9417 - val_loss: 0.3766 - val_accuracy: 0.9523\n",
      "Epoch 84/100\n",
      "169/169 [==============================] - 2s 13ms/step - loss: 0.3955 - accuracy: 0.9489 - val_loss: 0.3656 - val_accuracy: 0.9497\n",
      "Epoch 85/100\n",
      "169/169 [==============================] - 2s 12ms/step - loss: 0.3944 - accuracy: 0.9495 - val_loss: 0.3718 - val_accuracy: 0.9532\n",
      "Epoch 86/100\n",
      "169/169 [==============================] - 2s 10ms/step - loss: 0.3960 - accuracy: 0.9465 - val_loss: 0.3708 - val_accuracy: 0.9532\n",
      "Epoch 87/100\n",
      "169/169 [==============================] - 2s 10ms/step - loss: 0.3961 - accuracy: 0.9472 - val_loss: 0.3658 - val_accuracy: 0.9502\n",
      "Epoch 88/100\n",
      "169/169 [==============================] - 2s 9ms/step - loss: 0.3934 - accuracy: 0.9448 - val_loss: 0.3587 - val_accuracy: 0.9541\n",
      "Epoch 89/100\n",
      "169/169 [==============================] - 2s 10ms/step - loss: 0.3925 - accuracy: 0.9446 - val_loss: 0.3719 - val_accuracy: 0.9562\n",
      "Epoch 90/100\n",
      "169/169 [==============================] - 1s 9ms/step - loss: 0.3889 - accuracy: 0.9487 - val_loss: 0.3753 - val_accuracy: 0.9528\n",
      "Epoch 91/100\n",
      "169/169 [==============================] - 1s 8ms/step - loss: 0.3899 - accuracy: 0.9513 - val_loss: 0.3608 - val_accuracy: 0.9536\n",
      "Epoch 92/100\n",
      "169/169 [==============================] - 1s 7ms/step - loss: 0.3863 - accuracy: 0.9463 - val_loss: 0.3589 - val_accuracy: 0.9545\n",
      "Epoch 93/100\n",
      "169/169 [==============================] - 2s 9ms/step - loss: 0.3834 - accuracy: 0.9528 - val_loss: 0.3598 - val_accuracy: 0.9532\n",
      "Epoch 94/100\n",
      "169/169 [==============================] - 2s 11ms/step - loss: 0.3848 - accuracy: 0.9493 - val_loss: 0.3559 - val_accuracy: 0.9502\n",
      "Epoch 95/100\n",
      "169/169 [==============================] - 2s 14ms/step - loss: 0.3749 - accuracy: 0.9515 - val_loss: 0.3585 - val_accuracy: 0.9554\n",
      "Epoch 96/100\n",
      "169/169 [==============================] - 2s 9ms/step - loss: 0.3825 - accuracy: 0.9500 - val_loss: 0.3647 - val_accuracy: 0.9528\n",
      "Epoch 97/100\n",
      "169/169 [==============================] - 2s 9ms/step - loss: 0.3760 - accuracy: 0.9526 - val_loss: 0.3528 - val_accuracy: 0.9528\n",
      "Epoch 98/100\n",
      "169/169 [==============================] - 1s 9ms/step - loss: 0.3771 - accuracy: 0.9528 - val_loss: 0.3641 - val_accuracy: 0.9506\n",
      "Epoch 99/100\n",
      "169/169 [==============================] - 2s 9ms/step - loss: 0.3748 - accuracy: 0.9515 - val_loss: 0.3554 - val_accuracy: 0.9541\n",
      "Epoch 100/100\n",
      "169/169 [==============================] - 2s 9ms/step - loss: 0.3683 - accuracy: 0.9515 - val_loss: 0.3538 - val_accuracy: 0.9532\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 5383, 30)          549270    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 5383, 30)          0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 5383, 8)           248       \n",
      "=================================================================\n",
      "Total params: 549,518\n",
      "Trainable params: 549,518\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73/73 [==============================] - 0s 3ms/step - loss: 0.3538 - accuracy: 0.9532\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 5383, 18308) for input Tensor(\"dense_4_input:0\", shape=(None, 5383, 18308), dtype=float32), but it was called on an input with incompatible shape (None, 18308).\n",
      "prob 0\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_6 (Dense)              (None, 5383, 30)          549270    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 5383, 30)          0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 5383, 8)           248       \n",
      "=================================================================\n",
      "Total params: 549,518\n",
      "Trainable params: 549,518\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 5383, 18308) for input Tensor(\"dense_6_input:0\", shape=(None, 5383, 18308), dtype=float32), but it was called on an input with incompatible shape (None, 18308).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 5383, 18308) for input Tensor(\"dense_6_input:0\", shape=(None, 5383, 18308), dtype=float32), but it was called on an input with incompatible shape (None, 18308).\n",
      "164/169 [============================>.] - ETA: 0s - loss: 1.6231 - accuracy: 0.5846WARNING:tensorflow:Model was constructed with shape (None, 5383, 18308) for input Tensor(\"dense_6_input:0\", shape=(None, 5383, 18308), dtype=float32), but it was called on an input with incompatible shape (None, 18308).\n",
      "169/169 [==============================] - 2s 9ms/step - loss: 1.6118 - accuracy: 0.5872 - val_loss: 1.2013 - val_accuracy: 0.6763\n",
      "Epoch 2/100\n",
      "169/169 [==============================] - 2s 9ms/step - loss: 1.1519 - accuracy: 0.6911 - val_loss: 1.0414 - val_accuracy: 0.7777\n",
      "Epoch 3/100\n",
      "169/169 [==============================] - 1s 9ms/step - loss: 1.0583 - accuracy: 0.7243 - val_loss: 0.9760 - val_accuracy: 0.7864\n",
      "Epoch 4/100\n",
      "169/169 [==============================] - 1s 7ms/step - loss: 1.0089 - accuracy: 0.7516 - val_loss: 0.9295 - val_accuracy: 0.8072\n",
      "Epoch 5/100\n",
      "169/169 [==============================] - 1s 7ms/step - loss: 0.9663 - accuracy: 0.7665 - val_loss: 0.8916 - val_accuracy: 0.8206\n",
      "Epoch 6/100\n",
      "169/169 [==============================] - 1s 7ms/step - loss: 0.9391 - accuracy: 0.7763 - val_loss: 0.8616 - val_accuracy: 0.8280\n",
      "Epoch 7/100\n",
      "169/169 [==============================] - 1s 7ms/step - loss: 0.9099 - accuracy: 0.7944 - val_loss: 0.8357 - val_accuracy: 0.8583\n",
      "Epoch 8/100\n",
      "169/169 [==============================] - 1s 8ms/step - loss: 0.8786 - accuracy: 0.8038 - val_loss: 0.8092 - val_accuracy: 0.8601\n",
      "Epoch 9/100\n",
      "169/169 [==============================] - 2s 11ms/step - loss: 0.8580 - accuracy: 0.8126 - val_loss: 0.7870 - val_accuracy: 0.8713\n",
      "Epoch 10/100\n",
      "169/169 [==============================] - 2s 11ms/step - loss: 0.8368 - accuracy: 0.8228 - val_loss: 0.7650 - val_accuracy: 0.8731\n",
      "Epoch 11/100\n",
      "169/169 [==============================] - 2s 9ms/step - loss: 0.8149 - accuracy: 0.8324 - val_loss: 0.7480 - val_accuracy: 0.8882\n",
      "Epoch 12/100\n",
      "169/169 [==============================] - 1s 8ms/step - loss: 0.7938 - accuracy: 0.8380 - val_loss: 0.7295 - val_accuracy: 0.8873\n",
      "Epoch 13/100\n",
      "169/169 [==============================] - 1s 7ms/step - loss: 0.7818 - accuracy: 0.8369 - val_loss: 0.7131 - val_accuracy: 0.8912\n",
      "Epoch 14/100\n",
      "169/169 [==============================] - 2s 9ms/step - loss: 0.7661 - accuracy: 0.8408 - val_loss: 0.6967 - val_accuracy: 0.8886\n",
      "Epoch 15/100\n",
      "169/169 [==============================] - 2s 9ms/step - loss: 0.7539 - accuracy: 0.8477 - val_loss: 0.6824 - val_accuracy: 0.8930\n",
      "Epoch 16/100\n",
      "169/169 [==============================] - 1s 8ms/step - loss: 0.7291 - accuracy: 0.8549 - val_loss: 0.6675 - val_accuracy: 0.8986\n",
      "Epoch 17/100\n",
      "169/169 [==============================] - 2s 11ms/step - loss: 0.7212 - accuracy: 0.8544 - val_loss: 0.6562 - val_accuracy: 0.9055\n",
      "Epoch 18/100\n",
      "169/169 [==============================] - 2s 14ms/step - loss: 0.7120 - accuracy: 0.8603 - val_loss: 0.6425 - val_accuracy: 0.9042\n",
      "Epoch 19/100\n",
      "169/169 [==============================] - 2s 13ms/step - loss: 0.6995 - accuracy: 0.8612 - val_loss: 0.6296 - val_accuracy: 0.9077\n",
      "Epoch 20/100\n",
      "169/169 [==============================] - 2s 12ms/step - loss: 0.6900 - accuracy: 0.8638 - val_loss: 0.6248 - val_accuracy: 0.9099\n",
      "Epoch 21/100\n",
      "169/169 [==============================] - 2s 11ms/step - loss: 0.6765 - accuracy: 0.8729 - val_loss: 0.6248 - val_accuracy: 0.9103\n",
      "Epoch 22/100\n",
      "169/169 [==============================] - 1s 8ms/step - loss: 0.6638 - accuracy: 0.8766 - val_loss: 0.6046 - val_accuracy: 0.9138\n",
      "Epoch 23/100\n",
      "169/169 [==============================] - 2s 10ms/step - loss: 0.6559 - accuracy: 0.8750 - val_loss: 0.5931 - val_accuracy: 0.9168\n",
      "Epoch 24/100\n",
      "169/169 [==============================] - 2s 9ms/step - loss: 0.6484 - accuracy: 0.8798 - val_loss: 0.5833 - val_accuracy: 0.9164\n",
      "Epoch 25/100\n",
      "169/169 [==============================] - 2s 9ms/step - loss: 0.6374 - accuracy: 0.8809 - val_loss: 0.5756 - val_accuracy: 0.9185\n",
      "Epoch 26/100\n",
      "169/169 [==============================] - 2s 9ms/step - loss: 0.6341 - accuracy: 0.8859 - val_loss: 0.5726 - val_accuracy: 0.9185\n",
      "Epoch 27/100\n",
      "169/169 [==============================] - 2s 9ms/step - loss: 0.6154 - accuracy: 0.8891 - val_loss: 0.5681 - val_accuracy: 0.9268\n",
      "Epoch 28/100\n",
      "169/169 [==============================] - 2s 10ms/step - loss: 0.6068 - accuracy: 0.8898 - val_loss: 0.5578 - val_accuracy: 0.9259\n",
      "Epoch 29/100\n",
      "169/169 [==============================] - 2s 14ms/step - loss: 0.6070 - accuracy: 0.8893 - val_loss: 0.5460 - val_accuracy: 0.9237\n",
      "Epoch 30/100\n",
      "169/169 [==============================] - 2s 11ms/step - loss: 0.5986 - accuracy: 0.8917 - val_loss: 0.5377 - val_accuracy: 0.9259\n",
      "Epoch 31/100\n",
      "169/169 [==============================] - 2s 10ms/step - loss: 0.5909 - accuracy: 0.8952 - val_loss: 0.5345 - val_accuracy: 0.9285\n",
      "Epoch 32/100\n",
      "169/169 [==============================] - 2s 11ms/step - loss: 0.5837 - accuracy: 0.8976 - val_loss: 0.5253 - val_accuracy: 0.9263\n",
      "Epoch 33/100\n",
      "169/169 [==============================] - 1s 7ms/step - loss: 0.5718 - accuracy: 0.8991 - val_loss: 0.5249 - val_accuracy: 0.9333\n",
      "Epoch 34/100\n",
      "169/169 [==============================] - 1s 7ms/step - loss: 0.5696 - accuracy: 0.9056 - val_loss: 0.5138 - val_accuracy: 0.9302\n",
      "Epoch 35/100\n",
      "169/169 [==============================] - 1s 8ms/step - loss: 0.5597 - accuracy: 0.9014 - val_loss: 0.5111 - val_accuracy: 0.9324\n",
      "Epoch 36/100\n",
      "169/169 [==============================] - 1s 8ms/step - loss: 0.5516 - accuracy: 0.9051 - val_loss: 0.5006 - val_accuracy: 0.9263\n",
      "Epoch 37/100\n",
      "169/169 [==============================] - 1s 7ms/step - loss: 0.5418 - accuracy: 0.9079 - val_loss: 0.4951 - val_accuracy: 0.9315\n",
      "Epoch 38/100\n",
      "169/169 [==============================] - 1s 8ms/step - loss: 0.5436 - accuracy: 0.9086 - val_loss: 0.4947 - val_accuracy: 0.9272\n",
      "Epoch 39/100\n",
      "169/169 [==============================] - 1s 7ms/step - loss: 0.5348 - accuracy: 0.9116 - val_loss: 0.4905 - val_accuracy: 0.9346\n",
      "Epoch 40/100\n",
      "169/169 [==============================] - 1s 7ms/step - loss: 0.5297 - accuracy: 0.9108 - val_loss: 0.4828 - val_accuracy: 0.9311\n",
      "Epoch 41/100\n",
      "169/169 [==============================] - 1s 7ms/step - loss: 0.5260 - accuracy: 0.9106 - val_loss: 0.4765 - val_accuracy: 0.9354\n",
      "Epoch 42/100\n",
      "169/169 [==============================] - 1s 7ms/step - loss: 0.5236 - accuracy: 0.9105 - val_loss: 0.4722 - val_accuracy: 0.9337\n",
      "Epoch 43/100\n",
      "169/169 [==============================] - 2s 9ms/step - loss: 0.5118 - accuracy: 0.9170 - val_loss: 0.4742 - val_accuracy: 0.9294\n",
      "Epoch 44/100\n",
      "169/169 [==============================] - 1s 7ms/step - loss: 0.5084 - accuracy: 0.9155 - val_loss: 0.4675 - val_accuracy: 0.9354\n",
      "Epoch 45/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "169/169 [==============================] - 1s 7ms/step - loss: 0.5090 - accuracy: 0.9205 - val_loss: 0.4635 - val_accuracy: 0.9354\n",
      "Epoch 46/100\n",
      "169/169 [==============================] - 1s 7ms/step - loss: 0.4965 - accuracy: 0.9181 - val_loss: 0.4582 - val_accuracy: 0.9346\n",
      "Epoch 47/100\n",
      "169/169 [==============================] - 1s 8ms/step - loss: 0.4986 - accuracy: 0.9214 - val_loss: 0.4535 - val_accuracy: 0.9346\n",
      "Epoch 48/100\n",
      "169/169 [==============================] - 2s 9ms/step - loss: 0.4909 - accuracy: 0.9231 - val_loss: 0.4553 - val_accuracy: 0.9346\n",
      "Epoch 49/100\n",
      "169/169 [==============================] - 2s 10ms/step - loss: 0.4894 - accuracy: 0.9223 - val_loss: 0.4513 - val_accuracy: 0.9376\n",
      "Epoch 50/100\n",
      "169/169 [==============================] - 2s 9ms/step - loss: 0.4865 - accuracy: 0.9244 - val_loss: 0.4472 - val_accuracy: 0.9367\n",
      "Epoch 51/100\n",
      "169/169 [==============================] - 2s 10ms/step - loss: 0.4771 - accuracy: 0.9231 - val_loss: 0.4418 - val_accuracy: 0.9385\n",
      "Epoch 52/100\n",
      "169/169 [==============================] - 2s 9ms/step - loss: 0.4766 - accuracy: 0.9238 - val_loss: 0.4308 - val_accuracy: 0.9411\n",
      "Epoch 53/100\n",
      "169/169 [==============================] - 2s 10ms/step - loss: 0.4765 - accuracy: 0.9223 - val_loss: 0.4401 - val_accuracy: 0.9376\n",
      "Epoch 54/100\n",
      "169/169 [==============================] - 2s 11ms/step - loss: 0.4620 - accuracy: 0.9287 - val_loss: 0.4336 - val_accuracy: 0.9385\n",
      "Epoch 55/100\n",
      "169/169 [==============================] - 2s 10ms/step - loss: 0.4705 - accuracy: 0.9272 - val_loss: 0.4262 - val_accuracy: 0.9428\n",
      "Epoch 56/100\n",
      "169/169 [==============================] - 2s 12ms/step - loss: 0.4675 - accuracy: 0.9264 - val_loss: 0.4227 - val_accuracy: 0.9437\n",
      "Epoch 57/100\n",
      "169/169 [==============================] - 2s 10ms/step - loss: 0.4556 - accuracy: 0.9324 - val_loss: 0.4233 - val_accuracy: 0.9415\n",
      "Epoch 58/100\n",
      "169/169 [==============================] - 2s 9ms/step - loss: 0.4551 - accuracy: 0.9289 - val_loss: 0.4277 - val_accuracy: 0.9437\n",
      "Epoch 59/100\n",
      "169/169 [==============================] - 2s 9ms/step - loss: 0.4535 - accuracy: 0.9298 - val_loss: 0.4149 - val_accuracy: 0.9463\n",
      "Epoch 60/100\n",
      "169/169 [==============================] - 2s 12ms/step - loss: 0.4407 - accuracy: 0.9376 - val_loss: 0.4149 - val_accuracy: 0.9411\n",
      "Epoch 61/100\n",
      "169/169 [==============================] - 2s 14ms/step - loss: 0.4470 - accuracy: 0.9307 - val_loss: 0.4134 - val_accuracy: 0.9458\n",
      "Epoch 62/100\n",
      "169/169 [==============================] - 2s 10ms/step - loss: 0.4403 - accuracy: 0.9357 - val_loss: 0.4132 - val_accuracy: 0.9437\n",
      "Epoch 63/100\n",
      "169/169 [==============================] - 2s 14ms/step - loss: 0.4374 - accuracy: 0.9381 - val_loss: 0.4036 - val_accuracy: 0.9515\n",
      "Epoch 64/100\n",
      "169/169 [==============================] - 2s 10ms/step - loss: 0.4407 - accuracy: 0.9320 - val_loss: 0.4090 - val_accuracy: 0.9493\n",
      "Epoch 65/100\n",
      "169/169 [==============================] - 2s 9ms/step - loss: 0.4350 - accuracy: 0.9352 - val_loss: 0.4048 - val_accuracy: 0.9506\n",
      "Epoch 66/100\n",
      "169/169 [==============================] - 2s 14ms/step - loss: 0.4320 - accuracy: 0.9381 - val_loss: 0.3993 - val_accuracy: 0.9484\n",
      "Epoch 67/100\n",
      "169/169 [==============================] - 2s 11ms/step - loss: 0.4206 - accuracy: 0.9419 - val_loss: 0.3960 - val_accuracy: 0.9489\n",
      "Epoch 68/100\n",
      "169/169 [==============================] - 2s 9ms/step - loss: 0.4275 - accuracy: 0.9372 - val_loss: 0.3965 - val_accuracy: 0.9515\n",
      "Epoch 69/100\n",
      "169/169 [==============================] - 2s 13ms/step - loss: 0.4103 - accuracy: 0.9400 - val_loss: 0.3887 - val_accuracy: 0.9506\n",
      "Epoch 70/100\n",
      "169/169 [==============================] - 2s 13ms/step - loss: 0.4222 - accuracy: 0.9367 - val_loss: 0.3992 - val_accuracy: 0.9467\n",
      "Epoch 71/100\n",
      "169/169 [==============================] - 2s 9ms/step - loss: 0.4117 - accuracy: 0.9385 - val_loss: 0.3911 - val_accuracy: 0.9467\n",
      "Epoch 72/100\n",
      "169/169 [==============================] - 1s 8ms/step - loss: 0.4197 - accuracy: 0.9407 - val_loss: 0.3873 - val_accuracy: 0.9463\n",
      "Epoch 73/100\n",
      "169/169 [==============================] - 2s 9ms/step - loss: 0.4120 - accuracy: 0.9413 - val_loss: 0.3850 - val_accuracy: 0.9480\n",
      "Epoch 74/100\n",
      "169/169 [==============================] - 2s 9ms/step - loss: 0.4115 - accuracy: 0.9432 - val_loss: 0.3807 - val_accuracy: 0.9515\n",
      "Epoch 75/100\n",
      "169/169 [==============================] - 1s 7ms/step - loss: 0.4059 - accuracy: 0.9420 - val_loss: 0.3870 - val_accuracy: 0.9528\n",
      "Epoch 76/100\n",
      "169/169 [==============================] - 1s 7ms/step - loss: 0.4088 - accuracy: 0.9411 - val_loss: 0.3751 - val_accuracy: 0.9506\n",
      "Epoch 77/100\n",
      "169/169 [==============================] - 1s 6ms/step - loss: 0.4050 - accuracy: 0.9407 - val_loss: 0.3850 - val_accuracy: 0.9502\n",
      "Epoch 78/100\n",
      "169/169 [==============================] - 1s 7ms/step - loss: 0.3978 - accuracy: 0.9428 - val_loss: 0.3711 - val_accuracy: 0.9519\n",
      "Epoch 79/100\n",
      "169/169 [==============================] - 2s 10ms/step - loss: 0.3979 - accuracy: 0.9463 - val_loss: 0.3789 - val_accuracy: 0.9510\n",
      "Epoch 80/100\n",
      "169/169 [==============================] - 1s 9ms/step - loss: 0.4004 - accuracy: 0.9456 - val_loss: 0.3786 - val_accuracy: 0.9476\n",
      "Epoch 81/100\n",
      "169/169 [==============================] - 1s 8ms/step - loss: 0.3971 - accuracy: 0.9420 - val_loss: 0.3756 - val_accuracy: 0.9528\n",
      "Epoch 82/100\n",
      "169/169 [==============================] - 1s 7ms/step - loss: 0.3945 - accuracy: 0.9437 - val_loss: 0.3703 - val_accuracy: 0.9523\n",
      "Epoch 83/100\n",
      "169/169 [==============================] - 1s 7ms/step - loss: 0.3898 - accuracy: 0.9448 - val_loss: 0.3658 - val_accuracy: 0.9532\n",
      "Epoch 84/100\n",
      "169/169 [==============================] - 1s 9ms/step - loss: 0.3850 - accuracy: 0.9487 - val_loss: 0.3678 - val_accuracy: 0.9528\n",
      "Epoch 85/100\n",
      "169/169 [==============================] - 2s 9ms/step - loss: 0.3900 - accuracy: 0.9463 - val_loss: 0.3655 - val_accuracy: 0.9510\n",
      "Epoch 86/100\n",
      "169/169 [==============================] - 2s 9ms/step - loss: 0.3842 - accuracy: 0.9478 - val_loss: 0.3683 - val_accuracy: 0.9523\n",
      "Epoch 87/100\n",
      "169/169 [==============================] - 1s 9ms/step - loss: 0.3861 - accuracy: 0.9461 - val_loss: 0.3663 - val_accuracy: 0.9532\n",
      "Epoch 88/100\n",
      "169/169 [==============================] - 2s 9ms/step - loss: 0.3853 - accuracy: 0.9452 - val_loss: 0.3612 - val_accuracy: 0.9523\n",
      "Epoch 89/100\n",
      "169/169 [==============================] - 2s 11ms/step - loss: 0.3837 - accuracy: 0.9456 - val_loss: 0.3576 - val_accuracy: 0.9528\n",
      "Epoch 90/100\n",
      "169/169 [==============================] - 2s 12ms/step - loss: 0.3813 - accuracy: 0.9493 - val_loss: 0.3651 - val_accuracy: 0.9502\n",
      "Epoch 91/100\n",
      "169/169 [==============================] - 2s 13ms/step - loss: 0.3757 - accuracy: 0.9474 - val_loss: 0.3570 - val_accuracy: 0.9528\n",
      "Epoch 92/100\n",
      "169/169 [==============================] - 2s 9ms/step - loss: 0.3799 - accuracy: 0.9459 - val_loss: 0.3631 - val_accuracy: 0.9597\n",
      "Epoch 93/100\n",
      "169/169 [==============================] - 1s 8ms/step - loss: 0.3749 - accuracy: 0.9498 - val_loss: 0.3600 - val_accuracy: 0.9575\n",
      "Epoch 94/100\n",
      "169/169 [==============================] - 1s 7ms/step - loss: 0.3766 - accuracy: 0.9476 - val_loss: 0.3571 - val_accuracy: 0.9532\n",
      "Epoch 95/100\n",
      "169/169 [==============================] - 2s 9ms/step - loss: 0.3778 - accuracy: 0.9472 - val_loss: 0.3594 - val_accuracy: 0.9554\n",
      "Epoch 96/100\n",
      "169/169 [==============================] - 2s 11ms/step - loss: 0.3682 - accuracy: 0.9526 - val_loss: 0.3476 - val_accuracy: 0.9562\n",
      "Epoch 97/100\n",
      "169/169 [==============================] - 2s 12ms/step - loss: 0.3742 - accuracy: 0.9471 - val_loss: 0.3568 - val_accuracy: 0.9541\n",
      "Epoch 98/100\n",
      "169/169 [==============================] - 2s 12ms/step - loss: 0.3710 - accuracy: 0.9528 - val_loss: 0.3541 - val_accuracy: 0.9562\n",
      "Epoch 99/100\n",
      "169/169 [==============================] - 2s 11ms/step - loss: 0.3631 - accuracy: 0.9530 - val_loss: 0.3464 - val_accuracy: 0.9549\n",
      "Epoch 100/100\n",
      "169/169 [==============================] - 1s 9ms/step - loss: 0.3676 - accuracy: 0.9510 - val_loss: 0.3467 - val_accuracy: 0.9554\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_6 (Dense)              (None, 5383, 30)          549270    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 5383, 30)          0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 5383, 8)           248       \n",
      "=================================================================\n",
      "Total params: 549,518\n",
      "Trainable params: 549,518\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73/73 [==============================] - 0s 3ms/step - loss: 0.3467 - accuracy: 0.9554\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 5383, 18308) for input Tensor(\"dense_6_input:0\", shape=(None, 5383, 18308), dtype=float32), but it was called on an input with incompatible shape (None, 18308).\n",
      "prob 0\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_8 (Dense)              (None, 5383, 30)          549270    \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 5383, 30)          0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 5383, 8)           248       \n",
      "=================================================================\n",
      "Total params: 549,518\n",
      "Trainable params: 549,518\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 5383, 18308) for input Tensor(\"dense_8_input:0\", shape=(None, 5383, 18308), dtype=float32), but it was called on an input with incompatible shape (None, 18308).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 5383, 18308) for input Tensor(\"dense_8_input:0\", shape=(None, 5383, 18308), dtype=float32), but it was called on an input with incompatible shape (None, 18308).\n",
      "168/169 [============================>.] - ETA: 0s - loss: 1.7346 - accuracy: 0.6497WARNING:tensorflow:Model was constructed with shape (None, 5383, 18308) for input Tensor(\"dense_8_input:0\", shape=(None, 5383, 18308), dtype=float32), but it was called on an input with incompatible shape (None, 18308).\n",
      "169/169 [==============================] - 3s 15ms/step - loss: 1.7343 - accuracy: 0.6496 - val_loss: 1.2849 - val_accuracy: 0.6906\n",
      "Epoch 2/100\n",
      "169/169 [==============================] - 2s 14ms/step - loss: 1.1993 - accuracy: 0.6747 - val_loss: 1.0849 - val_accuracy: 0.7834\n",
      "Epoch 3/100\n",
      "169/169 [==============================] - 1s 8ms/step - loss: 1.0979 - accuracy: 0.7050 - val_loss: 1.0203 - val_accuracy: 0.7860\n",
      "Epoch 4/100\n",
      "169/169 [==============================] - 1s 9ms/step - loss: 1.0523 - accuracy: 0.7342 - val_loss: 0.9742 - val_accuracy: 0.7899\n",
      "Epoch 5/100\n",
      "169/169 [==============================] - 2s 12ms/step - loss: 1.0042 - accuracy: 0.7492 - val_loss: 0.9391 - val_accuracy: 0.7964\n",
      "Epoch 6/100\n",
      "169/169 [==============================] - 2s 13ms/step - loss: 0.9732 - accuracy: 0.7572 - val_loss: 0.9072 - val_accuracy: 0.8029\n",
      "Epoch 7/100\n",
      "169/169 [==============================] - 2s 12ms/step - loss: 0.9506 - accuracy: 0.7704 - val_loss: 0.8814 - val_accuracy: 0.8076\n",
      "Epoch 8/100\n",
      "169/169 [==============================] - 2s 9ms/step - loss: 0.9288 - accuracy: 0.7784 - val_loss: 0.8615 - val_accuracy: 0.8072\n",
      "Epoch 9/100\n",
      "169/169 [==============================] - 1s 9ms/step - loss: 0.8972 - accuracy: 0.7923 - val_loss: 0.8354 - val_accuracy: 0.8276\n",
      "Epoch 10/100\n",
      "169/169 [==============================] - 1s 8ms/step - loss: 0.8797 - accuracy: 0.7912 - val_loss: 0.8150 - val_accuracy: 0.8371\n",
      "Epoch 11/100\n",
      "169/169 [==============================] - 1s 7ms/step - loss: 0.8630 - accuracy: 0.8044 - val_loss: 0.7981 - val_accuracy: 0.8466\n",
      "Epoch 12/100\n",
      "169/169 [==============================] - 1s 7ms/step - loss: 0.8447 - accuracy: 0.8092 - val_loss: 0.7802 - val_accuracy: 0.8622\n",
      "Epoch 13/100\n",
      "169/169 [==============================] - 2s 10ms/step - loss: 0.8286 - accuracy: 0.8092 - val_loss: 0.7623 - val_accuracy: 0.8588\n",
      "Epoch 14/100\n",
      "169/169 [==============================] - 3s 15ms/step - loss: 0.8098 - accuracy: 0.8096 - val_loss: 0.7480 - val_accuracy: 0.8596\n",
      "Epoch 15/100\n",
      "169/169 [==============================] - 2s 10ms/step - loss: 0.7951 - accuracy: 0.8217 - val_loss: 0.7305 - val_accuracy: 0.8778\n",
      "Epoch 16/100\n",
      "169/169 [==============================] - 1s 8ms/step - loss: 0.7819 - accuracy: 0.8259 - val_loss: 0.7178 - val_accuracy: 0.8813\n",
      "Epoch 17/100\n",
      "169/169 [==============================] - 2s 9ms/step - loss: 0.7683 - accuracy: 0.8315 - val_loss: 0.7070 - val_accuracy: 0.8852\n",
      "Epoch 18/100\n",
      "169/169 [==============================] - 1s 8ms/step - loss: 0.7607 - accuracy: 0.8330 - val_loss: 0.6917 - val_accuracy: 0.8895\n",
      "Epoch 19/100\n",
      "169/169 [==============================] - 1s 9ms/step - loss: 0.7426 - accuracy: 0.8399 - val_loss: 0.6752 - val_accuracy: 0.8986\n",
      "Epoch 20/100\n",
      "169/169 [==============================] - 1s 7ms/step - loss: 0.7273 - accuracy: 0.8443 - val_loss: 0.6655 - val_accuracy: 0.9047\n",
      "Epoch 21/100\n",
      "169/169 [==============================] - 1s 7ms/step - loss: 0.7209 - accuracy: 0.8477 - val_loss: 0.6522 - val_accuracy: 0.8960\n",
      "Epoch 22/100\n",
      "169/169 [==============================] - 1s 6ms/step - loss: 0.7069 - accuracy: 0.8525 - val_loss: 0.6400 - val_accuracy: 0.9038\n",
      "Epoch 23/100\n",
      "169/169 [==============================] - 1s 7ms/step - loss: 0.6980 - accuracy: 0.8562 - val_loss: 0.6318 - val_accuracy: 0.9155\n",
      "Epoch 24/100\n",
      "169/169 [==============================] - 1s 7ms/step - loss: 0.6867 - accuracy: 0.8568 - val_loss: 0.6277 - val_accuracy: 0.9155\n",
      "Epoch 25/100\n",
      "169/169 [==============================] - 1s 6ms/step - loss: 0.6787 - accuracy: 0.8627 - val_loss: 0.6131 - val_accuracy: 0.9129\n",
      "Epoch 26/100\n",
      "169/169 [==============================] - 1s 6ms/step - loss: 0.6733 - accuracy: 0.8636 - val_loss: 0.6068 - val_accuracy: 0.9177\n",
      "Epoch 27/100\n",
      "169/169 [==============================] - 1s 7ms/step - loss: 0.6543 - accuracy: 0.8640 - val_loss: 0.5914 - val_accuracy: 0.9159\n",
      "Epoch 28/100\n",
      "169/169 [==============================] - 1s 8ms/step - loss: 0.6507 - accuracy: 0.8655 - val_loss: 0.5862 - val_accuracy: 0.9168\n",
      "Epoch 29/100\n",
      "169/169 [==============================] - 1s 8ms/step - loss: 0.6465 - accuracy: 0.8659 - val_loss: 0.5787 - val_accuracy: 0.9259\n",
      "Epoch 30/100\n",
      "169/169 [==============================] - 1s 7ms/step - loss: 0.6348 - accuracy: 0.8733 - val_loss: 0.5697 - val_accuracy: 0.9242\n",
      "Epoch 31/100\n",
      "169/169 [==============================] - 1s 6ms/step - loss: 0.6265 - accuracy: 0.8768 - val_loss: 0.5673 - val_accuracy: 0.9268\n",
      "Epoch 32/100\n",
      "169/169 [==============================] - 1s 7ms/step - loss: 0.6164 - accuracy: 0.8792 - val_loss: 0.5499 - val_accuracy: 0.9255\n",
      "Epoch 33/100\n",
      "169/169 [==============================] - 1s 9ms/step - loss: 0.6081 - accuracy: 0.8817 - val_loss: 0.5469 - val_accuracy: 0.9311\n",
      "Epoch 34/100\n",
      "169/169 [==============================] - 2s 9ms/step - loss: 0.6069 - accuracy: 0.8811 - val_loss: 0.5390 - val_accuracy: 0.9268\n",
      "Epoch 35/100\n",
      "169/169 [==============================] - 1s 8ms/step - loss: 0.5893 - accuracy: 0.8913 - val_loss: 0.5354 - val_accuracy: 0.9272\n",
      "Epoch 36/100\n",
      "169/169 [==============================] - 2s 9ms/step - loss: 0.5915 - accuracy: 0.8843 - val_loss: 0.5297 - val_accuracy: 0.9328\n",
      "Epoch 37/100\n",
      "169/169 [==============================] - 2s 10ms/step - loss: 0.5895 - accuracy: 0.8887 - val_loss: 0.5248 - val_accuracy: 0.9311\n",
      "Epoch 38/100\n",
      "169/169 [==============================] - 2s 9ms/step - loss: 0.5769 - accuracy: 0.8917 - val_loss: 0.5170 - val_accuracy: 0.9337\n",
      "Epoch 39/100\n",
      "169/169 [==============================] - 2s 13ms/step - loss: 0.5774 - accuracy: 0.8910 - val_loss: 0.5106 - val_accuracy: 0.9341\n",
      "Epoch 40/100\n",
      "169/169 [==============================] - 2s 12ms/step - loss: 0.5712 - accuracy: 0.8904 - val_loss: 0.5085 - val_accuracy: 0.9350\n",
      "Epoch 41/100\n",
      "169/169 [==============================] - 2s 10ms/step - loss: 0.5582 - accuracy: 0.8943 - val_loss: 0.5006 - val_accuracy: 0.9350\n",
      "Epoch 42/100\n",
      "169/169 [==============================] - 2s 11ms/step - loss: 0.5517 - accuracy: 0.8939 - val_loss: 0.4966 - val_accuracy: 0.9337\n",
      "Epoch 43/100\n",
      "169/169 [==============================] - 2s 10ms/step - loss: 0.5473 - accuracy: 0.8975 - val_loss: 0.4915 - val_accuracy: 0.9372\n",
      "Epoch 44/100\n",
      "169/169 [==============================] - 2s 11ms/step - loss: 0.5460 - accuracy: 0.8997 - val_loss: 0.4917 - val_accuracy: 0.9285\n",
      "Epoch 45/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "169/169 [==============================] - 2s 9ms/step - loss: 0.5322 - accuracy: 0.9025 - val_loss: 0.4840 - val_accuracy: 0.9359\n",
      "Epoch 46/100\n",
      "169/169 [==============================] - 2s 9ms/step - loss: 0.5305 - accuracy: 0.9015 - val_loss: 0.4712 - val_accuracy: 0.9367\n",
      "Epoch 47/100\n",
      "169/169 [==============================] - 2s 9ms/step - loss: 0.5251 - accuracy: 0.9092 - val_loss: 0.4765 - val_accuracy: 0.9380\n",
      "Epoch 48/100\n",
      "169/169 [==============================] - 2s 9ms/step - loss: 0.5216 - accuracy: 0.9092 - val_loss: 0.4678 - val_accuracy: 0.9359\n",
      "Epoch 49/100\n",
      "169/169 [==============================] - 2s 9ms/step - loss: 0.5122 - accuracy: 0.9049 - val_loss: 0.4657 - val_accuracy: 0.9398\n",
      "Epoch 50/100\n",
      "169/169 [==============================] - 2s 10ms/step - loss: 0.5150 - accuracy: 0.9127 - val_loss: 0.4625 - val_accuracy: 0.9406\n",
      "Epoch 51/100\n",
      "169/169 [==============================] - 2s 11ms/step - loss: 0.5090 - accuracy: 0.9106 - val_loss: 0.4582 - val_accuracy: 0.9424\n",
      "Epoch 52/100\n",
      "169/169 [==============================] - 2s 10ms/step - loss: 0.5016 - accuracy: 0.9153 - val_loss: 0.4628 - val_accuracy: 0.9320\n",
      "Epoch 53/100\n",
      "169/169 [==============================] - 2s 11ms/step - loss: 0.5081 - accuracy: 0.9142 - val_loss: 0.4554 - val_accuracy: 0.9389\n",
      "Epoch 54/100\n",
      "169/169 [==============================] - 2s 10ms/step - loss: 0.4964 - accuracy: 0.9181 - val_loss: 0.4481 - val_accuracy: 0.9402\n",
      "Epoch 55/100\n",
      "169/169 [==============================] - 2s 9ms/step - loss: 0.4886 - accuracy: 0.9179 - val_loss: 0.4405 - val_accuracy: 0.9454\n",
      "Epoch 56/100\n",
      "169/169 [==============================] - 2s 12ms/step - loss: 0.4973 - accuracy: 0.9175 - val_loss: 0.4412 - val_accuracy: 0.9389\n",
      "Epoch 57/100\n",
      "169/169 [==============================] - 2s 13ms/step - loss: 0.4868 - accuracy: 0.9158 - val_loss: 0.4354 - val_accuracy: 0.9463\n",
      "Epoch 58/100\n",
      "169/169 [==============================] - 2s 10ms/step - loss: 0.4891 - accuracy: 0.9153 - val_loss: 0.4342 - val_accuracy: 0.9398\n",
      "Epoch 59/100\n",
      "169/169 [==============================] - 2s 9ms/step - loss: 0.4775 - accuracy: 0.9225 - val_loss: 0.4311 - val_accuracy: 0.9402\n",
      "Epoch 60/100\n",
      "169/169 [==============================] - 2s 9ms/step - loss: 0.4794 - accuracy: 0.9199 - val_loss: 0.4246 - val_accuracy: 0.9437\n",
      "Epoch 61/100\n",
      "169/169 [==============================] - 2s 11ms/step - loss: 0.4785 - accuracy: 0.9199 - val_loss: 0.4216 - val_accuracy: 0.9454\n",
      "Epoch 62/100\n",
      "169/169 [==============================] - 2s 10ms/step - loss: 0.4675 - accuracy: 0.9238 - val_loss: 0.4237 - val_accuracy: 0.9432\n",
      "Epoch 63/100\n",
      "169/169 [==============================] - 2s 9ms/step - loss: 0.4683 - accuracy: 0.9244 - val_loss: 0.4160 - val_accuracy: 0.9484\n",
      "Epoch 64/100\n",
      "169/169 [==============================] - 2s 9ms/step - loss: 0.4716 - accuracy: 0.9209 - val_loss: 0.4185 - val_accuracy: 0.9476\n",
      "Epoch 65/100\n",
      "169/169 [==============================] - 2s 9ms/step - loss: 0.4566 - accuracy: 0.9294 - val_loss: 0.4076 - val_accuracy: 0.9484\n",
      "Epoch 66/100\n",
      "169/169 [==============================] - 1s 8ms/step - loss: 0.4513 - accuracy: 0.9344 - val_loss: 0.4097 - val_accuracy: 0.9467\n",
      "Epoch 67/100\n",
      "169/169 [==============================] - 1s 8ms/step - loss: 0.4580 - accuracy: 0.9289 - val_loss: 0.4116 - val_accuracy: 0.9528\n",
      "Epoch 68/100\n",
      "169/169 [==============================] - 2s 9ms/step - loss: 0.4557 - accuracy: 0.9287 - val_loss: 0.4059 - val_accuracy: 0.9476\n",
      "Epoch 69/100\n",
      "169/169 [==============================] - 1s 8ms/step - loss: 0.4528 - accuracy: 0.9281 - val_loss: 0.3985 - val_accuracy: 0.9506\n",
      "Epoch 70/100\n",
      "169/169 [==============================] - 2s 10ms/step - loss: 0.4535 - accuracy: 0.9277 - val_loss: 0.4061 - val_accuracy: 0.9489\n",
      "Epoch 71/100\n",
      "169/169 [==============================] - 1s 9ms/step - loss: 0.4443 - accuracy: 0.9298 - val_loss: 0.3954 - val_accuracy: 0.9471\n",
      "Epoch 72/100\n",
      "169/169 [==============================] - 1s 9ms/step - loss: 0.4439 - accuracy: 0.9311 - val_loss: 0.3952 - val_accuracy: 0.9502\n",
      "Epoch 73/100\n",
      "169/169 [==============================] - 1s 8ms/step - loss: 0.4380 - accuracy: 0.9309 - val_loss: 0.3967 - val_accuracy: 0.9502\n",
      "Epoch 74/100\n",
      "169/169 [==============================] - 1s 7ms/step - loss: 0.4383 - accuracy: 0.9307 - val_loss: 0.3918 - val_accuracy: 0.9541\n",
      "Epoch 75/100\n",
      "169/169 [==============================] - 2s 9ms/step - loss: 0.4412 - accuracy: 0.9316 - val_loss: 0.3907 - val_accuracy: 0.9532\n",
      "Epoch 76/100\n",
      "169/169 [==============================] - 2s 10ms/step - loss: 0.4337 - accuracy: 0.9328 - val_loss: 0.3871 - val_accuracy: 0.9541\n",
      "Epoch 77/100\n",
      "169/169 [==============================] - 2s 15ms/step - loss: 0.4316 - accuracy: 0.9354 - val_loss: 0.3836 - val_accuracy: 0.9545\n",
      "Epoch 78/100\n",
      "169/169 [==============================] - 2s 11ms/step - loss: 0.4258 - accuracy: 0.9348 - val_loss: 0.3881 - val_accuracy: 0.9493\n",
      "Epoch 79/100\n",
      "169/169 [==============================] - 2s 11ms/step - loss: 0.4293 - accuracy: 0.9277 - val_loss: 0.3807 - val_accuracy: 0.9519\n",
      "Epoch 80/100\n",
      "169/169 [==============================] - 2s 10ms/step - loss: 0.4297 - accuracy: 0.9368 - val_loss: 0.3820 - val_accuracy: 0.9536\n",
      "Epoch 81/100\n",
      "169/169 [==============================] - 2s 9ms/step - loss: 0.4254 - accuracy: 0.9328 - val_loss: 0.3867 - val_accuracy: 0.9510\n",
      "Epoch 82/100\n",
      "169/169 [==============================] - 2s 9ms/step - loss: 0.4277 - accuracy: 0.9333 - val_loss: 0.3836 - val_accuracy: 0.9506\n",
      "Epoch 83/100\n",
      "169/169 [==============================] - 2s 9ms/step - loss: 0.4155 - accuracy: 0.9357 - val_loss: 0.3798 - val_accuracy: 0.9493\n",
      "Epoch 84/100\n",
      "169/169 [==============================] - 1s 8ms/step - loss: 0.4153 - accuracy: 0.9400 - val_loss: 0.3793 - val_accuracy: 0.9545\n",
      "Epoch 85/100\n",
      "169/169 [==============================] - 1s 8ms/step - loss: 0.4182 - accuracy: 0.9354 - val_loss: 0.3729 - val_accuracy: 0.9528\n",
      "Epoch 86/100\n",
      "169/169 [==============================] - 1s 7ms/step - loss: 0.4006 - accuracy: 0.9450 - val_loss: 0.3648 - val_accuracy: 0.9532\n",
      "Epoch 87/100\n",
      "169/169 [==============================] - 2s 10ms/step - loss: 0.4130 - accuracy: 0.9394 - val_loss: 0.3734 - val_accuracy: 0.9554\n",
      "Epoch 88/100\n",
      "169/169 [==============================] - 2s 10ms/step - loss: 0.4159 - accuracy: 0.9337 - val_loss: 0.3778 - val_accuracy: 0.9502\n",
      "Epoch 89/100\n",
      "169/169 [==============================] - 2s 11ms/step - loss: 0.4091 - accuracy: 0.9361 - val_loss: 0.3672 - val_accuracy: 0.9515\n",
      "Epoch 90/100\n",
      "169/169 [==============================] - 1s 8ms/step - loss: 0.4099 - accuracy: 0.9376 - val_loss: 0.3703 - val_accuracy: 0.9554\n",
      "Epoch 91/100\n",
      "169/169 [==============================] - 2s 9ms/step - loss: 0.4129 - accuracy: 0.9385 - val_loss: 0.3710 - val_accuracy: 0.9536\n",
      "Epoch 92/100\n",
      "169/169 [==============================] - 1s 7ms/step - loss: 0.4046 - accuracy: 0.9365 - val_loss: 0.3697 - val_accuracy: 0.9510\n",
      "Epoch 93/100\n",
      "169/169 [==============================] - 1s 8ms/step - loss: 0.4035 - accuracy: 0.9443 - val_loss: 0.3609 - val_accuracy: 0.9549\n",
      "Epoch 94/100\n",
      "169/169 [==============================] - 1s 9ms/step - loss: 0.3949 - accuracy: 0.9411 - val_loss: 0.3614 - val_accuracy: 0.9554\n",
      "Epoch 95/100\n",
      "169/169 [==============================] - 2s 12ms/step - loss: 0.3898 - accuracy: 0.9437 - val_loss: 0.3568 - val_accuracy: 0.9541\n",
      "Epoch 96/100\n",
      "169/169 [==============================] - 2s 13ms/step - loss: 0.3894 - accuracy: 0.9413 - val_loss: 0.3558 - val_accuracy: 0.9523\n",
      "Epoch 97/100\n",
      "169/169 [==============================] - 2s 13ms/step - loss: 0.3929 - accuracy: 0.9406 - val_loss: 0.3609 - val_accuracy: 0.9541\n",
      "Epoch 98/100\n",
      "169/169 [==============================] - 2s 14ms/step - loss: 0.3961 - accuracy: 0.9420 - val_loss: 0.3541 - val_accuracy: 0.9554\n",
      "Epoch 99/100\n",
      "169/169 [==============================] - 2s 10ms/step - loss: 0.3875 - accuracy: 0.9446 - val_loss: 0.3604 - val_accuracy: 0.9567\n",
      "Epoch 100/100\n",
      "169/169 [==============================] - 2s 9ms/step - loss: 0.3875 - accuracy: 0.9446 - val_loss: 0.3548 - val_accuracy: 0.9554\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_8 (Dense)              (None, 5383, 30)          549270    \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 5383, 30)          0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 5383, 8)           248       \n",
      "=================================================================\n",
      "Total params: 549,518\n",
      "Trainable params: 549,518\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73/73 [==============================] - 0s 3ms/step - loss: 0.3548 - accuracy: 0.9554\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 5383, 18308) for input Tensor(\"dense_8_input:0\", shape=(None, 5383, 18308), dtype=float32), but it was called on an input with incompatible shape (None, 18308).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hassa\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metric Base\n",
      "time 0:14:11.347409\n",
      "measure Accuracy\n",
      "+----------------+--------------------+\n",
      "| Experiment No. |      DataSet1      |\n",
      "+----------------+--------------------+\n",
      "|       1        | 0.9566724436741768 |\n",
      "|       2        | 0.9519064124783362 |\n",
      "|       3        | 0.9532062391681109 |\n",
      "|       4        | 0.9553726169844021 |\n",
      "|       5        | 0.9553726169844021 |\n",
      "|    Average     | 0.9545060658578854 |\n",
      "+----------------+--------------------+\n",
      "metric Base\n",
      "time 0:14:11.347409\n",
      "measure Macro Precision\n",
      "+----------------+--------------------+\n",
      "| Experiment No. |      DataSet1      |\n",
      "+----------------+--------------------+\n",
      "|       1        | 0.9429445587585684 |\n",
      "|       2        | 0.806952876800857  |\n",
      "|       3        | 0.9496701969182128 |\n",
      "|       4        | 0.9470530276195126 |\n",
      "|       5        | 0.8136823753550882 |\n",
      "|    Average     | 0.8920606070904478 |\n",
      "+----------------+--------------------+\n",
      "metric Base\n",
      "time 0:14:11.347409\n",
      "measure Micro Precision\n",
      "+----------------+--------------------+\n",
      "| Experiment No. |      DataSet1      |\n",
      "+----------------+--------------------+\n",
      "|       1        | 0.9566724436741768 |\n",
      "|       2        | 0.9519064124783362 |\n",
      "|       3        | 0.9532062391681109 |\n",
      "|       4        | 0.9553726169844021 |\n",
      "|       5        | 0.9553726169844021 |\n",
      "|    Average     | 0.9545060658578854 |\n",
      "+----------------+--------------------+\n",
      "metric Base\n",
      "time 0:14:11.347409\n",
      "measure Macro Recall\n",
      "+----------------+--------------------+\n",
      "| Experiment No. |      DataSet1      |\n",
      "+----------------+--------------------+\n",
      "|       1        | 0.8157116165905569 |\n",
      "|       2        | 0.7777117593571474 |\n",
      "|       3        | 0.8022247149995345 |\n",
      "|       4        | 0.8063683926298055 |\n",
      "|       5        | 0.7766488447557577 |\n",
      "|    Average     | 0.7957330656665603 |\n",
      "+----------------+--------------------+\n",
      "metric Base\n",
      "time 0:14:11.347409\n",
      "measure Micro Recall\n",
      "+----------------+--------------------+\n",
      "| Experiment No. |      DataSet1      |\n",
      "+----------------+--------------------+\n",
      "|       1        | 0.9566724436741768 |\n",
      "|       2        | 0.9519064124783362 |\n",
      "|       3        | 0.9532062391681109 |\n",
      "|       4        | 0.9553726169844021 |\n",
      "|       5        | 0.9553726169844021 |\n",
      "|    Average     | 0.9545060658578854 |\n",
      "+----------------+--------------------+\n",
      "metric Base\n",
      "time 0:14:11.347409\n",
      "measure F Measure\n",
      "+----------------+--------------------+\n",
      "| Experiment No. |      DataSet1      |\n",
      "+----------------+--------------------+\n",
      "|       1        | 0.8447788029860657 |\n",
      "|       2        | 0.7914381025085214 |\n",
      "|       3        | 0.8326227558296107 |\n",
      "|       4        | 0.8449564144759117 |\n",
      "|       5        | 0.7931194872889207 |\n",
      "|    Average     | 0.821383112617806  |\n",
      "+----------------+--------------------+\n",
      "metric Base\n",
      "time 0:14:11.347409\n",
      "measure Micro F Measure\n",
      "+----------------+--------------------+\n",
      "| Experiment No. |      DataSet1      |\n",
      "+----------------+--------------------+\n",
      "|       1        | 0.9566724436741768 |\n",
      "|       2        | 0.9519064124783363 |\n",
      "|       3        | 0.9532062391681109 |\n",
      "|       4        | 0.9553726169844021 |\n",
      "|       5        | 0.9553726169844021 |\n",
      "|    Average     | 0.9545060658578857 |\n",
      "+----------------+--------------------+\n",
      "metric Base\n",
      "time 0:14:11.347409\n",
      "measure ROC\n",
      "+----------------+--------------------+\n",
      "| Experiment No. |      DataSet1      |\n",
      "+----------------+--------------------+\n",
      "|       1        | 0.9037874220135066 |\n",
      "|       2        | 0.8842412590409928 |\n",
      "|       3        | 0.8962644856157282 |\n",
      "|       4        | 0.8989327292929287 |\n",
      "|       5        | 0.8842090291238559 |\n",
      "|    Average     | 0.8934869850174024 |\n",
      "+----------------+--------------------+\n",
      "###############\n",
      "###############\n",
      "###############\n",
      "prob 2308\n",
      "Dist Mat shape 2308\n",
      "Element shape 5383\n",
      "(2308, 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hassa\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1176: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prob 2308\n",
      "Dist Mat shape 2308\n",
      "Element shape 5383\n",
      "(2308, 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hassa\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1176: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prob 2308\n",
      "Dist Mat shape 2308\n",
      "Element shape 5383\n",
      "(2308, 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hassa\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1176: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prob 2308\n",
      "Dist Mat shape 2308\n",
      "Element shape 5383\n",
      "(2308, 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hassa\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1176: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prob 2308\n",
      "Dist Mat shape 2308\n",
      "Element shape 5383\n",
      "(2308, 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hassa\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1176: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metric Euclidean\n",
      "time 1:09:11.108910\n",
      "measure Accuracy\n",
      "+----------------+--------------------+\n",
      "| Experiment No. |      DataSet1      |\n",
      "+----------------+--------------------+\n",
      "|       1        | 0.9579722703639515 |\n",
      "|       2        | 0.9523396880415944 |\n",
      "|       3        | 0.9545060658578857 |\n",
      "|       4        | 0.9536395147313691 |\n",
      "|       5        | 0.9566724436741768 |\n",
      "|    Average     | 0.9550259965337956 |\n",
      "+----------------+--------------------+\n",
      "metric Euclidean\n",
      "time 1:09:11.108910\n",
      "measure Macro Precision\n",
      "+----------------+--------------------+\n",
      "| Experiment No. |      DataSet1      |\n",
      "+----------------+--------------------+\n",
      "|       1        | 0.9470754002387396 |\n",
      "|       2        | 0.9366202134195047 |\n",
      "|       3        | 0.952583970176228  |\n",
      "|       4        | 0.9436701185271897 |\n",
      "|       5        | 0.945746809589401  |\n",
      "|    Average     | 0.9451393023902128 |\n",
      "+----------------+--------------------+\n",
      "metric Euclidean\n",
      "time 1:09:11.108910\n",
      "measure Micro Precision\n",
      "+----------------+--------------------+\n",
      "| Experiment No. |      DataSet1      |\n",
      "+----------------+--------------------+\n",
      "|       1        | 0.9579722703639515 |\n",
      "|       2        | 0.9523396880415944 |\n",
      "|       3        | 0.9545060658578857 |\n",
      "|       4        | 0.9536395147313691 |\n",
      "|       5        | 0.9566724436741768 |\n",
      "|    Average     | 0.9550259965337956 |\n",
      "+----------------+--------------------+\n",
      "metric Euclidean\n",
      "time 1:09:11.108910\n",
      "measure Macro Recall\n",
      "+----------------+--------------------+\n",
      "| Experiment No. |      DataSet1      |\n",
      "+----------------+--------------------+\n",
      "|       1        | 0.8256755423767985 |\n",
      "|       2        | 0.7831688343177949 |\n",
      "|       3        | 0.8107704527508797 |\n",
      "|       4        | 0.8020427201138045 |\n",
      "|       5        | 0.7934217136314303 |\n",
      "|    Average     | 0.8030158526381417 |\n",
      "+----------------+--------------------+\n",
      "metric Euclidean\n",
      "time 1:09:11.108910\n",
      "measure Micro Recall\n",
      "+----------------+--------------------+\n",
      "| Experiment No. |      DataSet1      |\n",
      "+----------------+--------------------+\n",
      "|       1        | 0.9579722703639515 |\n",
      "|       2        | 0.9523396880415944 |\n",
      "|       3        | 0.9545060658578857 |\n",
      "|       4        | 0.9536395147313691 |\n",
      "|       5        | 0.9566724436741768 |\n",
      "|    Average     | 0.9550259965337956 |\n",
      "+----------------+--------------------+\n",
      "metric Euclidean\n",
      "time 1:09:11.108910\n",
      "measure F Measure\n",
      "+----------------+--------------------+\n",
      "| Experiment No. |      DataSet1      |\n",
      "+----------------+--------------------+\n",
      "|       1        | 0.8586802335532912 |\n",
      "|       2        | 0.8073920532479748 |\n",
      "|       3        | 0.8460490193965919 |\n",
      "|       4        | 0.8411048627063589 |\n",
      "|       5        | 0.825192259431304  |\n",
      "|    Average     | 0.8356836856671042 |\n",
      "+----------------+--------------------+\n",
      "metric Euclidean\n",
      "time 1:09:11.108910\n",
      "measure Micro F Measure\n",
      "+----------------+--------------------+\n",
      "| Experiment No. |      DataSet1      |\n",
      "+----------------+--------------------+\n",
      "|       1        | 0.9579722703639515 |\n",
      "|       2        | 0.9523396880415944 |\n",
      "|       3        | 0.9545060658578857 |\n",
      "|       4        | 0.9536395147313691 |\n",
      "|       5        | 0.9566724436741768 |\n",
      "|    Average     | 0.9550259965337956 |\n",
      "+----------------+--------------------+\n",
      "metric Euclidean\n",
      "time 1:09:11.108910\n",
      "measure ROC\n",
      "+----------------+--------------------+\n",
      "| Experiment No. |      DataSet1      |\n",
      "+----------------+--------------------+\n",
      "|       1        | 0.9088470950926051 |\n",
      "|       2        | 0.8869435462202313 |\n",
      "|       3        | 0.9006689087974484 |\n",
      "|       4        | 0.8966030773997501 |\n",
      "|       5        | 0.8926725508623656 |\n",
      "|    Average     | 0.8971470356744801 |\n",
      "+----------------+--------------------+\n",
      "###############\n",
      "###############\n",
      "###############\n",
      "prob 2308\n",
      "Dist Mat shape 2308\n",
      "Element shape 5383\n",
      "(2308, 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hassa\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1176: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prob 2308\n",
      "Dist Mat shape 2308\n",
      "Element shape 5383\n",
      "(2308, 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hassa\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1176: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prob 2308\n",
      "Dist Mat shape 2308\n",
      "Element shape 5383\n",
      "(2308, 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hassa\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1176: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prob 2308\n",
      "Dist Mat shape 2308\n",
      "Element shape 5383\n",
      "(2308, 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hassa\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1176: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prob 2308\n",
      "Dist Mat shape 2308\n",
      "Element shape 5383\n",
      "(2308, 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hassa\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1176: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metric Manhattan\n",
      "time 3:09:35.490201\n",
      "measure Accuracy\n",
      "+----------------+--------------------+\n",
      "| Experiment No. |      DataSet1      |\n",
      "+----------------+--------------------+\n",
      "|       1        | 0.958838821490468  |\n",
      "|       2        | 0.9523396880415944 |\n",
      "|       3        | 0.9536395147313691 |\n",
      "|       4        | 0.9527729636048526 |\n",
      "|       5        | 0.9553726169844021 |\n",
      "|    Average     | 0.9545927209705372 |\n",
      "+----------------+--------------------+\n",
      "metric Manhattan\n",
      "time 3:09:35.490201\n",
      "measure Macro Precision\n",
      "+----------------+--------------------+\n",
      "| Experiment No. |      DataSet1      |\n",
      "+----------------+--------------------+\n",
      "|       1        | 0.9500584197248981 |\n",
      "|       2        | 0.937208506209642  |\n",
      "|       3        | 0.950990441798691  |\n",
      "|       4        | 0.9425889533722123 |\n",
      "|       5        | 0.9559944479990147 |\n",
      "|    Average     | 0.9473681538208915 |\n",
      "+----------------+--------------------+\n",
      "metric Manhattan\n",
      "time 3:09:35.490201\n",
      "measure Micro Precision\n",
      "+----------------+--------------------+\n",
      "| Experiment No. |      DataSet1      |\n",
      "+----------------+--------------------+\n",
      "|       1        | 0.958838821490468  |\n",
      "|       2        | 0.9523396880415944 |\n",
      "|       3        | 0.9536395147313691 |\n",
      "|       4        | 0.9527729636048526 |\n",
      "|       5        | 0.9553726169844021 |\n",
      "|    Average     | 0.9545927209705372 |\n",
      "+----------------+--------------------+\n",
      "metric Manhattan\n",
      "time 3:09:35.490201\n",
      "measure Macro Recall\n",
      "+----------------+--------------------+\n",
      "| Experiment No. |      DataSet1      |\n",
      "+----------------+--------------------+\n",
      "|       1        | 0.826897816014376  |\n",
      "|       2        | 0.7803680597826148 |\n",
      "|       3        | 0.8063390857627912 |\n",
      "|       4        | 0.7870965866664308 |\n",
      "|       5        | 0.7847007833988722 |\n",
      "|    Average     | 0.7970804663250171 |\n",
      "+----------------+--------------------+\n",
      "metric Manhattan\n",
      "time 3:09:35.490201\n",
      "measure Micro Recall\n",
      "+----------------+--------------------+\n",
      "| Experiment No. |      DataSet1      |\n",
      "+----------------+--------------------+\n",
      "|       1        | 0.958838821490468  |\n",
      "|       2        | 0.9523396880415944 |\n",
      "|       3        | 0.9536395147313691 |\n",
      "|       4        | 0.9527729636048526 |\n",
      "|       5        | 0.9553726169844021 |\n",
      "|    Average     | 0.9545927209705372 |\n",
      "+----------------+--------------------+\n",
      "metric Manhattan\n",
      "time 3:09:35.490201\n",
      "measure F Measure\n",
      "+----------------+--------------------+\n",
      "| Experiment No. |      DataSet1      |\n",
      "+----------------+--------------------+\n",
      "|       1        | 0.8607311540889022 |\n",
      "|       2        | 0.8057117506197072 |\n",
      "|       3        | 0.8425956414173559 |\n",
      "|       4        | 0.8246667705563484 |\n",
      "|       5        | 0.8215953550621676 |\n",
      "|    Average     | 0.8310601343488961 |\n",
      "+----------------+--------------------+\n",
      "metric Manhattan\n",
      "time 3:09:35.490201\n",
      "measure Micro F Measure\n",
      "+----------------+--------------------+\n",
      "| Experiment No. |      DataSet1      |\n",
      "+----------------+--------------------+\n",
      "|       1        | 0.958838821490468  |\n",
      "|       2        | 0.9523396880415944 |\n",
      "|       3        | 0.9536395147313691 |\n",
      "|       4        | 0.9527729636048526 |\n",
      "|       5        | 0.9553726169844021 |\n",
      "|    Average     | 0.9545927209705372 |\n",
      "+----------------+--------------------+\n",
      "metric Manhattan\n",
      "time 3:09:35.490201\n",
      "measure ROC\n",
      "+----------------+--------------------+\n",
      "| Experiment No. |      DataSet1      |\n",
      "+----------------+--------------------+\n",
      "|       1        | 0.909524405977292  |\n",
      "|       2        | 0.8855524113427653 |\n",
      "|       3        | 0.8983697477679924 |\n",
      "|       4        | 0.8890297478584896 |\n",
      "|       5        | 0.888156824546376  |\n",
      "|    Average     | 0.8941266274985832 |\n",
      "+----------------+--------------------+\n",
      "###############\n",
      "###############\n",
      "###############\n",
      "prob 2308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hassa\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\scipy\\spatial\\distance.py:720: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  dist = 1.0 - uv / np.sqrt(uu * vv)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dist Mat shape 2308\n",
      "Element shape 5383\n",
      "(2308, 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hassa\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1176: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "C:\\Users\\hassa\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1178: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 0 is out of bounds for axis 0 with size 0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-de249ffd2f59>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m   1264\u001b[0m         \u001b[0mtrain_labels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0myTrain\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1265\u001b[0m         \u001b[0mtest_labels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0myTest\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1266\u001b[1;33m         \u001b[0mclassify\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmetric\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmet\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1267\u001b[0m         \u001b[0msplit\u001b[0m\u001b[1;33m+=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1268\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-1-de249ffd2f59>\u001b[0m in \u001b[0;36mclassify\u001b[1;34m(metric, termOccurance, docOccurance)\u001b[0m\n\u001b[0;32m   1063\u001b[0m     \u001b[0mmicroFMeasure\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1064\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1065\u001b[1;33m     \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0mNBCombined\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtest_labels\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmetric\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1066\u001b[0m     \u001b[0mtime2\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1067\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-1-de249ffd2f59>\u001b[0m in \u001b[0;36mNBCombined\u001b[1;34m(train_data, train_labels, test_data, test_labels, metric)\u001b[0m\n\u001b[0;32m   1182\u001b[0m         \u001b[1;31m#print(\"combined value is\",totalValue)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1183\u001b[0m         \u001b[0mlblInd\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtotalValue\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtotalValue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1184\u001b[1;33m         \u001b[0mind1\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlblInd\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1185\u001b[0m        \u001b[1;31m# print(ind1)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1186\u001b[0m        \u001b[1;31m# print(lbl)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: index 0 is out of bounds for axis 0 with size 0"
     ]
    }
   ],
   "source": [
    "# importing all the required modules\n",
    "\n",
    "from importlib import reload\n",
    "import nltk\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer\n",
    "import os\n",
    "import errno\n",
    "import string\n",
    "from nltk.corpus import reuters\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import FreqDist\n",
    "from nltk.text import TextCollection\n",
    "import collections\n",
    "import numpy as np\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from prettytable import PrettyTable\n",
    "import time\n",
    "from datetime import timedelta\n",
    "from sklearn.metrics import recall_score,precision_score,average_precision_score,f1_score,accuracy_score,roc_auc_score\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics.cluster import homogeneity_score,completeness_score\n",
    "import statistics\n",
    "import math\n",
    "import sklearn.metrics \n",
    "from sklearn.model_selection import KFold\n",
    "import csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "import math\n",
    "from scipy.spatial import distance\n",
    "import statistics\n",
    "from scipy.stats import pearsonr,entropy\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.naive_bayes import MultinomialNB,GaussianNB\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from scipy.io import arff\n",
    "from tensorflow.keras.models import Sequential,Model\n",
    "from tensorflow.keras.layers import Dense,RNN,SimpleRNNCell,LSTM,Flatten,Dropout,Input\n",
    "\n",
    "\n",
    "\n",
    "from keras import layers\n",
    "from sklearn import svm\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import KFold\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "import re\n",
    "import string\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import gc\n",
    "\n",
    "\n",
    "\n",
    "def loadReutersData(documents,labels):\n",
    "    categories_list=['acq','crude','earn','grain','interest','money-fx','ship','trade']\n",
    "    docCount=0\n",
    "    for i in range(0,len(categories_list)):\n",
    "        category_docs = reuters.fileids(categories_list[i])\n",
    "        print (categories_list[i])\n",
    "        for document_id in reuters.fileids(categories_list[i]):\n",
    "            if(len(reuters.categories(document_id))==1):\n",
    "                content=str(reuters.raw(document_id))\n",
    "                soup = BeautifulSoup(content)\n",
    "                content=soup.get_text()\n",
    "                documents.append(content)\n",
    "                docCount+=1\n",
    "                labels.append(str(reuters.categories(document_id)))\n",
    "\n",
    "                \n",
    "def most_common(lst):\n",
    "    return max(set(lst), key=lst.count)\n",
    "def tokenize1(documents):\n",
    "    tokens=[]\n",
    "    content= documents\n",
    "    tokens=(word_tokenize(content))\n",
    "    tokens= [token.lower() for token in tokens ]\n",
    "    tokens = [token for token in tokens if token not in stopwords]\n",
    "    tokens= [token for token in tokens if token.isalpha()]\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "    tokens= [token for token in tokens if len(token)>3 ]\n",
    "    return tokens\n",
    "def count_values_in_range(a, range_min, range_max):\n",
    "\n",
    "    # \"between\" returns a boolean Series equivalent to left <= series <= right.\n",
    "    # NA values will be treated as False.\n",
    "    return ((range_min <= a) & (a <= range_max)).sum()\n",
    "def display_scores(vectorizer, tfidf_result):\n",
    "    scores = zip(vectorizer.get_feature_names(),\n",
    "                 np.asarray(tfidf_result.sum(axis=0)).ravel())\n",
    "def sorted_tfs(tfs,n):\n",
    "    doc,terms=tfs.shape\n",
    "    ind=(np.argsort(-(np.asarray(tfs.sum(axis=0)).ravel())))\n",
    "    scores=np.zeros((doc,n))\n",
    "    for i in range(0,len(documents)):\n",
    "        for j in range(0,n):\n",
    "            if(tfs[i,ind[j]]!=0):\n",
    "                scores[i,j]=tfs[i,ind[j]]\n",
    "    return scores\n",
    "\n",
    "def dislay_tfidf(vectorizer,tfidf_result):\n",
    "    print(vectorizer.get_feature_names())\n",
    "    print(tfidf_result)\n",
    "def Manhattan(doc1,doc2):\n",
    "    return distance.cityblock(doc1,doc2)                       \n",
    "def Euclidean(a, b):#distance\n",
    "    return distance.euclidean(a,b)\n",
    "def Minkowski(doc1,doc2):\n",
    "    return distance.minkowski(doc1,doc2) \n",
    "def Cosine(a, b):#distance\n",
    "    return distance.cosine(a,b)\n",
    "def Jaccard(a, b):#distance\n",
    "    return distance.jaccard(a,b)\n",
    "def EnhancedJaccard(a, b):#distance\n",
    "    a=[0 if x==0 else 1 for x in a]\n",
    "    b=[0 if x==0 else 1 for x in b]\n",
    "    return distance.jaccard(a,b)\n",
    "def PCC(a, b):\n",
    "    pcc, col=pearsonr(a,b)\n",
    "    return abs(pcc)\n",
    "def extendedJaccard(a,b):\n",
    "    vector1=[0 if x==0 else 1 for x in a]\n",
    "    vector2=[0 if x==0 else 1 for x in b]\n",
    "    dot=np.dot(vector1,vector2)\n",
    "    sum1=np.sum(vector1)\n",
    "    sum2=np.sum(vector2)\n",
    "    denom=math.sqrt(sum1)+math.sqrt(sum2)-dot\n",
    "    if(denom!=0):\n",
    "        return 1.0 - (float(dot)/(denom))\n",
    "    else:\n",
    "        return -1\n",
    "def bhatta(a,b):\n",
    "\n",
    "    length=len(a)\n",
    "    score = 0;\n",
    "    score=np.sum(np.sqrt( np.multiply(a,b) ))\n",
    "    distance=-1*np.log(score)\n",
    "    return distance;        \n",
    "\n",
    "def JS(a, b):\n",
    "   # normalize\n",
    "    p = a/ np.sum(a)\n",
    "    q = b/ np.sum(b)\n",
    "    m = (p + q) / 2\n",
    "    return (entropy(p, m) + entropy(q, m)) / 2\n",
    "\n",
    "def Pairwise(a,b):\n",
    "    percentage=1 #100 percent\n",
    "    K1=np.count_nonzero(a)\n",
    "    K2=np.count_nonzero(b)\n",
    "    k=percentage*min(K1,K2)\n",
    "   # setA=set((-a).argsort()[:k])\n",
    "   # setB=set((-b).argsort()[:k])\n",
    "    \n",
    "    setA=set(np.argpartition(a, len(a)-1 - k)[-k:])\n",
    "    setB=set(np.argpartition(b, len(b)-1 - k)[-k:])\n",
    "    union=setA.union(setB)\n",
    "    elementsA=[a[ind] for ind in union]\n",
    "    elementsB=[b[ind] for ind in union]\n",
    "    dist= distance.cosine(elementsA, elementsB)\n",
    "    return dist\n",
    "\n",
    "def Dice(a, b):\n",
    "    a=[(a.astype(bool)).astype(int)]\n",
    "    b=[(b.astype(bool)).astype(int)]\n",
    "    return distance.dice(a,b)\n",
    "def Extended_Dice(a, b):\n",
    "    a=[0 if x==0 else 1 for x in a]\n",
    "    b=[0 if x==0 else 1 for x in b]\n",
    "    sim=(2*np.dot(a,b))/(sum(a)**2 + sum(b)**2)\n",
    "    return sim\n",
    "def simIT(a,b,termOcc,docOcc):\n",
    "    p1= np.divide(a,termOcc) \n",
    "    p2= np.divide(b,termOcc)\n",
    "    minVal=np.minimum(p1,p2)\n",
    "    pi=np.log((np.array(docOcc)/totalDocs))\n",
    "    sIT=(2*np.sum(np.multiply(minVal,pi)))/((np.sum(np.multiply(p1,pi)))+(np.sum(np.multiply(p2,pi))))\n",
    "    return sIT\n",
    "\n",
    "def ISC(doc1,doc2): \n",
    "    dot=sum(np.sqrt(np.multiply(doc1,doc2)))\n",
    "    isc=dot /( math.sqrt(np.linalg.norm(doc1, ord=1))*math.sqrt(np.linalg.norm(doc2, ord=1)))\n",
    "    return isc\n",
    "\n",
    "def SP(doc1,doc2,N):\n",
    "    \n",
    "    a=set(np.nonzero(doc1)[0])  #indices of non zero elements in doc1\n",
    "    b=set(np.nonzero(doc2)[0])  #indices of non zero elements in doc2\n",
    "    nonzeroTerm=list(a.intersection(b))\n",
    "    minArr=np.minimum(doc1[nonzeroTerm],doc2[nonzeroTerm])\n",
    "    maxArr=np.maximum(doc1[nonzeroTerm],doc2[nonzeroTerm])\n",
    "    ln=len(nonzeroTerm)\n",
    "    docCount=np.zeros(ln)\n",
    "    aData=allData[:,nonzeroTerm] #extracting data with only feature indices of doc1 intersection  doc2\n",
    "    for ti in range(0,ln):\n",
    "        docCount[ti]=count_values_in_range(aData[:,ti], minArr[ti], maxArr[ti]) #count values which lies between min and max\n",
    "    normFactor= len(a.union(b))\n",
    "    dCount=np.array(docCount[np.nonzero(docCount)[0]])\n",
    "    SP_val=0\n",
    "    if(normFactor!=0):\n",
    "        SP_val=sum(np.log(totalDocs/dCount))\n",
    "        SP_val = (SP_val/normFactor)\n",
    "    return SP_val\n",
    "\n",
    "def PDSM(doc1,doc2):\n",
    "    a=set(np.nonzero(doc1)[0])  #indices of non zero elements in doc1\n",
    "    b=set(np.nonzero(doc2)[0])  #indices of non zero elements in doc2\n",
    "    intersection=sum(np.minimum(doc1,doc2))\n",
    "    union=sum(np.maximum(doc1,doc2))\n",
    "    PF=len(a.intersection(b))\n",
    "    M=len(doc1)\n",
    "    AF=len(set(range(0,M))-(a.union(b)))\n",
    "    psdm=(intersection/union)*((PF+1)/(M-AF+1))\n",
    "    return psdm\n",
    "def EPDSM(doc1,doc2):\n",
    "    a=set(np.nonzero(doc1)[0])  #indices of non zero elements in doc1\n",
    "    b=set(np.nonzero(doc2)[0])  #indices of non zero elements in doc2\n",
    "    intersection=np.sum(np.minimum(doc1,doc2))\n",
    "    union=np.sum(np.maximum(doc1,doc2))\n",
    "    PF=len(a.intersection(b))\n",
    "    M=len(doc1)\n",
    "    AF=M-len(a.union(b))\n",
    "    psdm=(intersection/union)*((PF+1)/(M-AF+1))\n",
    "    return psdm\n",
    "def EEnhancedJaccard(a, b):#similarity\n",
    "    a=set(np.nonzero(a)[0])  #indices of non zero elements in doc1\n",
    "    b=set(np.nonzero(b)[0])  #indices of non zero elements in doc2\n",
    "    union=a.union(b)\n",
    "    intersection=a.intersection(b)\n",
    "    sim=len(intersection)/len(union)#similarity\n",
    "    return sim\n",
    "def smtp(doc1,doc2,var):\n",
    "    lemda=0.0001\n",
    "    a=set(np.nonzero(doc1)[0])  #indices of non zero elements in doc1\n",
    "    b=set(np.nonzero(doc2)[0])  #indices of non zero elements in doc2\n",
    "    intersection=a.intersection(b) # indices where both docs have non zero elements\n",
    "    union=a.union(b) # indices where either doc has non zero elements\n",
    "    d1=np.array(list(a-intersection)) # doc1 !=0 and doc2=0\n",
    "    d2=np.array(list(b-intersection)) # doc1 =0 and doc2!=0\n",
    "    doc1=np.array(doc1)\n",
    "    doc2=np.array(doc2)\n",
    "    Nstar=0\n",
    "    intersection=np.array(list(intersection))\n",
    "    if (len(intersection)>0):\n",
    "        term1=np.exp(-1*np.square(( doc1[intersection]-doc2[intersection] )/var[intersection]))\n",
    "        Nstar=sum(0.5* (1+term1)) +lemda* -1 *(len(d1)+len(d2))\n",
    "    else:\n",
    "        Nstar=lemda* -1 *(len(d1)+len(d2))   \n",
    "    Nunion=len(intersection)+len(d1)+len(d2)\n",
    "    smtp=0\n",
    "    if Nunion!=0:\n",
    "        smtp=((Nstar/Nunion)+lemda)/(1+lemda)\n",
    "    return smtp\n",
    "def EISC(doc1,doc2): \n",
    "    dot=np.sum(np.sqrt(np.multiply(doc1,doc2)))\n",
    "    isc=dot /( math.sqrt(np.linalg.norm(doc1, ord=1))*math.sqrt(np.linalg.norm(doc2, ord=1)))\n",
    "    return isc\n",
    "\n",
    "def NSMT(doc1,doc2):\n",
    "    Dij=Nij=Di=Ni=Nj=Dj=0\n",
    "    a=set(np.nonzero(doc1)[0])  #indices of non zero elements in doc1\n",
    "    b=set(np.nonzero(doc2)[0])  #indices of non zero elements in doc2\n",
    "    intersection=a.intersection(b)# indices where both docs have non zero elements\n",
    "    a=np.array(list(a-intersection)) \n",
    "    b=np.array(list(b-intersection))\n",
    "    intersection=np.array(list(intersection))\n",
    "    if len(intersection)>0:\n",
    "      #  prod=np.multiply(doc1[intersection],doc2[intersection])\n",
    "        Dij=np.dot(doc1[intersection],doc2[intersection])#sum(prod)\n",
    "    if len(a)>0:\n",
    "        Di=sum(doc1[a])\n",
    "    if len(b)>0:\n",
    "        Dj=sum(doc2[b])\n",
    "    Nij=len(intersection)\n",
    "    Ni=len(a)\n",
    "    Nj=len(b)\n",
    "    Nsmt=0\n",
    "    if (Ni*Di+Dj*Nj)!=0:\n",
    "        Nsmt=(Nij*Dij)/(Ni*Di+Dj*Nj)\n",
    "    return Nsmt\n",
    "def CSMB(doc1,doc2,alpha=0.5,Beta=0.5):\n",
    "    sim1=CSM_P1(doc1,doc2)\n",
    "    sim2=CSM_P2(doc1,doc2)\n",
    "    simValue=alpha*sim1+Beta*sim2\n",
    "    return simValue\n",
    "def CSMB_MinMax(doc1,doc2,alpha=0.5,Beta=0.5):\n",
    "    sim1=CSM_P1(doc1,doc2)\n",
    "    sim2=CSM_P2(doc1,doc2)\n",
    "    simValue=alpha*max(sim1,sim2)+Beta*min(sim1,sim2)\n",
    "    return simValue\n",
    "def BLAB_SM(doc1,doc2):\n",
    "    sim1=CSMB(doc1,doc2,alpha=0.5,Beta=0.5)# CSMB10\n",
    "    return sim1\n",
    "def ZSM(doc1,doc2):\n",
    "    Dij=Nij=Di=Ni=Nj=Dj=0\n",
    "    a=set(np.nonzero(doc1)[0])  #indices of non zero elements in doc1\n",
    "    b=set(np.nonzero(doc2)[0])  #indices of non zero elements in doc2\n",
    "    intersection=a.intersection(b)# indices where both docs have non zero elements\n",
    "    intersection=np.array(list(intersection))\n",
    "    if len(intersection)>0:\n",
    "      #  prod=np.multiply(doc1[intersection],doc2[intersection])\n",
    "        Dij=np.dot(doc1[intersection],doc2[intersection])#sum(prod)\n",
    "    Nij=len(intersection)\n",
    "    zsm=(Nij*Dij)/(np.sum(doc1)*np.sum(doc2))\n",
    "    return  zsm\n",
    "def CSM_P1(doc1,doc2):\n",
    "    simValue=0 \n",
    "    if ((not np.any(doc1)) or (not np.any( doc2))):   \n",
    "        simValue=0  \n",
    "    else:\n",
    "        simValue=0\n",
    "        N=len(doc1)#total_features;\n",
    "        a=set(np.nonzero(doc1)[0])  \n",
    "        b=set(np.nonzero(doc2)[0])   \n",
    "        Nab=len(a.intersection(b))\n",
    "        F=len(a.union(b))-Nab\n",
    "        simValue=(1-F/N)\n",
    "    return simValue\n",
    "def CSM_P2(doc1,doc2):\n",
    "    simVal=0\n",
    "    if ((not np.any(doc1)) or (not np.any( doc2))):   \n",
    "        simValue=0  \n",
    "    else:\n",
    "        simValue=0\n",
    "        a=set(np.nonzero(doc1)[0])  \n",
    "        b=set(np.nonzero(doc2)[0])   \n",
    "        Na=len(a)\n",
    "        Nb=len(b)\n",
    "        Nab=len(a.intersection(b))\n",
    "        simVal=(2*Nab)/(Na+Nb)\n",
    "    return simVal\n",
    "def DDSMa(doc1,doc2):\n",
    "    sim=1-(np.sum(np.abs(doc1-doc2))/np.sum(doc1+doc2))\n",
    "    return sim\n",
    "def DDSMb(doc1,doc2):\n",
    "    sim =1-(np.sum(np.square(doc1-doc2))/np.sum(np.square(doc1+doc2)))\n",
    "    return sim\n",
    "def DDSMc(doc1,doc2):\n",
    "    doc3=np.square(doc1)\n",
    "    doc4=np.square(doc2)\n",
    "    sim= 1-(np.sum(np.abs(doc3-doc4))/np.sum(np.square(doc1+doc2)))\n",
    "    return sim\n",
    "def EN1_DDSMa(doc1,doc2):\n",
    "    return (DDSMa(doc1,doc2)*CSM_P1(doc1,doc2))\n",
    "def EN_DDSMb(doc1,doc2):\n",
    "    a=set(np.nonzero(doc1)[0])  \n",
    "    b=set(np.nonzero(doc2)[0])\n",
    "    SF=len(list(a.intersection(b)))\n",
    "    N=len(doc1)\n",
    "    return (DDSMb(doc1,doc2)*(SF+1)/(N+1))\n",
    "def EN_DDSMc(doc1,doc2):\n",
    "    a=set(np.nonzero(doc1)[0])  \n",
    "    b=set(np.nonzero(doc2)[0])\n",
    "    SF=len(list(a.intersection(b)))\n",
    "    N=len(doc1)\n",
    "    return (DDSMc(doc1,doc2)*(SF+1)/(N+1))\n",
    "def BASM(doc1,doc2):\n",
    "    return CSM_P2(doc1,doc2) \n",
    "def ESTB_SM(doc1,doc2):\n",
    "    a=set(np.nonzero(doc1)[0])  \n",
    "    b=set(np.nonzero(doc2)[0])\n",
    "    intersection=np.array(list(a.intersection(b)))\n",
    "    comp1=np.array(list(a-b))\n",
    "    comp2=np.array(list(b-a))\n",
    "    X,Y,D1,D2,sim=0,0,0,0,0  \n",
    "    sim=0\n",
    "    if len(intersection)>0:\n",
    "        X=np.sum(doc1[intersection])\n",
    "        Y=np.sum(doc2[intersection])\n",
    "        if len(comp1)>0:\n",
    "            D1=np.sum(doc1[comp1])\n",
    "        if len(comp2)>0:\n",
    "            D2=np.sum(doc2[comp2])\n",
    "        if len(intersection)>0:\n",
    "            sim=1/(1+((D1/X)+(D2/Y)))\n",
    "    return sim \n",
    "def ESTBSM_Sim2(doc1,doc2):\n",
    "    sim= (1-ESTB_SM(doc1,doc2))*CSM_P2(doc1,doc2)\n",
    "    return 1-sim\n",
    "def ESTB_V1(doc1,doc2):\n",
    "    return (1-ESTB_SM(doc1,doc2))+CSM_P2(doc1,doc2)\n",
    "def ESTB_V2(doc1,doc2):\n",
    "    return (1-ESTB_SM(doc1,doc2))*CSM_P2(doc1,doc2)*(1-ANSM(doc1,doc2))\n",
    "def ESTB_V3(doc1,doc2):\n",
    "    estb=1-ESTB_SM(doc1,doc2)\n",
    "    ansm=ANSM(doc1,doc2)\n",
    "    return ((estb+ansm)/2)*CSM_P2(doc1,doc2)\n",
    "def EMX1(doc1,doc2):\n",
    "    a=set(np.nonzero(doc1)[0])  \n",
    "    b=set(np.nonzero(doc2)[0])\n",
    "    intersection=a.intersection(b)\n",
    "    sim=0\n",
    "    if len(intersection)>0:\n",
    "        meanDiff=abs(np.mean(doc1)-np.mean(doc2))\n",
    "        sim=1/(1+math.exp(-1*meanDiff))\n",
    "    return sim\n",
    "def EMX2(doc1,doc2):\n",
    "    a=set(np.nonzero(doc1)[0])  \n",
    "    b=set(np.nonzero(doc2)[0])\n",
    "    intersection=a.intersection(b)\n",
    "    sim=0\n",
    "    if len(intersection)>0:\n",
    "        meanDiff=abs(np.mean(doc1)-np.mean(doc2))\n",
    "        stdDiff=abs(np.std(doc1)-np.std(doc2))\n",
    "        sim=1/(1+math.exp(-1*meanDiff*stdDiff))\n",
    "    return sim \n",
    "def EMX7(doc1,doc2):\n",
    "    sim=EMX1(doc1,doc2)\n",
    "    if sim>0:\n",
    "        sim=sim*(1-ESTB_SM(doc1,doc2))*CSM_P2(doc1,doc2)\n",
    "    return sim \n",
    "def EMX13(doc1,doc2):\n",
    "    sim=EMX2(doc1,doc2)\n",
    "    if sim>0:\n",
    "        sim=sim*(1-ESTB_SM(doc1,doc2))*CSM_P2(doc1,doc2)\n",
    "    return sim \n",
    "def PCC_Sim2(doc1,doc2):#distance\n",
    "    return (1-PCC(doc1,doc2))*CSM_P2(doc1,doc2)\n",
    "def ANSM(doc1,doc2):\n",
    "    a=set(np.nonzero(doc1)[0])  #indices of non zero elements in doc1\n",
    "    b=set(np.nonzero(doc2)[0])  #indices of non zero elements in doc2\n",
    "    com=np.array(list(a.intersection(b)))\n",
    "    sim=0\n",
    "    if len(com)>0:\n",
    "        sim=np.sum(np.sum(doc1[com]+doc2[com]))/(np.sum(doc1)+np.sum(doc2))\n",
    "        \n",
    "    return sim   \n",
    "def ANSM_V1(doc1,doc2):\n",
    "    a=set(np.nonzero(doc1)[0])  #indices of non zero elements in doc1\n",
    "    b=set(np.nonzero(doc2)[0])  #indices of non zero elements in doc2\n",
    "    SP=len(a.intersection(b))\n",
    "    N=len(doc1)\n",
    "    return 1-((1-ANSM(doc1,doc2))*((SP+1)/(N+1)))\n",
    "def ANSM_V2(doc1,doc2):\n",
    "    return (1-ANSM(doc1,doc2))*CSM_P2(doc1,doc2)\n",
    "def ANSM_V3(doc1,doc2):\n",
    "    sim= ((1-ANSM(doc1,doc2))+CSM_P2(doc1,doc2))/2\n",
    "    return sim\n",
    "def KL(a, b):\n",
    "    return entropy(a,b)\n",
    "\n",
    "def MSTB_SM(doc1,doc2):\n",
    "    a=set(np.nonzero(doc1)[0])  \n",
    "    b=set(np.nonzero(doc2)[0])\n",
    "    intersection=np.array(list(a.intersection(b)))\n",
    "    sim=0\n",
    "    if len(intersection)>0:\n",
    "        ints=np.sum(np.intersect1d(doc1,doc2))\n",
    "        D1=np.sum(np.unique(doc1))-ints\n",
    "        D2=np.sum(np.unique(doc2))-ints\n",
    "        X,Y=0,0  \n",
    "        X=np.sum(doc1[intersection])\n",
    "        Y=np.sum(doc2[intersection])\n",
    "        a=np.array(list(a))\n",
    "        b=np.array(list(b))\n",
    "        Z1,Z2=0,0\n",
    "        Z1=np.sum(doc1[a])\n",
    "        Z2=np.sum(doc2[b]) \n",
    "        sim=((X*Y)/(Z1*Z2))*(1-((D1*D2)/(Z1*Z2)))\n",
    "    return sim \n",
    "def STB_SM(doc1,doc2):\n",
    "    a=set(np.nonzero(doc1)[0])  \n",
    "    b=set(np.nonzero(doc2)[0])\n",
    "    intersection=np.array(list(a.intersection(b)))\n",
    "    comp1=a-b\n",
    "    comp2=b-a   \n",
    "    comp1=np.array(list(comp1))\n",
    "    comp2=np.array(list(comp2))\n",
    "    a=np.array(list(a))\n",
    "    b=np.array(list(b))\n",
    "    X,Y,D1,D2,Z1,Z2,sim=0,0,0,0,0,0,0\n",
    "    if len(intersection)>0:\n",
    "        X=np.sum(doc1[intersection])\n",
    "        Y=np.sum(doc2[intersection])\n",
    "    if len(comp1)>0:\n",
    "        D1=np.sum(doc1[comp1])\n",
    "    if len(comp2)>0:\n",
    "        D2=np.sum(doc2[comp2])\n",
    "    if len(a)>0:\n",
    "        Z1=np.sum(doc1[a])\n",
    "    if len(b)>0:\n",
    "        Z2=np.sum(doc2[b]) \n",
    "    if Z1!=0 and Z2!=0:\n",
    "        sim=((X*Y)/(Z1*Z2))*(1-((D1*D2)/(Z1*Z2)))\n",
    "    return sim\n",
    "def DSM(doc1,doc2,var):\n",
    "    lemda=1\n",
    "    a=set(np.nonzero(doc1)[0])  #indices of non zero elements in doc1\n",
    "    b=set(np.nonzero(doc2)[0])  #indices of non zero elements in doc2\n",
    "    intersection=a.intersection(b) # indices where both docs have non zero elements\n",
    "    union=a.union(b) # indices where either doc has non zero elements\n",
    "    doc1=np.array(doc1)\n",
    "    doc2=np.array(doc2)\n",
    "    Nstar=0\n",
    "    intersection=np.array(list(intersection))\n",
    "    if (len(intersection)>0):\n",
    "        term1=np.exp(-1*( doc1[intersection]-doc2[intersection] )/var[intersection])\n",
    "        Nstar=sum(0.5* (1+term1)) \n",
    "    else:\n",
    "        Nstar=lemda* -1 \n",
    "    Nunion=len(union)\n",
    "    dsm=0\n",
    "    if Nunion!=0:\n",
    "        dsm=((Nstar/Nunion)+lemda)/(1+lemda)\n",
    "   \n",
    "    return dsm\n",
    "def TA(doc1,doc2):\n",
    "    a=np.sqrt(doc1.dot(doc1))\n",
    "    b=np.sqrt(doc2.dot(doc2))\n",
    "    dot=np.dot(doc1,doc2)**2\n",
    "    sim=0\n",
    "    if a<=b:\n",
    "        sim=dot/(a*(b**3))\n",
    "    else:\n",
    "        sim=1-(dot/(b*(a**3)))\n",
    "    return sim\n",
    "\n",
    "\n",
    "######################Enhnaced Measures#################################################\n",
    "def EExtendedJaccard(a,b):\n",
    "    vector1=set(np.where(a!=0)[0])\n",
    "    vector2=set(np.where(b!=0)[0])\n",
    "    dot=len(vector1.intersection(vector2))\n",
    "    sum1=len(vector1)\n",
    "    sum2=len(vector2)\n",
    "    denom=math.sqrt(sum1)+math.sqrt(sum2)-dot\n",
    "    if(denom!=0):\n",
    "        return 1.0 - (float(dot)/(denom))\n",
    "    else:\n",
    "        return -1\n",
    "    \n",
    "def EPairwise(a,b):\n",
    "    percentage=1 #100 percent\n",
    "    K1=np.count_nonzero(a)\n",
    "    K2=np.count_nonzero(b)\n",
    "    k=percentage*min(K1,K2)\n",
    "    setA=set(np.argpartition(a, len(a)-1 - k)[-k:])\n",
    "    setB=set(np.argpartition(b, len(b) -1- k)[-k:])\n",
    "    union=np.array(list(setA.union(setB)))\n",
    "    elementsA=a[union]\n",
    "    elementsB=b[union]\n",
    "    return distance.cosine(elementsA, elementsB)\n",
    "\n",
    "def EJS(a, b):\n",
    "    p = a/ np.sum(a)\n",
    "    q = b/ np.sum(b)\n",
    "    m = np.add(p,q) / 2\n",
    "    return (entropy(p, m) + entropy(q, m)) / 2\n",
    "\n",
    "def EDice(doc1,doc2):\n",
    "    a=set(list(np.nonzero(doc1!=0)[0]))  #indices of non zero elements in doc1\n",
    "    b=set(list(np.nonzero(doc2!=0)[0]))  #indices of non zero elements in doc2\n",
    "    intr=len(a.intersection(b))\n",
    "    aComp=len(a-b)\n",
    "    bComp=len(b-a)\n",
    "    sim=0\n",
    "    if (intr+aComp+bComp)!=0:\n",
    "        sim=2*(intr/(2*(intr+aComp+bComp)))\n",
    "    return sim\n",
    "def EExtendedDice(doc1, doc2):\n",
    "    a=set(list(np.nonzero(doc1!=0)[0]))  #indices of non zero elements in doc1\n",
    "    b=set(list(np.nonzero(doc2!=0)[0]))  #indices of non zero elements in doc2\n",
    "    intr=len(a.intersection(b))\n",
    "    sim=(2*intr)/(len(a)**2 + len(b)**2)\n",
    "    return sim\n",
    "def EPDSM(doc1,doc2):\n",
    "    a=set(np.nonzero(doc1!=0)[0])  #indices of non zero elements in doc1\n",
    "    b=set(np.nonzero(doc2!=0)[0])  #indices of non zero elements in doc2\n",
    "    intersection=np.sum(np.minimum(doc1,doc2))\n",
    "    union=np.sum(np.maximum(doc1,doc2))\n",
    "    PF=len(a.intersection(b))\n",
    "    M=len(doc1)\n",
    "    AF=M-len(a.union(b))\n",
    "    psdm=(intersection/union)*((PF+1)/(M-AF+1))\n",
    "    return psdm\n",
    "def esmtp(doc1,doc2,var):\n",
    "    lemda=0.0001\n",
    "    a=set(list(np.nonzero(doc1 != 0)[0]))  #indices of non zero elements in doc1\n",
    "    b=set(list(np.nonzero(doc2 != 0)[0]))  #indices of non zero elements in doc2\n",
    "    intersection=a.intersection(b) # indices where both docs have non zero elements\n",
    "    union=a.union(b) # indices where either doc has non zero elements\n",
    "    l1=len(a-intersection) # doc1 !=0 and doc2=0\n",
    "    l2=len(b-intersection) # doc1 =0 and doc2!=0\n",
    "    Nstar=0\n",
    "    intersection=np.array(list(intersection))\n",
    "    if (len(intersection)>0):\n",
    "        term1=np.exp(-1*np.square(( doc1[intersection]-doc2[intersection] )/var[intersection]))\n",
    "        Nstar=np.sum(0.5* (1+term1)) +lemda* -1 *(l1+l2)\n",
    "    else:\n",
    "        Nstar=lemda* -1 *(l1+l2)   \n",
    "    Nunion=len(intersection)+l1+l2\n",
    "    smtp=0\n",
    "    if NUnion!=0:\n",
    "        smtp=((Nstar/Nunion)+lemda)/(1+lemda)\n",
    "    return smtp\n",
    "def ENSMT(doc1,doc2):\n",
    "    Dij=Nij=Di=Ni=Nj=Dj=0\n",
    "    a=set(list(np.nonzero(doc1 != 0)[0]))  #indices of non zero elements in doc1\n",
    "    b=set(list(np.nonzero(doc2 != 0)[0]))  #indices of non zero elements in doc2\n",
    "    intersection=a.intersection(b)# indices where both docs have non zero elements\n",
    "    a=np.array(list(a-intersection)) \n",
    "    b=np.array(list(b-intersection))\n",
    "    intersection=np.array(list(intersection))\n",
    "    if len(intersection)>0:\n",
    "      #  prod=np.multiply(doc1[intersection],doc2[intersection])\n",
    "        Dij=np.dot(doc1[intersection],doc2[intersection])#sum(prod)\n",
    "    if len(a)>0:\n",
    "        Di=np.sum(doc1[a])\n",
    "    if len(b)>0:\n",
    "        Dj=np.sum(doc2[b])\n",
    "    Nij=len(intersection)\n",
    "    Ni=len(a)\n",
    "    Nj=len(b)\n",
    "    Nsmt=0\n",
    "    if (Ni*Di+Dj*Nj)!=0:\n",
    "        Nsmt=(Nij*Dij)/(Ni*Di+Dj*Nj)\n",
    "    return Nsmt\n",
    "\n",
    "def EBLAB_SM(doc1,doc2):\n",
    "    return 0.5*(ECSM_P1(doc1,doc2)+ECSM_P2(doc1,doc2))\n",
    "    '''\n",
    "    if dataset==\"reuters\":\n",
    "        sim1=ECSMB_MinMax(doc1,doc2,alpha=0.7,Beta=0.3)#CSMB12\n",
    "    else:\n",
    "        sim1=ECSMB(doc1,doc2,alpha=0.9,Beta=0.1)# CSMB10\n",
    "    \n",
    "    return sim1\n",
    "    '''\n",
    "def EESTB_SM(doc1,doc2):\n",
    "    a=set(list(np.nonzero(doc1 != 0)[0]))  #indices of non zero elements in doc1\n",
    "    b=set(list(np.nonzero(doc2 != 0)[0]))  #indices of non zero elements in doc2\n",
    "    intersection= np.array(list(a.intersection(b)))\n",
    "    comp1=np.array(list(a-b))\n",
    "    comp2=np.array(list(b-a))\n",
    "    D1=D2=sim=0                   \n",
    "    if len(intersection)>0:\n",
    "        X=np.sum(doc1[intersection])\n",
    "        Y=np.sum(doc2[intersection])\n",
    "        if len(comp1)>0:\n",
    "            D1=np.sum(doc1[comp1])\n",
    "        if len(comp2)>0:\n",
    "            D2=np.sum(doc2[comp2])\n",
    "        sim=1/(1+((D1/X)+(D2/Y)))\n",
    "    return sim\n",
    "\n",
    "\n",
    "def ECSM_P2(doc1,doc2):\n",
    "    a=set(list(np.nonzero(doc1 != 0)[0]))  #indices of non zero elements in doc1\n",
    "    b=set(list(np.nonzero(doc2 != 0)[0]))  #indices of non zero elements in doc2NSMT\n",
    "    sim=0\n",
    "    if (len(a)+len(b))!=0:\n",
    "        sim=(2*len(a.intersection(b)))/(len(a)+len(b))\n",
    "    return sim\n",
    "\n",
    "\n",
    "\n",
    "def EEMX1(doc1,doc2):\n",
    "    a=set(np.nonzero(doc1!=0)[0])  \n",
    "    b=set(np.nonzero(doc2!=0)[0])\n",
    "    intersection=a.intersection(b)\n",
    "    intersection=a.intersection(b)\n",
    "    sim=0\n",
    "    if len(intersection)>0:\n",
    "        meanDiff=abs(np.mean(doc1)-np.mean(doc2))\n",
    "        sim=1/(1+math.exp(-1*meanDiff))\n",
    "    return sim\n",
    "\n",
    "\n",
    "def EEMX2(doc1,doc2):\n",
    "    a=set(np.nonzero(doc1!=0)[0])  \n",
    "    b=set(np.nonzero(doc2!=0)[0])\n",
    "    intersection=a.intersection(b)\n",
    "    sim=0\n",
    "    if len(intersection)>0:\n",
    "        meanDiff=abs(np.mean(doc1)-np.mean(doc2))\n",
    "        stdDiff=abs(np.std(doc1)-np.std(doc2))\n",
    "        sim=1/(1+math.exp(-1*meanDiff*stdDiff))\n",
    "    return sim \n",
    "\n",
    "def EEMX7(doc1,doc2):\n",
    "    sim=EEMX1(doc1,doc2)\n",
    "    if sim>0:\n",
    "        sim=sim*(1-EESTB_SM(doc1,doc2))*ECSM_P2(doc1,doc2)\n",
    "    return sim\n",
    "def EEMX13(doc1,doc2):\n",
    "    sim=EEMX2(doc1,doc2)\n",
    "    if sim>0:\n",
    "        sim=sim*(1-EESTB_SM(doc1,doc2))*ECSM_P2(doc1,doc2)\n",
    "    return sim \n",
    "\n",
    "def EMSTB_SM(doc1,doc2):\n",
    "    a=np.nonzero(doc1 != 0)[0]  #indices of non zero elements in doc1\n",
    "    b=np.nonzero(doc2 != 0)[0]  #indices of non zero elements in doc2\n",
    "    newDoc1=doc1[a]\n",
    "    newDoc2=doc2[b]\n",
    "    intersection=np.intersect1d(a,b)\n",
    "    sim=0\n",
    "    if len(intersection)>0:\n",
    "        ints=np.sum(np.intersect1d(doc1,doc2))\n",
    "        D1=np.sum(np.unique(newDoc1))-ints\n",
    "        D2=np.sum(np.unique(newDoc2))-ints \n",
    "        X=np.sum(doc1[intersection])\n",
    "        Y=np.sum(doc2[intersection])\n",
    "        Z1=np.sum(newDoc1)\n",
    "        Z2=np.sum(newDoc2) \n",
    "        sim=((X*Y)/(Z1*Z2))*(1-((D1*D2)/(Z1*Z2)))\n",
    "    return sim \n",
    "\n",
    "def ECSM_P1(doc1,doc2):\n",
    "    simValue=0\n",
    "    N=len(doc1)#total_features;\n",
    "    a=set(list(np.nonzero(doc1 != 0)[0]))  #indices of non zero elements in doc1\n",
    "    b=set(list(np.nonzero(doc2 != 0)[0]))  #indices of non zero elements in doc2NSMT\n",
    "    Nab=len(a.intersection(b))\n",
    "    F=len(a.union(b))-Nab\n",
    "    simValue=(1-F/N)\n",
    "    return simValue\n",
    "def DDSMa(doc1,doc2):\n",
    "    return 1-(np.sum(np.abs(doc1-doc2))/np.sum(doc1+doc2))\n",
    "def DDSMb(doc1,doc2):\n",
    "    return 1-(np.sum(np.square(doc1-doc2))/np.sum(np.square(doc1+doc2)))\n",
    "def DDSMc(doc1,doc2):\n",
    "    doc3=np.square(doc1)\n",
    "    doc4=np.square(doc2)\n",
    "    return 1-(np.sum(np.abs(doc3-doc4))/np.sum(np.square(doc1+doc2)))\n",
    "\n",
    "def EEN1_DDSMa(doc1,doc2):\n",
    "    return DDSMa(doc1,doc2)*ECSM_P1(doc1,doc2)\n",
    "def EEN_DDSMb(doc1,doc2):\n",
    "    a=set(list(np.nonzero(doc1 != 0)[0]))  #indices of non zero elements in doc1\n",
    "    b=set(list(np.nonzero(doc2 != 0)[0]))  #indices of non zero elements in doc2\n",
    "    SF=len(a.intersection(b))\n",
    "    N=len(doc1)\n",
    "    return DDSMb(doc1,doc2)*(SF+1)/(N+1)\n",
    "def EEN_DDSMc(doc1,doc2):\n",
    "    a=set(list(np.nonzero(doc1 != 0)[0]))  #indices of non zero elements in doc1\n",
    "    b=set(list(np.nonzero(doc2 != 0)[0]))  #indices of non zero elements in doc2\n",
    "    SF=len(a.intersection(b))\n",
    "    sim=1-(DDSMc(doc1,doc2)*(SF+1)/(len(doc1)+1))\n",
    "    return sim\n",
    "\n",
    "\n",
    "def EANSM(doc1,doc2):\n",
    "    a=np.nonzero(doc1 != 0)[0] #indices of non zero elements in doc1\n",
    "    b=np.nonzero(doc2 != 0)[0]  #indices of non zero elements in doc2\n",
    "    com=np.intersect1d(a,b)\n",
    "    sim=0\n",
    "    if len(com)>0:\n",
    "        sim=np.sum(doc1[com]+doc2[com])/np.sum(doc1+doc2)\n",
    "    return sim  \n",
    "def EANSM_V3(doc1,doc2):\n",
    "    return (EANSM(doc1,doc2)+ECSM_P2(doc1,doc2))/2\n",
    "\n",
    "def EZSM(doc1,doc2):\n",
    "    Dij=Nij=Di=Ni=Nj=Dj=0\n",
    "    a=np.nonzero(doc1 != 0)[0]  #indices of non zero elements in doc1\n",
    "    b=np.nonzero(doc2 != 0)[0]  #indices of non zero elements in doc2\n",
    "   # sum1=np.sum(doc1[a])\n",
    "    #sum2=np.sum(doc2[b])\n",
    "    a=set(list(a))\n",
    "    b=set(list(b)) \n",
    "    intersection=a.intersection(b)# indices where both docs have non zero elements\n",
    "    intersection=np.array(list(intersection))\n",
    "    Nij=len(intersection)\n",
    "    if Nij>0:\n",
    "        Dij=np.dot(doc1[intersection],doc2[intersection])#sum(prod)\n",
    "    zsm=(Nij*Dij)/(np.sum(doc1)*np.sum(doc2))\n",
    "    return zsm\n",
    "def EEnhancedJaccard(a, b):#similarity\n",
    "    a=set(np.nonzero(a!=0)[0])  #indices of non zero elements in doc1\n",
    "    b=set(np.nonzero(b!=0)[0])  #indices of non zero elements in doc2\n",
    "    union=a.union(b)\n",
    "    intersection=a.intersection(b)\n",
    "    sim=0\n",
    "    if len(union)!=0:\n",
    "        sim=len(intersection)/len(union)#similarity\n",
    "    return sim\n",
    "def esimIT(a,b):\n",
    "    p1= np.divide(a,termOcc) \n",
    "    p2= np.divide(b,termOcc)\n",
    "    minVal=np.minimum(p1,p2)\n",
    "    pi=np.log((np.array(docOcc)/totalDocs))\n",
    "    sIT=(2*np.sum(np.multiply(minVal,pi)))/((np.sum(np.multiply(p1,pi)))+(np.sum(np.multiply(p2,pi))))\n",
    "    return sIT\n",
    "def STB_SM_new(doc1,doc2):\n",
    "    a=set(list(np.nonzero(doc1 != 0)[0]))  #indices of non zero elements in doc1\n",
    "    b=set(list(np.nonzero(doc2 != 0)[0]))  #indices of non zero elements in doc2\n",
    "    intersection=np.array(list(a.intersection(b)))\n",
    "    comp1=a-b\n",
    "    comp2=b-a   \n",
    "    comp1=np.array(list(comp1))\n",
    "    comp2=np.array(list(comp2))\n",
    "    X,Y,D1,D2,Z1,Z2,sim=0,0,0,0,0,0,0\n",
    "    if len(intersection)>0:\n",
    "        X=np.sum(doc1[intersection])\n",
    "        Y=np.sum(doc2[intersection])\n",
    "    if len(comp1)>0:\n",
    "        D1=np.sum(doc1[comp1])\n",
    "    if len(comp2)>0:\n",
    "        D2=np.sum(doc2[comp2])\n",
    "    Z1=np.sum(doc1)\n",
    "    Z2=np.sum(doc2) \n",
    "    if Z1!=0 and Z2!=0:\n",
    "        sim=((X*Y)/(Z1*Z2))*(1-((D1*D2)/(Z1*Z2)))\n",
    "    return sim\n",
    "def EBASM(doc1,doc2):\n",
    "    return ECSM_P2(doc1,doc2) \n",
    "def EISC(doc1,doc2): \n",
    "    dot=np.sum(np.sqrt(np.multiply(doc1,doc2)))\n",
    "    isc=dot /( math.sqrt(np.linalg.norm(doc1, ord=1))*math.sqrt(np.linalg.norm(doc2, ord=1)))\n",
    "    return isc\n",
    "\n",
    "#SP equations\n",
    "def ESP(doc1,doc2):\n",
    "    a=set(list(np.nonzero(doc1!=0)[0]))  #indices of non zero elements in doc1\n",
    "    b=set(list(np.nonzero(doc2!=0)[0]))  #indices of non zero elements in doc2\n",
    "    nonzeroTerm=list(a.intersection(b))  #indices where both docs have non zero elemments\n",
    "    d1=doc1[nonzeroTerm] #doc1 values of doc1 intersection  doc2\n",
    "    d2=doc2[nonzeroTerm] #doc2 values of doc1 intersection  doc2\n",
    "    minArr=np.minimum(d1,d2) #minimum values  of d1 and d2\n",
    "    maxArr=np.maximum(d1,d2) #maximum values  of d1 and d2\n",
    "    ln=len(nonzeroTerm)\n",
    "    docCount=np.zeros(ln)\n",
    "    aData=allData[:,nonzeroTerm] #extracting data with only feature indices of doc1 intersection  doc2\n",
    "    for ti in range(0,ln):\n",
    "        docCount[ti]=count_values_in_range(aData[:,ti], minArr[ti], maxArr[ti]) #count values which lies between min and max\n",
    "    #norm factor which is ist part of equation 6 in paper\n",
    "    normFactor= len(a.union(b))#norm factor equal to length of doc1 union doc2\n",
    "    dCount=np.array(docCount[np.nonzero(docCount!=0)[0]])# get all non zero values between min and max\n",
    "    SP_val=0\n",
    "    if(normFactor!=0):\n",
    "        SP_val=np.sum(np.log(totalDocs/dCount)) #2nd part in equation 6 in paper\n",
    "        SP_val = (SP_val/normFactor) #equation 6 in paper\n",
    "    return SP_val\n",
    "def ENSMT_BASM(doc1,doc2):\n",
    "    return ENSMT(doc1,doc2)*BASM(doc1,doc2)\n",
    "    \n",
    "def PCC_BASM(doc1,doc2):\n",
    "    return PCC(doc1,doc2)*BASM(doc1,doc2)\n",
    "\n",
    "\n",
    "class SimMeaure:\n",
    "\n",
    "    #constructor\n",
    "\n",
    "    def __init__(self,k = 1,metric=\"euclidean\",termOccurance=None, docOccurance=None):\n",
    "\n",
    "        \n",
    "        self.k=k\n",
    "        #print (\"KNN\",self.k)\n",
    "        self.metric=metric\n",
    "        self.trainingData=[]\n",
    "        self.trainLabels=[]\n",
    "        self.smtp=None\n",
    "        self.termOccurance=termOccurance\n",
    "        self.docOccurance=docOccurance\n",
    "         \n",
    "    \n",
    "         \n",
    "\n",
    "    def fit(self, training_data, trainLabels ):\n",
    "        self.trainingData=training_data\n",
    "        self.trainLabels=trainLabels\n",
    "        \n",
    "            \n",
    "       \n",
    "    def predict(self, testData):\n",
    "        train=self.trainingData\n",
    "        var=np.zeros(train.shape[1])\n",
    "        if(self.metric==\"smtp\" or  self.metric==\"esmtp\" or  self.metric==\"DSM\"):\n",
    "            var=np.var(train,axis=0)\n",
    "            print(\"Vrainace is\",var)\n",
    "        distList=[\"KL\",\"extendedJaccard\",\"bhatta\",\"Euclidean\",\"Cosine\",\"Jaccard\",\"JS\",\"EJS\",\"Dice\",\n",
    "                  \"Pairwise\",\"EPairwise\",\"Manhattan\",\"EnhancedJaccard\",\"EEnhancedJaccard\",\"eextendedJaccard\",\"EJS\",\"Minkowski\"]#distance\n",
    "        func=globals()[self.metric]\n",
    "        predLabel=[]\n",
    "        kList=[1,3,5,9,15,30,45,70,90,120]\n",
    "        for kk in range(0,len(kList)):\n",
    "            temp=[]\n",
    "            predLabel.append(temp)\n",
    "            ''''''\n",
    "        distMatrix=[]         \n",
    "        for i in(range(0,len(testData))):\n",
    "            #print(i)\n",
    "            dist=[]\n",
    "            for j in(range(0,len(train))):\n",
    "                if(self.metric==\"smtp\" or self.metric==\"smtp_improved\" or self.metric==\"esmtp\" or self.metric==\"DSM\"):\n",
    "                    dist.append(func(testData[i],train[j],var)) \n",
    "                elif(self.metric==\"simIT\" or self.metric==\"esimIT\"  ):\n",
    "                    dist.append(simIT(testData[i], train[j],self.termOccurance,self.docOccurance))\n",
    "                elif(self.metric==\"SP\"):\n",
    "                    doc1=testData[i]\n",
    "                    doc2=train[j]\n",
    "                    nonzeroDoc1=set(np.nonzero(doc1)[0])\n",
    "                    nonzeroDoc2=set(np.nonzero(doc2)[0])\n",
    "                    nonzeroTerm=list(nonzeroDoc1.intersection(nonzeroDoc2))\n",
    "                    minArr=np.minimum(doc1[nonzeroTerm],doc2[nonzeroTerm])\n",
    "                    maxArr=np.maximum(doc1[nonzeroTerm],doc2[nonzeroTerm])\n",
    "                    ln=len(nonzeroTerm)\n",
    "                    aData=allData[:,nonzeroTerm]\n",
    "                    docCount=np.zeros(ln)\n",
    "                    for ti in range(0,ln):\n",
    "                        tData=pd.Series(aData[:,ti])\n",
    "                        docCount[ti]=count_values_in_range(tData, minArr[ti], maxArr[ti])\n",
    "                    dist.append(SP(testData[i],train[j],docCount,totalDocs))\n",
    "                else:\n",
    "                    dist.append(func(testData[i], train[j]))\n",
    "            flag=-1\n",
    "            dist=list(dist)\n",
    "            if(self.metric in distList):\n",
    "                \n",
    "                dist=[(1/(x+0.0001)) for x in dist]\n",
    "                flag=1\n",
    "\n",
    "            distMatrix.append(dist)\n",
    "        return distMatrix\n",
    "\n",
    "\n",
    "def groupData(labels,categories):\n",
    "\n",
    "    print (categories)\n",
    "    groups=[]\n",
    "    for i in range(0,len(categories)):\n",
    "        groups.append([0,0,0])\n",
    "    totalDocs=len(labels)\n",
    "    print (totalDocs)\n",
    "    for i in range(0,totalDocs):\n",
    "        tmp=(categories.index(labels[i]))\n",
    "        groups[tmp].append(i)\n",
    "    for i in range(0,len(categories)):\n",
    "        del (groups[i])[0:3]\n",
    "    return groups\n",
    "\n",
    "class ANN() : # to take preprocessed data , pass them into model and print results\n",
    "    def __init__ (self ,  x_train  , x_test , y_train , y_test ):\n",
    "        self.x_train=x_train\n",
    "        self.x_test=x_test\n",
    "        self.y_train=y_train\n",
    "        self.y_test=y_test\n",
    "    def fit(self,x_train  , y_train  , x_test, y_test , outputdim) :         \n",
    "      #Fitting ANN Model\n",
    "        config = tf.compat.v1.ConfigProto( device_count = {'GPU': 2 , 'CPU': 6} ) \n",
    "        sess = tf.compat.v1.Session(config=config) \n",
    "        tf.compat.v1.keras.backend.set_session(sess)\n",
    "        model = Sequential()\n",
    "        input_dim = x_train.shape[1]  # Number of features\n",
    "        #micro_f1 = metrics.F1Score(num_classes=input_dim , average='micro')\n",
    "        y_train = np.asarray(train_labels)\n",
    "        y_test = np.asarray(test_labels)\n",
    "        model.add(Dense(30, activation='relu',kernel_regularizer='l2',input_shape = ( x_train.shape)))\n",
    "        model.add(Dropout(0.5))\n",
    "        model.add(Dense(outputdim, activation='softmax'))\n",
    "        model.summary()\n",
    "        model.compile(loss='sparse_categorical_crossentropy', optimizer='adam' ,metrics=['accuracy'])\n",
    "        \n",
    "        history = model.fit(x_train, y_train,\n",
    "                    epochs=100,\n",
    "                    validation_data=(x_test, y_test),\n",
    "                     verbose=1)\n",
    "         #Finally testing the model & getting accuracy metrics\n",
    "        model.summary()\n",
    "        loss,acc = model.evaluate(x_test, y_test, verbose=1)\n",
    "        y_pred1 = model.predict(x_test)\n",
    "        predicts = np.max(y_pred1,axis=1) \n",
    "        sess.close()\n",
    "        gc.collect()\n",
    " \n",
    "        return np.argmax(y_pred1,axis=1) ,y_pred1\n",
    "def ECSM_P1(doc1,doc2):\n",
    "    simValue=0\n",
    "    N=len(doc1)#total_features;\n",
    "    a=set((np.nonzero(doc1 != 0)[0]).tolist()) #indices of non zero elements in doc1\n",
    "    b=set((np.nonzero(doc2 != 0)[0]).tolist()) #indices of non zero elements in doc2NSMT\n",
    "    Nab=len(a.intersection(b))\n",
    "    F=len(a.union(b))-Nab\n",
    "    simValue=(1-F/N)\n",
    "    return simValue\n",
    "def ECSM_P2(doc1,doc2):\n",
    "    a=set((np.nonzero(doc1 != 0)[0]).tolist()) #indices of non zero elements in doc1\n",
    "    b=set((np.nonzero(doc2 != 0)[0]).tolist()) #indices of non zero elements in doc2NSMT\n",
    "    sim=0\n",
    "    if (len(a)+len(b))!=0:\n",
    "        sim=(2*len(a.intersection(b)))/(len(a)+len(b))\n",
    "    return sim\n",
    "\n",
    "def EBLAB_SM(doc1,doc2):\n",
    "    return 0.5*(ECSM_P1(doc1,doc2)+ECSM_P2(doc1,doc2))\n",
    "\n",
    "def ESTB_SM(doc1,doc2):\n",
    "    a=set(np.nonzero(doc1)[0])  \n",
    "    b=set(np.nonzero(doc2)[0])\n",
    "    intersection=np.array(list(a.intersection(b)))\n",
    "    comp1=np.array(list(a-b))\n",
    "    comp2=np.array(list(b-a))\n",
    "    X,Y,D1,D2,sim=0,0,0,0,0                   \n",
    "    if len(intersection)>0:\n",
    "        X=np.sum(doc1[intersection])\n",
    "        Y=np.sum(doc2[intersection])\n",
    "        if len(comp1)>0:\n",
    "            D1=np.sum(doc1[comp1])\n",
    "        if len(comp2)>0:\n",
    "            D2=np.sum(doc2[comp2])\n",
    "        if len(intersection)>0:\n",
    "            sim=1/(1+((D1/X)+(D2/Y)))\n",
    "    return sim \n",
    "def ESP(doc1,doc2):\n",
    "    a=set(list(np.nonzero(doc1!=0)[0]))  #indices of non zero elements in doc1\n",
    "    b=set(list(np.nonzero(doc2!=0)[0]))  #indices of non zero elements in doc2\n",
    "    nonzeroTerm=list(a.intersection(b))  #indices where both docs have non zero elemments\n",
    "    d1=doc1[nonzeroTerm] #doc1 values of doc1 intersection  doc2\n",
    "    d2=doc2[nonzeroTerm] #doc2 values of doc1 intersection  doc2\n",
    "    minArr=np.minimum(d1,d2) #minimum values  of d1 and d2\n",
    "    maxArr=np.maximum(d1,d2) #maximum values  of d1 and d2\n",
    "    ln=len(nonzeroTerm)\n",
    "    docCount=np.zeros(ln)\n",
    "    aData=allData[:,nonzeroTerm] #extracting data with only feature indices of doc1 intersection  doc2\n",
    "    for ti in range(0,ln):\n",
    "        docCount[ti]=count_values_in_range(aData[:,ti], minArr[ti], maxArr[ti]) #count values which lies between min and max\n",
    "    #norm factor which is ist part of equation 6 in paper\n",
    "    normFactor= len(a.union(b))#norm factor equal to length of doc1 union doc2\n",
    "    dCount=np.array(docCount[np.nonzero(docCount!=0)[0]])# get all non zero values between min and max\n",
    "    SP_val=0\n",
    "    if(normFactor!=0):\n",
    "        SP_val=np.sum(np.log(totalDocs/dCount)) #2nd part in equation 6 in paper\n",
    "        SP_val = (SP_val/normFactor) #equation 6 in paper\n",
    "    return SP_val\n",
    "\n",
    "def esmtp(doc1,doc2,var):\n",
    "    lemda=1\n",
    "    a=set(list(np.nonzero(doc1 != 0)[0]))  #indices of non zero elements in doc1\n",
    "    b=set(list(np.nonzero(doc2 != 0)[0]))  #indices of non zero elements in doc2\n",
    "    intersection=a.intersection(b) # indices where both docs have non zero elements\n",
    "    union=a.union(b) # indices where either doc has non zero elements\n",
    "    l1=len(a-intersection) # doc1 !=0 and doc2=0\n",
    "    l2=len(b-intersection) # doc1 =0 and doc2!=0\n",
    "    Nstar=0\n",
    "    intersection=np.array(list(intersection))\n",
    "    if (len(intersection)>0):\n",
    "        term1=np.exp(-1*np.square(( doc1[intersection]-doc2[intersection] )/var[intersection]))\n",
    "        Nstar=np.sum(0.5* (1+term1)) +lemda* -1 *(l1+l2)\n",
    "    else:\n",
    "        Nstar=lemda* -1 *(l1+l2)   \n",
    "    Nunion=len(intersection)+l1+l2\n",
    "    smtp=((Nstar/Nunion)+lemda)/(1+lemda)\n",
    "    return smtp\n",
    "def classify(metric='Cosine',termOccurance=None, docOccurance=None):\n",
    "    time1= time.time()\n",
    "    accuracy=[]\n",
    "    macroFMeasure=[]\n",
    "    microFMeasure=[]\n",
    "    \n",
    "    y_pred =NBCombined(train_data, train_labels,test_data,test_labels,metric)\n",
    "    time2= time.time()\n",
    "    \n",
    "    for i in range(0,1):\n",
    "        #Accuracy\n",
    "    \n",
    "        accuracy=accuracy_score(test_labels, y_pred)\n",
    "        \n",
    "        #Macro Precision\n",
    "        \n",
    "        macroP=precision_score(test_labels, y_pred,average='macro')\n",
    "        \n",
    "        #Micro Precision\n",
    "        \n",
    "        microP=precision_score(test_labels, y_pred,average='micro')\n",
    "        \n",
    "        #Macro Recall\n",
    "        \n",
    "        macroR=recall_score(test_labels, y_pred,average='macro')\n",
    "        \n",
    "        #Micro Recall\n",
    "        \n",
    "        microR=recall_score(test_labels, y_pred,average='micro')\n",
    "        \n",
    "        \n",
    "        fMeasure=f1_score(test_labels, y_pred,average='macro')\n",
    "       # PrintDetails(metric=metric,time=str(timedelta(seconds=(time2-time1))),measure=\"F Measure\",Arr=fMeasure)\n",
    "        \n",
    "        m_fMeasure=f1_score(test_labels, y_pred,average='micro')\n",
    "       # PrintDetails(metric=metric,time=str(timedelta(seconds=(time2-time1))),measure=\"F Measure\",Arr=fMeasure)\n",
    "        \n",
    "        #PrintDetails(metric=metric,time=str(timedelta(seconds=(time2-time1))),measure=\"g Measure\",Arr=gMeasure)\n",
    "      \n",
    "        test = label_binarize(test_labels, classes=categories)\n",
    "        pred = label_binarize( y_pred, classes=categories)\n",
    "        \n",
    "        #roc\n",
    "        roc=roc_auc_score(test, pred)\n",
    "    #Accuracy\n",
    "    accuracy_avg.append(accuracy)\n",
    "    #Precision\n",
    "    macroP_avg.append(macroP)\n",
    "    microP_avg.append(microP)\n",
    "    #recall\n",
    "    macroR_avg.append(macroR)\n",
    "    microR_avg.append(microR)\n",
    "    #F measure\n",
    "    macroFMeasure_avg.append(fMeasure)\n",
    "    microFMeasure_avg.append( m_fMeasure)\n",
    "    #Roc\n",
    "    roc_avg.append(roc)\n",
    "\n",
    "def PrintDetails(metric=\"smtp\",time=None,measure= \"Accuracy\",Arr=None):\n",
    "    x = PrettyTable()\n",
    "    kList=[1,3,5,9,15,30,45]\n",
    "    x.field_names = [\"Experiment No.\",\"DataSet1\"]\n",
    "    print(\"metric\",metric)\n",
    "    print(\"time\",time)\n",
    "    print(\"measure\",measure)\n",
    "    tables.write(\"metric\\t\"+str(metric)+\"\\n\")\n",
    "    tables.write(\"time\\t\"+str(time)+\"\\n\")\n",
    "    tables.write(\"measure\\t\"+str(measure)+\"\\n\")\n",
    "    average=0\n",
    "    for i in range(0,len(Arr)):\n",
    "        x.add_row([i+1,Arr[i]]) \n",
    "        average+=Arr[i]\n",
    "    x.add_row([\"Average\",average/len(Arr)])   \n",
    "    tables.write(str(x))\n",
    "    print (x)\n",
    "def NBCombined(train_data, train_labels,test_data,test_labels,metric):\n",
    "    #prediction of NB on test data\n",
    "    classes=list(set(train_labels))\n",
    "    global prob\n",
    "    prob1=prob[split]\n",
    "    y_pred=[]\n",
    "    print(\"prob\",len(prob1))\n",
    "    if len(prob1)==0:\n",
    "        ann = ANN(train_data, train_labels,test_data,test_labels)\n",
    "        y_pred,prob[split] = ann.fit(train_data, train_labels,test_data,test_labels,len(classes))\n",
    "        #y_pred = np.max(y_pred1,axis=1)\n",
    "    if metric==\"Base\":\n",
    "        return y_pred\n",
    "\n",
    "    classifier =SimMeaure(k=1,metric=metric)#,termOccurance=termOccurance,docOccurance=docOccurance)  \n",
    "    classifier.fit(train_data, train_labels)\n",
    "    distMatrix = classifier.predict(test_data) \n",
    "    print(\"Dist Mat shape\", len(distMatrix))\n",
    "    print(\"Element shape\", len(distMatrix[0]))\n",
    "    distList=[]\n",
    "    predLabels=[]\n",
    "    nn=10\n",
    "    prob1=np.array(prob1)\n",
    "    print(prob1.shape)\n",
    "    indices=[]\n",
    "    for cl in range(0,len(classes)):\n",
    "            indices.append([l for l in range(0,len(train_labels)) if train_labels[l]==classes[cl]])\n",
    "    \n",
    "    for tst in range(0,test_data.shape[0]):\n",
    "        probNb=np.array(prob1[tst,:])\n",
    "        simAvg=[]\n",
    "        simValue=np.array(distMatrix[tst])\n",
    "        \n",
    "        #neigh_labels=np.array(train_labels)[neigh]\n",
    "        for cl in range(0,len(classes)):\n",
    "            cl_ind=indices[cl]\n",
    "            sim=simValue[cl_ind]\n",
    "            if nn<=len(sim):\n",
    "                neigh= np.argpartition(np.array(sim), len(sim) - nn)[-nn:]\n",
    "            else:\n",
    "                nnn=len(sim)\n",
    "                neigh= np.argpartition(np.array(sim), len(sim) - nnn)[-nnn:]\n",
    "            avg=np.nansum(sim[[neigh]])\n",
    "            simAvg.append(avg)\n",
    "        simAvg=(np.array(simAvg))/(np.nansum(simAvg))\n",
    "        #print(probNb)\n",
    "        totalValue=np.add(probNb, simAvg)\n",
    "       # totalValue=simAvg\n",
    "        #print(\"combined value is\",totalValue)\n",
    "        lblInd=np.where(totalValue == np.max(totalValue))\n",
    "        ind1=(lblInd[0])[0]\n",
    "       # print(ind1)\n",
    "       # print(lbl)\n",
    "        predLabels.append(ind1)      \n",
    "\n",
    "    return predLabels\n",
    "dataset='Reuters'\n",
    "count=0\n",
    "documents=[]\n",
    "labels=[]\n",
    "rawData=[]\n",
    "token_dict = dict()\n",
    "loadReutersData(documents=documents,labels=labels)  \n",
    "print(len(documents))\n",
    "categories=list(set(labels))\n",
    "totalDocs= len(documents)\n",
    "print (totalDocs)\n",
    "stopwords = stopwords.words('english')\n",
    "tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')\n",
    "vocabulary = set()\n",
    "term_docs=[]\n",
    "terms=[]\n",
    "totalDocs= len(documents)\n",
    "print (len(documents))\n",
    "print (\"vectorize\")\n",
    "tfidf = TfidfVectorizer(tokenizer=tokenize1)\n",
    "print (\"fit transform\")\n",
    "tfs = tfidf.fit_transform(documents)\n",
    "#sorted_scores=display_scores(tfidf, tfs)\n",
    "#groups=groupData(labels,categories) \n",
    "#n=len(sorted_scores)  \n",
    "arr=tfs.todense()\n",
    "n=arr.shape[1]\n",
    "allData=arr\n",
    "measures=[\"Base\",\"Euclidean\",\"Manhattan\",\"Cosine\",\"Jaccard\", \"bhatta\",\"EPairwise\" ,\n",
    "          \"EPDSM\",\"PCC\",\"STB_SM_new\",\n",
    "          \"esmtp\",\"EISC\",\"EDice\",\"ESP\",\"EBLAB_SM\"]\n",
    "global prob\n",
    "prob=[]\n",
    "labels=np.array(labels)\n",
    "lab_enc = LabelEncoder()\n",
    "labels = lab_enc.fit_transform(labels)\n",
    "k_splits=5\n",
    "for ks in range(0,k_splits):\n",
    "    prob.append([])\n",
    "\n",
    "labels=np.array(labels)\n",
    "var=0\n",
    "categories=list(set(set(labels)))\n",
    "categories.sort()\n",
    "print(categories)\n",
    "global time1\n",
    "global time2\n",
    "time1,time2=0,0\n",
    "split=0\n",
    "\n",
    "for met in measures:\n",
    "    print(\"###############\")\n",
    "    fname='table_'+dataset+'_ANN_'+met+'_Tfidf_5Exp.txt'\n",
    "    tables = open(fname, 'w')\n",
    "    tables.write(\"No. of features\\t\"+str(n)+\"\\n\")\n",
    "    print(\"###############\")\n",
    "    accuracy_avg=[]\n",
    "    macroP_avg=[]\n",
    "    microP_avg=[]\n",
    "    macroR_avg=[]\n",
    "    microR_avg=[]\n",
    "    macroFMeasure_avg=[]\n",
    "    microFMeasure_avg=[]\n",
    "    roc_avg=[]\n",
    "    split=0\n",
    "    if met==\"smtp\" or met==\"esmtp\" or met==\"DSM\":\n",
    "        var1=np.var(arr,axis=0).reshape(-1,1).ravel()\n",
    "        var=np.asarray(var1).ravel()\n",
    "    rand_state=[0,1,10,42,30]\n",
    "    time1=time.time()\n",
    "    for i in range(0,k_splits):\n",
    "        xTrain, xTest, yTrain, yTest = train_test_split(arr, labels, test_size = 0.3, random_state = rand_state[i],stratify=labels)\n",
    "        train_data=np.array(xTrain)\n",
    "        test_data=np.array(xTest)\n",
    "        train_labels=yTrain\n",
    "        test_labels=yTest\n",
    "        classify(metric=met) \n",
    "        split+=1\n",
    "\n",
    "    time2=time.time()\n",
    "    #Accuracy\n",
    "    PrintDetails(metric=met,time=str(timedelta(seconds=(time2-time1))),measure=\"Accuracy\",Arr=accuracy_avg)\n",
    "    #Precision\n",
    "    PrintDetails(metric=met,time=str(timedelta(seconds=(time2-time1))),measure=\"Macro Precision\",Arr=macroP_avg)\n",
    "    PrintDetails(metric=met,time=str(timedelta(seconds=(time2-time1))),measure=\"Micro Precision\",Arr=microP_avg)\n",
    "    #Recall\n",
    "    PrintDetails(metric=met,time=str(timedelta(seconds=(time2-time1))),measure=\"Macro Recall\",Arr=macroR_avg)\n",
    "    PrintDetails(metric=met,time=str(timedelta(seconds=(time2-time1))),measure=\"Micro Recall\",Arr=microR_avg)\n",
    "    #f measure\n",
    "    PrintDetails(metric=met,time=str(timedelta(seconds=(time2-time1))),measure=\"F Measure\",Arr=macroFMeasure_avg)\n",
    "\n",
    "    #f measure\n",
    "    PrintDetails(metric=met,time=str(timedelta(seconds=(time2-time1))),measure=\"Micro F Measure\",Arr=microFMeasure_avg)\n",
    "\n",
    "    #roc\n",
    "    PrintDetails(metric=met,time=str(timedelta(seconds=(time2-time1))),measure=\"ROC\",Arr=roc_avg)\n",
    "    tables.close()\n",
    "    print(\"###############\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###############\n",
      "###############\n",
      "prob 2308\n",
      "Vrainace is [1.87030707e-05 0.00000000e+00 3.91747901e-05 ... 2.16134738e-05\n",
      " 3.34465973e-07 5.28951900e-05]\n",
      "Dist Mat shape 2308\n",
      "Element shape 5383\n",
      "(2308, 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hassa\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:63: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prob 2308\n",
      "Vrainace is [1.87030707e-05 1.41720430e-06 3.91747901e-05 ... 3.21250960e-05\n",
      " 0.00000000e+00 5.28951900e-05]\n",
      "Dist Mat shape 2308\n",
      "Element shape 5383\n",
      "(2308, 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hassa\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:63: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prob 2308\n",
      "Vrainace is [0.00000000e+00 1.41720430e-06 3.91747901e-05 ... 2.83254670e-05\n",
      " 3.34465973e-07 0.00000000e+00]\n",
      "Dist Mat shape 2308\n",
      "Element shape 5383\n",
      "(2308, 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hassa\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:63: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prob 2308\n",
      "Vrainace is [0.00000000e+00 1.41720430e-06 3.91747901e-05 ... 2.32570534e-05\n",
      " 3.34465973e-07 5.28951900e-05]\n",
      "Dist Mat shape 2308\n",
      "Element shape 5383\n",
      "(2308, 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hassa\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:63: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prob 2308\n",
      "Vrainace is [0.00000000e+00 1.41720430e-06 0.00000000e+00 ... 2.59031735e-05\n",
      " 3.34465973e-07 5.28951900e-05]\n",
      "Dist Mat shape 2308\n",
      "Element shape 5383\n",
      "(2308, 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hassa\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:63: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metric esmtp\n",
      "time 1:40:36.155934\n",
      "measure Accuracy\n",
      "+----------------+--------------------+\n",
      "| Experiment No. |      DataSet1      |\n",
      "+----------------+--------------------+\n",
      "|       1        | 0.9592720970537262 |\n",
      "|       2        | 0.9519064124783362 |\n",
      "|       3        | 0.9553726169844021 |\n",
      "|       4        | 0.9584055459272097 |\n",
      "|       5        | 0.9566724436741768 |\n",
      "|    Average     | 0.9563258232235702 |\n",
      "+----------------+--------------------+\n",
      "metric esmtp\n",
      "time 1:40:36.155934\n",
      "measure Macro Precision\n",
      "+----------------+--------------------+\n",
      "| Experiment No. |      DataSet1      |\n",
      "+----------------+--------------------+\n",
      "|       1        | 0.9465026446292653 |\n",
      "|       2        | 0.9361393653295026 |\n",
      "|       3        | 0.9515300262899784 |\n",
      "|       4        | 0.9451174744456549 |\n",
      "|       5        | 0.9411653031510548 |\n",
      "|    Average     | 0.9440909627690912 |\n",
      "+----------------+--------------------+\n",
      "metric esmtp\n",
      "time 1:40:36.155934\n",
      "measure Micro Precision\n",
      "+----------------+--------------------+\n",
      "| Experiment No. |      DataSet1      |\n",
      "+----------------+--------------------+\n",
      "|       1        | 0.9592720970537262 |\n",
      "|       2        | 0.9519064124783362 |\n",
      "|       3        | 0.9553726169844021 |\n",
      "|       4        | 0.9584055459272097 |\n",
      "|       5        | 0.9566724436741768 |\n",
      "|    Average     | 0.9563258232235702 |\n",
      "+----------------+--------------------+\n",
      "metric esmtp\n",
      "time 1:40:36.155934\n",
      "measure Macro Recall\n",
      "+----------------+--------------------+\n",
      "| Experiment No. |      DataSet1      |\n",
      "+----------------+--------------------+\n",
      "|       1        | 0.8268237140009849 |\n",
      "|       2        | 0.7816800456085053 |\n",
      "|       3        | 0.8125918951816923 |\n",
      "|       4        | 0.8194461733822778 |\n",
      "|       5        | 0.793476332022049  |\n",
      "|    Average     | 0.8068036320391018 |\n",
      "+----------------+--------------------+\n",
      "metric esmtp\n",
      "time 1:40:36.155934\n",
      "measure Micro Recall\n",
      "+----------------+--------------------+\n",
      "| Experiment No. |      DataSet1      |\n",
      "+----------------+--------------------+\n",
      "|       1        | 0.9592720970537262 |\n",
      "|       2        | 0.9519064124783362 |\n",
      "|       3        | 0.9553726169844021 |\n",
      "|       4        | 0.9584055459272097 |\n",
      "|       5        | 0.9566724436741768 |\n",
      "|    Average     | 0.9563258232235702 |\n",
      "+----------------+--------------------+\n",
      "metric esmtp\n",
      "time 1:40:36.155934\n",
      "measure F Measure\n",
      "+----------------+--------------------+\n",
      "| Experiment No. |      DataSet1      |\n",
      "+----------------+--------------------+\n",
      "|       1        | 0.8588846676422491 |\n",
      "|       2        | 0.8060860339889768 |\n",
      "|       3        | 0.846740203879393  |\n",
      "|       4        | 0.8572633264155578 |\n",
      "|       5        | 0.8233393498890768 |\n",
      "|    Average     | 0.8384627163630507 |\n",
      "+----------------+--------------------+\n",
      "metric esmtp\n",
      "time 1:40:36.155934\n",
      "measure Micro F Measure\n",
      "+----------------+--------------------+\n",
      "| Experiment No. |      DataSet1      |\n",
      "+----------------+--------------------+\n",
      "|       1        | 0.9592720970537262 |\n",
      "|       2        | 0.9519064124783363 |\n",
      "|       3        | 0.9553726169844021 |\n",
      "|       4        | 0.9584055459272097 |\n",
      "|       5        | 0.9566724436741768 |\n",
      "|    Average     | 0.9563258232235702 |\n",
      "+----------------+--------------------+\n",
      "metric esmtp\n",
      "time 1:40:36.155934\n",
      "measure ROC\n",
      "+----------------+--------------------+\n",
      "| Experiment No. |      DataSet1      |\n",
      "+----------------+--------------------+\n",
      "|       1        | 0.9095973269406916 |\n",
      "|       2        | 0.8861771883641847 |\n",
      "|       3        | 0.9017340566810444 |\n",
      "|       4        | 0.9058297585224883 |\n",
      "|       5        | 0.8927712517808566 |\n",
      "|    Average     | 0.8992219164578531 |\n",
      "+----------------+--------------------+\n",
      "###############\n",
      "###############\n",
      "###############\n",
      "prob 2308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hassa\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:823: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dist Mat shape 2308\n",
      "Element shape 5383\n",
      "(2308, 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hassa\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:63: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "C:\\Users\\hassa\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:65: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prob 2308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hassa\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:823: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dist Mat shape 2308\n",
      "Element shape 5383\n",
      "(2308, 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hassa\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:63: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "C:\\Users\\hassa\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:65: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prob 2308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hassa\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:823: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dist Mat shape 2308\n",
      "Element shape 5383\n",
      "(2308, 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hassa\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:63: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "C:\\Users\\hassa\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:65: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prob 2308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hassa\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:823: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dist Mat shape 2308\n",
      "Element shape 5383\n",
      "(2308, 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hassa\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:63: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "C:\\Users\\hassa\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:65: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prob 2308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hassa\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:823: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dist Mat shape 2308\n",
      "Element shape 5383\n",
      "(2308, 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hassa\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:63: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "C:\\Users\\hassa\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:65: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metric EISC\n",
      "time 2:10:50.899556\n",
      "measure Accuracy\n",
      "+----------------+--------------------+\n",
      "| Experiment No. |      DataSet1      |\n",
      "+----------------+--------------------+\n",
      "|       1        | 0.9488734835355286 |\n",
      "|       2        | 0.9484402079722704 |\n",
      "|       3        | 0.951473136915078  |\n",
      "|       4        | 0.9584055459272097 |\n",
      "|       5        | 0.9506065857885615 |\n",
      "|    Average     | 0.9515597920277296 |\n",
      "+----------------+--------------------+\n",
      "metric EISC\n",
      "time 2:10:50.899556\n",
      "measure Macro Precision\n",
      "+----------------+--------------------+\n",
      "| Experiment No. |      DataSet1      |\n",
      "+----------------+--------------------+\n",
      "|       1        | 0.9398060136193982 |\n",
      "|       2        | 0.9397142641695295 |\n",
      "|       3        | 0.9496529710437623 |\n",
      "|       4        | 0.9513165758151332 |\n",
      "|       5        | 0.9415896807425934 |\n",
      "|    Average     | 0.9444159010780833 |\n",
      "+----------------+--------------------+\n",
      "metric EISC\n",
      "time 2:10:50.899556\n",
      "measure Micro Precision\n",
      "+----------------+--------------------+\n",
      "| Experiment No. |      DataSet1      |\n",
      "+----------------+--------------------+\n",
      "|       1        | 0.9488734835355286 |\n",
      "|       2        | 0.9484402079722704 |\n",
      "|       3        | 0.951473136915078  |\n",
      "|       4        | 0.9584055459272097 |\n",
      "|       5        | 0.9506065857885615 |\n",
      "|    Average     | 0.9515597920277296 |\n",
      "+----------------+--------------------+\n",
      "metric EISC\n",
      "time 2:10:50.899556\n",
      "measure Macro Recall\n",
      "+----------------+--------------------+\n",
      "| Experiment No. |      DataSet1      |\n",
      "+----------------+--------------------+\n",
      "|       1        | 0.8729879771216613 |\n",
      "|       2        | 0.8467650604889037 |\n",
      "|       3        | 0.8560899367301146 |\n",
      "|       4        | 0.8692008017781341 |\n",
      "|       5        | 0.8558069888878566 |\n",
      "|    Average     | 0.860170153001334  |\n",
      "+----------------+--------------------+\n",
      "metric EISC\n",
      "time 2:10:50.899556\n",
      "measure Micro Recall\n",
      "+----------------+--------------------+\n",
      "| Experiment No. |      DataSet1      |\n",
      "+----------------+--------------------+\n",
      "|       1        | 0.9488734835355286 |\n",
      "|       2        | 0.9484402079722704 |\n",
      "|       3        | 0.951473136915078  |\n",
      "|       4        | 0.9584055459272097 |\n",
      "|       5        | 0.9506065857885615 |\n",
      "|    Average     | 0.9515597920277296 |\n",
      "+----------------+--------------------+\n",
      "metric EISC\n",
      "time 2:10:50.899556\n",
      "measure F Measure\n",
      "+----------------+--------------------+\n",
      "| Experiment No. |      DataSet1      |\n",
      "+----------------+--------------------+\n",
      "|       1        | 0.8990728396622636 |\n",
      "|       2        | 0.8820907885067182 |\n",
      "|       3        | 0.8896718534431083 |\n",
      "|       4        | 0.8999463237009748 |\n",
      "|       5        | 0.8886418454917144 |\n",
      "|    Average     | 0.8918847301609558 |\n",
      "+----------------+--------------------+\n",
      "metric EISC\n",
      "time 2:10:50.899556\n",
      "measure Micro F Measure\n",
      "+----------------+--------------------+\n",
      "| Experiment No. |      DataSet1      |\n",
      "+----------------+--------------------+\n",
      "|       1        | 0.9488734835355286 |\n",
      "|       2        | 0.9484402079722704 |\n",
      "|       3        | 0.951473136915078  |\n",
      "|       4        | 0.9584055459272097 |\n",
      "|       5        | 0.9506065857885615 |\n",
      "|    Average     | 0.9515597920277296 |\n",
      "+----------------+--------------------+\n",
      "metric EISC\n",
      "time 2:10:50.899556\n",
      "measure ROC\n",
      "+----------------+--------------------+\n",
      "| Experiment No. |      DataSet1      |\n",
      "+----------------+--------------------+\n",
      "|       1        | 0.9320775849603059 |\n",
      "|       2        | 0.9187330562000282 |\n",
      "|       3        | 0.9234732960182064 |\n",
      "|       4        | 0.9308861606275176 |\n",
      "|       5        | 0.9234998810960164 |\n",
      "|    Average     | 0.9257339957804149 |\n",
      "+----------------+--------------------+\n",
      "###############\n",
      "###############\n",
      "###############\n",
      "prob 2308\n",
      "Dist Mat shape 2308\n",
      "Element shape 5383\n",
      "(2308, 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hassa\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:63: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "C:\\Users\\hassa\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:65: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prob 2308\n",
      "Dist Mat shape 2308\n",
      "Element shape 5383\n",
      "(2308, 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hassa\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:63: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "C:\\Users\\hassa\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:65: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prob 2308\n",
      "Dist Mat shape 2308\n",
      "Element shape 5383\n",
      "(2308, 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hassa\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:63: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "C:\\Users\\hassa\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:65: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prob 2308\n",
      "Dist Mat shape 2308\n",
      "Element shape 5383\n",
      "(2308, 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hassa\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:63: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "C:\\Users\\hassa\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:65: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prob 2308\n",
      "Dist Mat shape 2308\n",
      "Element shape 5383\n",
      "(2308, 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hassa\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:63: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "C:\\Users\\hassa\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:65: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metric EDice\n",
      "time 1:16:53.121833\n",
      "measure Accuracy\n",
      "+----------------+--------------------+\n",
      "| Experiment No. |      DataSet1      |\n",
      "+----------------+--------------------+\n",
      "|       1        | 0.9553726169844021 |\n",
      "|       2        | 0.9488734835355286 |\n",
      "|       3        | 0.9527729636048526 |\n",
      "|       4        | 0.9562391681109186 |\n",
      "|       5        | 0.9545060658578857 |\n",
      "|    Average     | 0.9535528596187175 |\n",
      "+----------------+--------------------+\n",
      "metric EDice\n",
      "time 1:16:53.121833\n",
      "measure Macro Precision\n",
      "+----------------+--------------------+\n",
      "| Experiment No. |      DataSet1      |\n",
      "+----------------+--------------------+\n",
      "|       1        | 0.9421198425395108 |\n",
      "|       2        | 0.9347193179475819 |\n",
      "|       3        | 0.9514472694250722 |\n",
      "|       4        | 0.9440959925270063 |\n",
      "|       5        | 0.9414576765901304 |\n",
      "|    Average     | 0.9427680198058603 |\n",
      "+----------------+--------------------+\n",
      "metric EDice\n",
      "time 1:16:53.121833\n",
      "measure Micro Precision\n",
      "+----------------+--------------------+\n",
      "| Experiment No. |      DataSet1      |\n",
      "+----------------+--------------------+\n",
      "|       1        | 0.9553726169844021 |\n",
      "|       2        | 0.9488734835355286 |\n",
      "|       3        | 0.9527729636048526 |\n",
      "|       4        | 0.9562391681109186 |\n",
      "|       5        | 0.9545060658578857 |\n",
      "|    Average     | 0.9535528596187175 |\n",
      "+----------------+--------------------+\n",
      "metric EDice\n",
      "time 1:16:53.121833\n",
      "measure Macro Recall\n",
      "+----------------+--------------------+\n",
      "| Experiment No. |      DataSet1      |\n",
      "+----------------+--------------------+\n",
      "|       1        | 0.8232873061100411 |\n",
      "|       2        | 0.7809366301454638 |\n",
      "|       3        | 0.805296706513237  |\n",
      "|       4        | 0.8215649691974168 |\n",
      "|       5        | 0.7942880251744102 |\n",
      "|    Average     | 0.8050747274281138 |\n",
      "+----------------+--------------------+\n",
      "metric EDice\n",
      "time 1:16:53.121833\n",
      "measure Micro Recall\n",
      "+----------------+--------------------+\n",
      "| Experiment No. |      DataSet1      |\n",
      "+----------------+--------------------+\n",
      "|       1        | 0.9553726169844021 |\n",
      "|       2        | 0.9488734835355286 |\n",
      "|       3        | 0.9527729636048526 |\n",
      "|       4        | 0.9562391681109186 |\n",
      "|       5        | 0.9545060658578857 |\n",
      "|    Average     | 0.9535528596187175 |\n",
      "+----------------+--------------------+\n",
      "metric EDice\n",
      "time 1:16:53.121833\n",
      "measure F Measure\n",
      "+----------------+--------------------+\n",
      "| Experiment No. |      DataSet1      |\n",
      "+----------------+--------------------+\n",
      "|       1        | 0.8548882040563711 |\n",
      "|       2        | 0.8049786114884525 |\n",
      "|       3        | 0.8349990263289188 |\n",
      "|       4        | 0.8584023317456038 |\n",
      "|       5        | 0.8239250237799373 |\n",
      "|    Average     | 0.8354386394798567 |\n",
      "+----------------+--------------------+\n",
      "metric EDice\n",
      "time 1:16:53.121833\n",
      "measure Micro F Measure\n",
      "+----------------+--------------------+\n",
      "| Experiment No. |      DataSet1      |\n",
      "+----------------+--------------------+\n",
      "|       1        | 0.9553726169844021 |\n",
      "|       2        | 0.9488734835355286 |\n",
      "|       3        | 0.9527729636048526 |\n",
      "|       4        | 0.9562391681109186 |\n",
      "|       5        | 0.9545060658578857 |\n",
      "|    Average     | 0.9535528596187175 |\n",
      "+----------------+--------------------+\n",
      "metric EDice\n",
      "time 1:16:53.121833\n",
      "measure ROC\n",
      "+----------------+--------------------+\n",
      "| Experiment No. |      DataSet1      |\n",
      "+----------------+--------------------+\n",
      "|       1        | 0.9075528090465204 |\n",
      "|       2        | 0.8856021412411061 |\n",
      "|       3        | 0.8978946590753386 |\n",
      "|       4        | 0.9067296163639085 |\n",
      "|       5        | 0.892990514164054  |\n",
      "|    Average     | 0.8981539479781855 |\n",
      "+----------------+--------------------+\n",
      "###############\n",
      "###############\n",
      "###############\n",
      "prob 2308\n",
      "Dist Mat shape 2308\n",
      "Element shape 5383\n",
      "(2308, 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hassa\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:63: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "C:\\Users\\hassa\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:65: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prob 2308\n",
      "Dist Mat shape 2308\n",
      "Element shape 5383\n",
      "(2308, 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hassa\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:63: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "C:\\Users\\hassa\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:65: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prob 2308\n",
      "Dist Mat shape 2308\n",
      "Element shape 5383\n",
      "(2308, 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hassa\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:63: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "C:\\Users\\hassa\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:65: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prob 2308\n",
      "Dist Mat shape 2308\n",
      "Element shape 5383\n",
      "(2308, 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hassa\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:63: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "C:\\Users\\hassa\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:65: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prob 2308\n",
      "Dist Mat shape 2308\n",
      "Element shape 5383\n",
      "(2308, 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hassa\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:63: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "C:\\Users\\hassa\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:65: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metric ESP\n",
      "time 9:02:33.864999\n",
      "measure Accuracy\n",
      "+----------------+--------------------+\n",
      "| Experiment No. |      DataSet1      |\n",
      "+----------------+--------------------+\n",
      "|       1        | 0.9575389948006933 |\n",
      "|       2        | 0.9506065857885615 |\n",
      "|       3        | 0.9532062391681109 |\n",
      "|       4        | 0.9575389948006933 |\n",
      "|       5        | 0.9562391681109186 |\n",
      "|    Average     | 0.9550259965337954 |\n",
      "+----------------+--------------------+\n",
      "metric ESP\n",
      "time 9:02:33.864999\n",
      "measure Macro Precision\n",
      "+----------------+--------------------+\n",
      "| Experiment No. |      DataSet1      |\n",
      "+----------------+--------------------+\n",
      "|       1        | 0.9446825933343366 |\n",
      "|       2        | 0.9419892659131921 |\n",
      "|       3        | 0.9503447504102198 |\n",
      "|       4        | 0.9444625600846842 |\n",
      "|       5        | 0.9414211588448529 |\n",
      "|    Average     | 0.9445800657174571 |\n",
      "+----------------+--------------------+\n",
      "metric ESP\n",
      "time 9:02:33.864999\n",
      "measure Micro Precision\n",
      "+----------------+--------------------+\n",
      "| Experiment No. |      DataSet1      |\n",
      "+----------------+--------------------+\n",
      "|       1        | 0.9575389948006933 |\n",
      "|       2        | 0.9506065857885615 |\n",
      "|       3        | 0.9532062391681109 |\n",
      "|       4        | 0.9575389948006933 |\n",
      "|       5        | 0.9562391681109186 |\n",
      "|    Average     | 0.9550259965337954 |\n",
      "+----------------+--------------------+\n",
      "metric ESP\n",
      "time 9:02:33.864999\n",
      "measure Macro Recall\n",
      "+----------------+--------------------+\n",
      "| Experiment No. |      DataSet1      |\n",
      "+----------------+--------------------+\n",
      "|       1        | 0.8359394039392936 |\n",
      "|       2        | 0.8169952541764716 |\n",
      "|       3        | 0.8122118518116739 |\n",
      "|       4        | 0.8287680027513713 |\n",
      "|       5        | 0.7973402123432989 |\n",
      "|    Average     | 0.8182509450044219 |\n",
      "+----------------+--------------------+\n",
      "metric ESP\n",
      "time 9:02:33.864999\n",
      "measure Micro Recall\n",
      "+----------------+--------------------+\n",
      "| Experiment No. |      DataSet1      |\n",
      "+----------------+--------------------+\n",
      "|       1        | 0.9575389948006933 |\n",
      "|       2        | 0.9506065857885615 |\n",
      "|       3        | 0.9532062391681109 |\n",
      "|       4        | 0.9575389948006933 |\n",
      "|       5        | 0.9562391681109186 |\n",
      "|    Average     | 0.9550259965337954 |\n",
      "+----------------+--------------------+\n",
      "metric ESP\n",
      "time 9:02:33.864999\n",
      "measure F Measure\n",
      "+----------------+--------------------+\n",
      "| Experiment No. |      DataSet1      |\n",
      "+----------------+--------------------+\n",
      "|       1        | 0.8682263944457632 |\n",
      "|       2        | 0.856424212669527  |\n",
      "|       3        | 0.8459724154015278 |\n",
      "|       4        | 0.8669290757836156 |\n",
      "|       5        | 0.8257421578567357 |\n",
      "|    Average     | 0.8526588512314339 |\n",
      "+----------------+--------------------+\n",
      "metric ESP\n",
      "time 9:02:33.864999\n",
      "measure Micro F Measure\n",
      "+----------------+--------------------+\n",
      "| Experiment No. |      DataSet1      |\n",
      "+----------------+--------------------+\n",
      "|       1        | 0.9575389948006933 |\n",
      "|       2        | 0.9506065857885615 |\n",
      "|       3        | 0.9532062391681109 |\n",
      "|       4        | 0.9575389948006933 |\n",
      "|       5        | 0.9562391681109186 |\n",
      "|    Average     | 0.9550259965337954 |\n",
      "+----------------+--------------------+\n",
      "metric ESP\n",
      "time 9:02:33.864999\n",
      "measure ROC\n",
      "+----------------+--------------------+\n",
      "| Experiment No. |      DataSet1      |\n",
      "+----------------+--------------------+\n",
      "|       1        | 0.9140943732522648 |\n",
      "|       2        | 0.9037804819726156 |\n",
      "|       3        | 0.9014178560983046 |\n",
      "|       4        | 0.9104468738816265 |\n",
      "|       5        | 0.8946979728629867 |\n",
      "|    Average     | 0.9048875116135596 |\n",
      "+----------------+--------------------+\n",
      "###############\n",
      "###############\n",
      "###############\n",
      "prob 2308\n",
      "Dist Mat shape 2308\n",
      "Element shape 5383\n",
      "(2308, 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hassa\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:63: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prob 2308\n",
      "Dist Mat shape 2308\n",
      "Element shape 5383\n",
      "(2308, 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hassa\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:63: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "C:\\Users\\hassa\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prob 2308\n",
      "Dist Mat shape 2308\n",
      "Element shape 5383\n",
      "(2308, 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hassa\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:63: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prob 2308\n",
      "Dist Mat shape 2308\n",
      "Element shape 5383\n",
      "(2308, 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hassa\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:63: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prob 2308\n",
      "Dist Mat shape 2308\n",
      "Element shape 5383\n",
      "(2308, 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hassa\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:63: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metric EBLAB_SM\n",
      "time 2:03:35.365616\n",
      "measure Accuracy\n",
      "+----------------+--------------------+\n",
      "| Experiment No. |      DataSet1      |\n",
      "+----------------+--------------------+\n",
      "|       1        | 0.9566724436741768 |\n",
      "|       2        | 0.9527729636048526 |\n",
      "|       3        | 0.9545060658578857 |\n",
      "|       4        | 0.9553726169844021 |\n",
      "|       5        | 0.9549393414211439 |\n",
      "|    Average     | 0.9548526863084923 |\n",
      "+----------------+--------------------+\n",
      "metric EBLAB_SM\n",
      "time 2:03:35.365616\n",
      "measure Macro Precision\n",
      "+----------------+--------------------+\n",
      "| Experiment No. |      DataSet1      |\n",
      "+----------------+--------------------+\n",
      "|       1        | 0.9429445587585684 |\n",
      "|       2        | 0.8111790028271156 |\n",
      "|       3        | 0.9526173969143537 |\n",
      "|       4        | 0.9470530276195126 |\n",
      "|       5        | 0.8104955603203265 |\n",
      "|    Average     | 0.8928579092879753 |\n",
      "+----------------+--------------------+\n",
      "metric EBLAB_SM\n",
      "time 2:03:35.365616\n",
      "measure Micro Precision\n",
      "+----------------+--------------------+\n",
      "| Experiment No. |      DataSet1      |\n",
      "+----------------+--------------------+\n",
      "|       1        | 0.9566724436741768 |\n",
      "|       2        | 0.9527729636048526 |\n",
      "|       3        | 0.9545060658578857 |\n",
      "|       4        | 0.9553726169844021 |\n",
      "|       5        | 0.9549393414211439 |\n",
      "|    Average     | 0.9548526863084923 |\n",
      "+----------------+--------------------+\n",
      "metric EBLAB_SM\n",
      "time 2:03:35.365616\n",
      "measure Macro Recall\n",
      "+----------------+--------------------+\n",
      "| Experiment No. |      DataSet1      |\n",
      "+----------------+--------------------+\n",
      "|       1        | 0.8157116165905569 |\n",
      "|       2        | 0.7793423518100557 |\n",
      "|       3        | 0.8054195799992381 |\n",
      "|       4        | 0.8063683926298055 |\n",
      "|       5        | 0.7755327733271863 |\n",
      "|    Average     | 0.7964749428713686 |\n",
      "+----------------+--------------------+\n",
      "metric EBLAB_SM\n",
      "time 2:03:35.365616\n",
      "measure Micro Recall\n",
      "+----------------+--------------------+\n",
      "| Experiment No. |      DataSet1      |\n",
      "+----------------+--------------------+\n",
      "|       1        | 0.9566724436741768 |\n",
      "|       2        | 0.9527729636048526 |\n",
      "|       3        | 0.9545060658578857 |\n",
      "|       4        | 0.9553726169844021 |\n",
      "|       5        | 0.9549393414211439 |\n",
      "|    Average     | 0.9548526863084923 |\n",
      "+----------------+--------------------+\n",
      "metric EBLAB_SM\n",
      "time 2:03:35.365616\n",
      "measure F Measure\n",
      "+----------------+--------------------+\n",
      "| Experiment No. |      DataSet1      |\n",
      "+----------------+--------------------+\n",
      "|       1        | 0.8447788029860657 |\n",
      "|       2        | 0.7941139852326002 |\n",
      "|       3        | 0.8356782052523122 |\n",
      "|       4        | 0.8449564144759117 |\n",
      "|       5        | 0.7912997154967185 |\n",
      "|    Average     | 0.8221654246887218 |\n",
      "+----------------+--------------------+\n",
      "metric EBLAB_SM\n",
      "time 2:03:35.365616\n",
      "measure Micro F Measure\n",
      "+----------------+--------------------+\n",
      "| Experiment No. |      DataSet1      |\n",
      "+----------------+--------------------+\n",
      "|       1        | 0.9566724436741768 |\n",
      "|       2        | 0.9527729636048526 |\n",
      "|       3        | 0.9545060658578857 |\n",
      "|       4        | 0.9553726169844021 |\n",
      "|       5        | 0.9549393414211439 |\n",
      "|    Average     | 0.9548526863084923 |\n",
      "+----------------+--------------------+\n",
      "metric EBLAB_SM\n",
      "time 2:03:35.365616\n",
      "measure ROC\n",
      "+----------------+--------------------+\n",
      "| Experiment No. |      DataSet1      |\n",
      "+----------------+--------------------+\n",
      "|       1        | 0.9037874220135066 |\n",
      "|       2        | 0.8851126099243186 |\n",
      "|       3        | 0.898010153005837  |\n",
      "|       4        | 0.8989327292929287 |\n",
      "|       5        | 0.8836233995905857 |\n",
      "|    Average     | 0.8938932627654352 |\n",
      "+----------------+--------------------+\n",
      "###############\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hassa\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "def esmtp(doc1,doc2,var):\n",
    "    lemda=0.0001\n",
    "    a=set(list(np.nonzero(doc1 != 0)[0]))  #indices of non zero elements in doc1\n",
    "    b=set(list(np.nonzero(doc2 != 0)[0]))  #indices of non zero elements in doc2\n",
    "    intersection=a.intersection(b) # indices where both docs have non zero elements\n",
    "    union=a.union(b) # indices where either doc has non zero elements\n",
    "    l1=len(a-intersection) # doc1 !=0 and doc2=0\n",
    "    l2=len(b-intersection) # doc1 =0 and doc2!=0\n",
    "    Nstar=0\n",
    "    intersection=np.array(list(intersection))\n",
    "    if (len(intersection)>0):\n",
    "        term1=np.exp(-1*np.square(( doc1[intersection]-doc2[intersection] )/var[intersection]))\n",
    "        Nstar=np.sum(0.5* (1+term1)) +lemda* -1 *(l1+l2)\n",
    "    else:\n",
    "        Nstar=lemda* -1 *(l1+l2)   \n",
    "    Nunion=len(intersection)+l1+l2\n",
    "    smtp=0\n",
    "    if Nunion!=0:\n",
    "        smtp=((Nstar/Nunion)+lemda)/(1+lemda)\n",
    "    return smtp\n",
    "def NBCombined(train_data, train_labels,test_data,test_labels,metric):\n",
    "    #prediction of NB on test data\n",
    "    classes=list(set(train_labels))\n",
    "    global prob\n",
    "    prob1=prob[split]\n",
    "    y_pred=[]\n",
    "    print(\"prob\",len(prob1))\n",
    "    if len(prob1)==0:\n",
    "        ann = ANN(train_data, train_labels,test_data,test_labels)\n",
    "        y_pred,prob[split] = ann.fit(train_data, train_labels,test_data,test_labels,len(classes))\n",
    "        #y_pred = np.max(y_pred1,axis=1)\n",
    "    if metric==\"Base\":\n",
    "        return y_pred\n",
    "\n",
    "    classifier =SimMeaure(k=1,metric=metric)#,termOccurance=termOccurance,docOccurance=docOccurance)  \n",
    "    classifier.fit(train_data, train_labels)\n",
    "    distMatrix = classifier.predict(test_data) \n",
    "    print(\"Dist Mat shape\", len(distMatrix))\n",
    "    print(\"Element shape\", len(distMatrix[0]))\n",
    "    distList=[]\n",
    "    predLabels=[]\n",
    "    nn=10\n",
    "    prob1=np.array(prob1)\n",
    "    print(prob1.shape)\n",
    "    indices=[]\n",
    "    for cl in range(0,len(classes)):\n",
    "            indices.append([l for l in range(0,len(train_labels)) if train_labels[l]==classes[cl]])\n",
    "    \n",
    "    for tst in range(0,test_data.shape[0]):\n",
    "        probNb=np.array(prob1[tst,:])\n",
    "        simAvg=[]\n",
    "        simValue=np.array(distMatrix[tst])\n",
    "        \n",
    "        #neigh_labels=np.array(train_labels)[neigh]\n",
    "        for cl in range(0,len(classes)):\n",
    "            cl_ind=indices[cl]\n",
    "            sim=simValue[cl_ind]\n",
    "            if nn<=len(sim):\n",
    "                neigh= np.argpartition(np.array(sim), len(sim) - nn)[-nn:]\n",
    "            else:\n",
    "                nnn=len(sim)\n",
    "                neigh= np.argpartition(np.array(sim), len(sim) - nnn)[-nnn:]\n",
    "            avg=np.nansum(sim[[neigh]])\n",
    "            simAvg.append(avg)\n",
    "        simAvg=(np.array(simAvg))/(np.nansum(simAvg))\n",
    "        #print(probNb)\n",
    "        totalValue=np.add(probNb, simAvg)\n",
    "       # totalValue=simAvg\n",
    "        #print(\"combined value is\",totalValue)\n",
    "        lblInd=np.where(totalValue == np.max(totalValue))\n",
    "        ind1=0\n",
    "        if len(lblInd[0])>0:\n",
    "            ind1=(lblInd[0])[0]\n",
    "       # print(ind1)\n",
    "       # print(lbl)\n",
    "        predLabels.append(ind1)      \n",
    "\n",
    "    return predLabels\n",
    "#\"Cosine\",\"Jaccard\", \"bhatta\",\"EPairwise\" ,\"EPDSM\",\"PCC\",\"STB_SM_new\",\n",
    "measures=[\"esmtp\",\"EISC\",\"EDice\",\"ESP\",\"EBLAB_SM\"]\n",
    "\n",
    "for met in measures:\n",
    "    print(\"###############\")\n",
    "    fname='table_'+dataset+'_ANN_'+met+'_Tfidf_5Exp.txt'\n",
    "    tables = open(fname, 'w')\n",
    "    tables.write(\"No. of features\\t\"+str(n)+\"\\n\")\n",
    "    print(\"###############\")\n",
    "    accuracy_avg=[]\n",
    "    macroP_avg=[]\n",
    "    microP_avg=[]\n",
    "    macroR_avg=[]\n",
    "    microR_avg=[]\n",
    "    macroFMeasure_avg=[]\n",
    "    microFMeasure_avg=[]\n",
    "    roc_avg=[]\n",
    "    split=0\n",
    "    if met==\"smtp\" or met==\"esmtp\" or met==\"DSM\":\n",
    "        var1=np.var(arr,axis=0).reshape(-1,1).ravel()\n",
    "        var=np.asarray(var1).ravel()\n",
    "    rand_state=[0,1,10,42,30]\n",
    "    time1=time.time()\n",
    "    for i in range(0,k_splits):\n",
    "        xTrain, xTest, yTrain, yTest = train_test_split(arr, labels, test_size = 0.3, random_state = rand_state[i],stratify=labels)\n",
    "        train_data=np.array(xTrain)\n",
    "        test_data=np.array(xTest)\n",
    "        train_labels=yTrain\n",
    "        test_labels=yTest\n",
    "        classify(metric=met) \n",
    "        split+=1\n",
    "\n",
    "    time2=time.time()\n",
    "    #Accuracy\n",
    "    PrintDetails(metric=met,time=str(timedelta(seconds=(time2-time1))),measure=\"Accuracy\",Arr=accuracy_avg)\n",
    "    #Precision\n",
    "    PrintDetails(metric=met,time=str(timedelta(seconds=(time2-time1))),measure=\"Macro Precision\",Arr=macroP_avg)\n",
    "    PrintDetails(metric=met,time=str(timedelta(seconds=(time2-time1))),measure=\"Micro Precision\",Arr=microP_avg)\n",
    "    #Recall\n",
    "    PrintDetails(metric=met,time=str(timedelta(seconds=(time2-time1))),measure=\"Macro Recall\",Arr=macroR_avg)\n",
    "    PrintDetails(metric=met,time=str(timedelta(seconds=(time2-time1))),measure=\"Micro Recall\",Arr=microR_avg)\n",
    "    #f measure\n",
    "    PrintDetails(metric=met,time=str(timedelta(seconds=(time2-time1))),measure=\"F Measure\",Arr=macroFMeasure_avg)\n",
    "\n",
    "    #f measure\n",
    "    PrintDetails(metric=met,time=str(timedelta(seconds=(time2-time1))),measure=\"Micro F Measure\",Arr=microFMeasure_avg)\n",
    "\n",
    "    #roc\n",
    "    PrintDetails(metric=met,time=str(timedelta(seconds=(time2-time1))),measure=\"ROC\",Arr=roc_avg)\n",
    "    tables.close()\n",
    "    print(\"###############\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 3], dtype=int64),)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "totalValue=[0, np.nan, np.nan, 0]\n",
    "np.where(totalValue == np.nanmax(totalValue))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

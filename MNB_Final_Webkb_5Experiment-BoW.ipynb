{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "webkb-data.gtar\\webkb\n",
      "4199\n",
      "4199\n",
      "4199\n",
      "vectorize\n",
      "fit transform\n",
      "['course', 'faculty', 'project', 'student']\n",
      "###############\n",
      "###############\n",
      "Dist Mat shape 1260\n",
      "Element shape 2939\n",
      "Dist Mat shape 1260\n",
      "Element shape 2939\n",
      "Dist Mat shape 1260\n",
      "Element shape 2939\n",
      "Dist Mat shape 1260\n",
      "Element shape 2939\n",
      "Dist Mat shape 1260\n",
      "Element shape 2939\n",
      "metric PCC\n",
      "time 3:37:52.512517\n",
      "measure Accuracy\n",
      "+----------------+--------------------+\n",
      "| Experiment No. |      DataSet1      |\n",
      "+----------------+--------------------+\n",
      "|       1        | 0.8420634920634921 |\n",
      "|       2        | 0.8468253968253968 |\n",
      "|       3        | 0.8293650793650794 |\n",
      "|       4        | 0.830952380952381  |\n",
      "|       5        | 0.8404761904761905 |\n",
      "|    Average     | 0.837936507936508  |\n",
      "+----------------+--------------------+\n",
      "metric PCC\n",
      "time 3:37:52.512517\n",
      "measure Macro Precision\n",
      "+----------------+--------------------+\n",
      "| Experiment No. |      DataSet1      |\n",
      "+----------------+--------------------+\n",
      "|       1        | 0.8337270606673591 |\n",
      "|       2        | 0.8573840514317137 |\n",
      "|       3        |  0.83187697553873  |\n",
      "|       4        | 0.835315238684847  |\n",
      "|       5        | 0.8393402661815885 |\n",
      "|    Average     | 0.8395287185008478 |\n",
      "+----------------+--------------------+\n",
      "metric PCC\n",
      "time 3:37:52.512517\n",
      "measure Micro Precision\n",
      "+----------------+--------------------+\n",
      "| Experiment No. |      DataSet1      |\n",
      "+----------------+--------------------+\n",
      "|       1        | 0.8420634920634921 |\n",
      "|       2        | 0.8468253968253968 |\n",
      "|       3        | 0.8293650793650794 |\n",
      "|       4        | 0.830952380952381  |\n",
      "|       5        | 0.8404761904761905 |\n",
      "|    Average     | 0.837936507936508  |\n",
      "+----------------+--------------------+\n",
      "metric PCC\n",
      "time 3:37:52.512517\n",
      "measure Macro Recall\n",
      "+----------------+--------------------+\n",
      "| Experiment No. |      DataSet1      |\n",
      "+----------------+--------------------+\n",
      "|       1        | 0.8184052326931044 |\n",
      "|       2        | 0.8091746027299092 |\n",
      "|       3        | 0.8139216278271985 |\n",
      "|       4        | 0.8043524840617264 |\n",
      "|       5        | 0.8163345430825146 |\n",
      "|    Average     | 0.8124376980788905 |\n",
      "+----------------+--------------------+\n",
      "metric PCC\n",
      "time 3:37:52.512517\n",
      "measure Micro Recall\n",
      "+----------------+--------------------+\n",
      "| Experiment No. |      DataSet1      |\n",
      "+----------------+--------------------+\n",
      "|       1        | 0.8420634920634921 |\n",
      "|       2        | 0.8468253968253968 |\n",
      "|       3        | 0.8293650793650794 |\n",
      "|       4        | 0.830952380952381  |\n",
      "|       5        | 0.8404761904761905 |\n",
      "|    Average     | 0.837936507936508  |\n",
      "+----------------+--------------------+\n",
      "metric PCC\n",
      "time 3:37:52.512517\n",
      "measure F Measure\n",
      "+----------------+--------------------+\n",
      "| Experiment No. |      DataSet1      |\n",
      "+----------------+--------------------+\n",
      "|       1        | 0.8249496566599366 |\n",
      "|       2        | 0.8249931984404791 |\n",
      "|       3        | 0.8215214381850307 |\n",
      "|       4        | 0.8160071068344834 |\n",
      "|       5        | 0.8255083301202839 |\n",
      "|    Average     | 0.8225959460480426 |\n",
      "+----------------+--------------------+\n",
      "metric PCC\n",
      "time 3:37:52.512517\n",
      "measure Micro F Measure\n",
      "+----------------+--------------------+\n",
      "| Experiment No. |      DataSet1      |\n",
      "+----------------+--------------------+\n",
      "|       1        | 0.8420634920634921 |\n",
      "|       2        | 0.8468253968253968 |\n",
      "|       3        | 0.8293650793650794 |\n",
      "|       4        | 0.830952380952381  |\n",
      "|       5        | 0.8404761904761906 |\n",
      "|    Average     | 0.837936507936508  |\n",
      "+----------------+--------------------+\n",
      "metric PCC\n",
      "time 3:37:52.512517\n",
      "measure ROC\n",
      "+----------------+--------------------+\n",
      "| Experiment No. |      DataSet1      |\n",
      "+----------------+--------------------+\n",
      "|       1        | 0.8808189823303386 |\n",
      "|       2        | 0.8767454578140209 |\n",
      "|       3        | 0.8759092693112795 |\n",
      "|       4        | 0.8715817996265105 |\n",
      "|       5        | 0.8793439090831228 |\n",
      "|    Average     | 0.8768798836330545 |\n",
      "+----------------+--------------------+\n",
      "###############\n",
      "###############\n",
      "###############\n",
      "Dist Mat shape 1260\n",
      "Element shape 2939\n",
      "Dist Mat shape 1260\n",
      "Element shape 2939\n",
      "Dist Mat shape 1260\n",
      "Element shape 2939\n",
      "Dist Mat shape 1260\n",
      "Element shape 2939\n",
      "Dist Mat shape 1260\n",
      "Element shape 2939\n",
      "metric STB_SM_new\n",
      "time 1:23:42.178932\n",
      "measure Accuracy\n",
      "+----------------+--------------------+\n",
      "| Experiment No. |      DataSet1      |\n",
      "+----------------+--------------------+\n",
      "|       1        | 0.8428571428571429 |\n",
      "|       2        | 0.8531746031746031 |\n",
      "|       3        | 0.8301587301587302 |\n",
      "|       4        | 0.8373015873015873 |\n",
      "|       5        | 0.8373015873015873 |\n",
      "|    Average     | 0.8401587301587302 |\n",
      "+----------------+--------------------+\n",
      "metric STB_SM_new\n",
      "time 1:23:42.178932\n",
      "measure Macro Precision\n",
      "+----------------+--------------------+\n",
      "| Experiment No. |      DataSet1      |\n",
      "+----------------+--------------------+\n",
      "|       1        | 0.8354695872294544 |\n",
      "|       2        | 0.8599757154211678 |\n",
      "|       3        | 0.8325941919008918 |\n",
      "|       4        | 0.8470389282922061 |\n",
      "|       5        | 0.8391848672358954 |\n",
      "|    Average     | 0.842852658015923  |\n",
      "+----------------+--------------------+\n",
      "metric STB_SM_new\n",
      "time 1:23:42.178932\n",
      "measure Micro Precision\n",
      "+----------------+--------------------+\n",
      "| Experiment No. |      DataSet1      |\n",
      "+----------------+--------------------+\n",
      "|       1        | 0.8428571428571429 |\n",
      "|       2        | 0.8531746031746031 |\n",
      "|       3        | 0.8301587301587302 |\n",
      "|       4        | 0.8373015873015873 |\n",
      "|       5        | 0.8373015873015873 |\n",
      "|    Average     | 0.8401587301587302 |\n",
      "+----------------+--------------------+\n",
      "metric STB_SM_new\n",
      "time 1:23:42.178932\n",
      "measure Macro Recall\n",
      "+----------------+--------------------+\n",
      "| Experiment No. |      DataSet1      |\n",
      "+----------------+--------------------+\n",
      "|       1        | 0.8153678759347608 |\n",
      "|       2        | 0.8142257100242881 |\n",
      "|       3        | 0.8123548919607332 |\n",
      "|       4        | 0.8075943567241587 |\n",
      "|       5        | 0.8083035842994399 |\n",
      "|    Average     | 0.8115692837886762 |\n",
      "+----------------+--------------------+\n",
      "metric STB_SM_new\n",
      "time 1:23:42.178932\n",
      "measure Micro Recall\n",
      "+----------------+--------------------+\n",
      "| Experiment No. |      DataSet1      |\n",
      "+----------------+--------------------+\n",
      "|       1        | 0.8428571428571429 |\n",
      "|       2        | 0.8531746031746031 |\n",
      "|       3        | 0.8301587301587302 |\n",
      "|       4        | 0.8373015873015873 |\n",
      "|       5        | 0.8373015873015873 |\n",
      "|    Average     | 0.8401587301587302 |\n",
      "+----------------+--------------------+\n",
      "metric STB_SM_new\n",
      "time 1:23:42.178932\n",
      "measure F Measure\n",
      "+----------------+--------------------+\n",
      "| Experiment No. |      DataSet1      |\n",
      "+----------------+--------------------+\n",
      "|       1        | 0.8237952510101918 |\n",
      "|       2        | 0.8299398742561954 |\n",
      "|       3        | 0.8213083585433251 |\n",
      "|       4        | 0.8218587180308857 |\n",
      "|       5        | 0.8200710434273392 |\n",
      "|    Average     | 0.8233946490535875 |\n",
      "+----------------+--------------------+\n",
      "metric STB_SM_new\n",
      "time 1:23:42.178932\n",
      "measure Micro F Measure\n",
      "+----------------+--------------------+\n",
      "| Experiment No. |      DataSet1      |\n",
      "+----------------+--------------------+\n",
      "|       1        | 0.8428571428571429 |\n",
      "|       2        | 0.853174603174603  |\n",
      "|       3        | 0.8301587301587302 |\n",
      "|       4        | 0.8373015873015873 |\n",
      "|       5        | 0.8373015873015873 |\n",
      "|    Average     | 0.8401587301587302 |\n",
      "+----------------+--------------------+\n",
      "metric STB_SM_new\n",
      "time 1:23:42.178932\n",
      "measure ROC\n",
      "+----------------+--------------------+\n",
      "| Experiment No. |      DataSet1      |\n",
      "+----------------+--------------------+\n",
      "|       1        | 0.8792544499871764 |\n",
      "|       2        | 0.8804309311472024 |\n",
      "|       3        | 0.8752116328179543 |\n",
      "|       4        | 0.8740611048615088 |\n",
      "|       5        | 0.8744853813236233 |\n",
      "|    Average     | 0.8766887000274931 |\n",
      "+----------------+--------------------+\n",
      "###############\n",
      "###############\n",
      "###############\n",
      "Vrainace is [0.         0.00034014 0.05390496 ... 0.00068004 0.00034014 0.00034014]\n",
      "Dist Mat shape 1260\n",
      "Element shape 2939\n",
      "Vrainace is [0.         0.00034014 0.08686111 ... 0.00271785 0.00340067 0.        ]\n",
      "Dist Mat shape 1260\n",
      "Element shape 2939\n",
      "Vrainace is [0.00034014 0.00034014 0.05464659 ... 0.00237887 0.         0.00034014]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dist Mat shape 1260\n",
      "Element shape 2939\n",
      "Vrainace is [0.00034014 0.00034014 0.04354227 ... 0.00203966 0.00034014 0.00034014]\n",
      "Dist Mat shape 1260\n",
      "Element shape 2939\n",
      "Vrainace is [0.00034014 0.00034014 0.05020838 ... 0.00169836 0.00306122 0.00034014]\n",
      "Dist Mat shape 1260\n",
      "Element shape 2939\n",
      "metric esmtp\n",
      "time 1:06:26.859680\n",
      "measure Accuracy\n",
      "+----------------+--------------------+\n",
      "| Experiment No. |      DataSet1      |\n",
      "+----------------+--------------------+\n",
      "|       1        | 0.8547619047619047 |\n",
      "|       2        | 0.8563492063492063 |\n",
      "|       3        | 0.8373015873015873 |\n",
      "|       4        | 0.8452380952380952 |\n",
      "|       5        | 0.8523809523809524 |\n",
      "|    Average     | 0.8492063492063492 |\n",
      "+----------------+--------------------+\n",
      "metric esmtp\n",
      "time 1:06:26.859680\n",
      "measure Macro Precision\n",
      "+----------------+--------------------+\n",
      "| Experiment No. |      DataSet1      |\n",
      "+----------------+--------------------+\n",
      "|       1        | 0.8528842818529119 |\n",
      "|       2        | 0.8701020652133438 |\n",
      "|       3        | 0.8470246551571187 |\n",
      "|       4        | 0.8539494303018824 |\n",
      "|       5        | 0.8572018844822464 |\n",
      "|    Average     | 0.8562324634015006 |\n",
      "+----------------+--------------------+\n",
      "metric esmtp\n",
      "time 1:06:26.859680\n",
      "measure Micro Precision\n",
      "+----------------+--------------------+\n",
      "| Experiment No. |      DataSet1      |\n",
      "+----------------+--------------------+\n",
      "|       1        | 0.8547619047619047 |\n",
      "|       2        | 0.8563492063492063 |\n",
      "|       3        | 0.8373015873015873 |\n",
      "|       4        | 0.8452380952380952 |\n",
      "|       5        | 0.8523809523809524 |\n",
      "|    Average     | 0.8492063492063492 |\n",
      "+----------------+--------------------+\n",
      "metric esmtp\n",
      "time 1:06:26.859680\n",
      "measure Macro Recall\n",
      "+----------------+--------------------+\n",
      "| Experiment No. |      DataSet1      |\n",
      "+----------------+--------------------+\n",
      "|       1        | 0.8267970795569637 |\n",
      "|       2        | 0.8160560554610334 |\n",
      "|       3        | 0.8170176533911078 |\n",
      "|       4        | 0.813387915873334  |\n",
      "|       5        | 0.8220027538457806 |\n",
      "|    Average     | 0.819052291625644  |\n",
      "+----------------+--------------------+\n",
      "metric esmtp\n",
      "time 1:06:26.859680\n",
      "measure Micro Recall\n",
      "+----------------+--------------------+\n",
      "| Experiment No. |      DataSet1      |\n",
      "+----------------+--------------------+\n",
      "|       1        | 0.8547619047619047 |\n",
      "|       2        | 0.8563492063492063 |\n",
      "|       3        | 0.8373015873015873 |\n",
      "|       4        | 0.8452380952380952 |\n",
      "|       5        | 0.8523809523809524 |\n",
      "|    Average     | 0.8492063492063492 |\n",
      "+----------------+--------------------+\n",
      "metric esmtp\n",
      "time 1:06:26.859680\n",
      "measure F Measure\n",
      "+----------------+--------------------+\n",
      "| Experiment No. |      DataSet1      |\n",
      "+----------------+--------------------+\n",
      "|       1        | 0.8376263366262561 |\n",
      "|       2        | 0.8331309676447491 |\n",
      "|       3        | 0.8299043014296674 |\n",
      "|       4        | 0.8279400229469199 |\n",
      "|       5        | 0.8354758441225012 |\n",
      "|    Average     | 0.8328154945540188 |\n",
      "+----------------+--------------------+\n",
      "metric esmtp\n",
      "time 1:06:26.859680\n",
      "measure Micro F Measure\n",
      "+----------------+--------------------+\n",
      "| Experiment No. |      DataSet1      |\n",
      "+----------------+--------------------+\n",
      "|       1        | 0.8547619047619046 |\n",
      "|       2        | 0.8563492063492063 |\n",
      "|       3        | 0.8373015873015873 |\n",
      "|       4        | 0.8452380952380952 |\n",
      "|       5        | 0.8523809523809524 |\n",
      "|    Average     | 0.8492063492063492 |\n",
      "+----------------+--------------------+\n",
      "metric esmtp\n",
      "time 1:06:26.859680\n",
      "measure ROC\n",
      "+----------------+--------------------+\n",
      "| Experiment No. |      DataSet1      |\n",
      "+----------------+--------------------+\n",
      "|       1        | 0.8869990832991876 |\n",
      "|       2        | 0.8817547089828146 |\n",
      "|       3        | 0.8784868996532662 |\n",
      "|       4        | 0.8783627701508064 |\n",
      "|       5        | 0.8839296374260172 |\n",
      "|    Average     | 0.8819066199024184 |\n",
      "+----------------+--------------------+\n",
      "###############\n",
      "###############\n",
      "###############\n",
      "Dist Mat shape 1260\n",
      "Element shape 2939\n",
      "Dist Mat shape 1260\n",
      "Element shape 2939\n",
      "Dist Mat shape 1260\n",
      "Element shape 2939\n",
      "Dist Mat shape 1260\n",
      "Element shape 2939\n",
      "Dist Mat shape 1260\n",
      "Element shape 2939\n",
      "metric EISC\n",
      "time 1:32:04.130375\n",
      "measure Accuracy\n",
      "+----------------+--------------------+\n",
      "| Experiment No. |      DataSet1      |\n",
      "+----------------+--------------------+\n",
      "|       1        | 0.8484126984126984 |\n",
      "|       2        | 0.8507936507936508 |\n",
      "|       3        | 0.8333333333333334 |\n",
      "|       4        | 0.8333333333333334 |\n",
      "|       5        | 0.8404761904761905 |\n",
      "|    Average     | 0.8412698412698413 |\n",
      "+----------------+--------------------+\n",
      "metric EISC\n",
      "time 1:32:04.130375\n",
      "measure Macro Precision\n",
      "+----------------+--------------------+\n",
      "| Experiment No. |      DataSet1      |\n",
      "+----------------+--------------------+\n",
      "|       1        | 0.8424718918954005 |\n",
      "|       2        | 0.8603125096347584 |\n",
      "|       3        | 0.8349055702002365 |\n",
      "|       4        | 0.8420651117536324 |\n",
      "|       5        | 0.8429953376337127 |\n",
      "|    Average     | 0.844550084223548  |\n",
      "+----------------+--------------------+\n",
      "metric EISC\n",
      "time 1:32:04.130375\n",
      "measure Micro Precision\n",
      "+----------------+--------------------+\n",
      "| Experiment No. |      DataSet1      |\n",
      "+----------------+--------------------+\n",
      "|       1        | 0.8484126984126984 |\n",
      "|       2        | 0.8507936507936508 |\n",
      "|       3        | 0.8333333333333334 |\n",
      "|       4        | 0.8333333333333334 |\n",
      "|       5        | 0.8404761904761905 |\n",
      "|    Average     | 0.8412698412698413 |\n",
      "+----------------+--------------------+\n",
      "metric EISC\n",
      "time 1:32:04.130375\n",
      "measure Macro Recall\n",
      "+----------------+--------------------+\n",
      "| Experiment No. |      DataSet1      |\n",
      "+----------------+--------------------+\n",
      "|       1        | 0.8224803719459267 |\n",
      "|       2        | 0.809277166728046  |\n",
      "|       3        | 0.815469640609153  |\n",
      "|       4        | 0.8019033615731201 |\n",
      "|       5        | 0.8126542134686078 |\n",
      "|    Average     | 0.8123569508649707 |\n",
      "+----------------+--------------------+\n",
      "metric EISC\n",
      "time 1:32:04.130375\n",
      "measure Micro Recall\n",
      "+----------------+--------------------+\n",
      "| Experiment No. |      DataSet1      |\n",
      "+----------------+--------------------+\n",
      "|       1        | 0.8484126984126984 |\n",
      "|       2        | 0.8507936507936508 |\n",
      "|       3        | 0.8333333333333334 |\n",
      "|       4        | 0.8333333333333334 |\n",
      "|       5        | 0.8404761904761905 |\n",
      "|    Average     | 0.8412698412698413 |\n",
      "+----------------+--------------------+\n",
      "metric EISC\n",
      "time 1:32:04.130375\n",
      "measure F Measure\n",
      "+----------------+--------------------+\n",
      "| Experiment No. |      DataSet1      |\n",
      "+----------------+--------------------+\n",
      "|       1        | 0.8308361747553366 |\n",
      "|       2        | 0.8254965813116304 |\n",
      "|       3        | 0.8239660916724822 |\n",
      "|       4        |  0.81631762161393  |\n",
      "|       5        | 0.8243190533699931 |\n",
      "|    Average     | 0.8241871045446745 |\n",
      "+----------------+--------------------+\n",
      "metric EISC\n",
      "time 1:32:04.130375\n",
      "measure Micro F Measure\n",
      "+----------------+--------------------+\n",
      "| Experiment No. |      DataSet1      |\n",
      "+----------------+--------------------+\n",
      "|       1        | 0.8484126984126984 |\n",
      "|       2        | 0.8507936507936508 |\n",
      "|       3        | 0.8333333333333334 |\n",
      "|       4        | 0.8333333333333334 |\n",
      "|       5        | 0.8404761904761906 |\n",
      "|    Average     | 0.8412698412698413 |\n",
      "+----------------+--------------------+\n",
      "metric EISC\n",
      "time 1:32:04.130375\n",
      "measure ROC\n",
      "+----------------+--------------------+\n",
      "| Experiment No. |      DataSet1      |\n",
      "+----------------+--------------------+\n",
      "|       1        | 0.8838801888701542 |\n",
      "|       2        | 0.8774578656680387 |\n",
      "|       3        | 0.8774257284974023 |\n",
      "|       4        | 0.8705060919832333 |\n",
      "|       5        | 0.8772898725951749 |\n",
      "|    Average     | 0.8773119495228008 |\n",
      "+----------------+--------------------+\n",
      "###############\n",
      "###############\n",
      "###############\n",
      "Dist Mat shape 1260\n",
      "Element shape 2939\n",
      "Dist Mat shape 1260\n",
      "Element shape 2939\n",
      "Dist Mat shape 1260\n",
      "Element shape 2939\n",
      "Dist Mat shape 1260\n",
      "Element shape 2939\n",
      "Dist Mat shape 1260\n",
      "Element shape 2939\n",
      "metric EDice\n",
      "time 0:57:21.108390\n",
      "measure Accuracy\n",
      "+----------------+--------------------+\n",
      "| Experiment No. |      DataSet1      |\n",
      "+----------------+--------------------+\n",
      "|       1        | 0.8428571428571429 |\n",
      "|       2        | 0.8531746031746031 |\n",
      "|       3        | 0.8301587301587302 |\n",
      "|       4        | 0.8428571428571429 |\n",
      "|       5        | 0.8507936507936508 |\n",
      "|    Average     | 0.843968253968254  |\n",
      "+----------------+--------------------+\n",
      "metric EDice\n",
      "time 0:57:21.108390\n",
      "measure Macro Precision\n",
      "+----------------+--------------------+\n",
      "| Experiment No. |      DataSet1      |\n",
      "+----------------+--------------------+\n",
      "|       1        | 0.8399007201620315 |\n",
      "|       2        | 0.8659080735372635 |\n",
      "|       3        | 0.8344631374214937 |\n",
      "|       4        | 0.8505227648866145 |\n",
      "|       5        | 0.8581287785068994 |\n",
      "|    Average     | 0.8497846949028606 |\n",
      "+----------------+--------------------+\n",
      "metric EDice\n",
      "time 0:57:21.108390\n",
      "measure Micro Precision\n",
      "+----------------+--------------------+\n",
      "| Experiment No. |      DataSet1      |\n",
      "+----------------+--------------------+\n",
      "|       1        | 0.8428571428571429 |\n",
      "|       2        | 0.8531746031746031 |\n",
      "|       3        | 0.8301587301587302 |\n",
      "|       4        | 0.8428571428571429 |\n",
      "|       5        | 0.8507936507936508 |\n",
      "|    Average     | 0.843968253968254  |\n",
      "+----------------+--------------------+\n",
      "metric EDice\n",
      "time 0:57:21.108390\n",
      "measure Macro Recall\n",
      "+----------------+--------------------+\n",
      "| Experiment No. |      DataSet1      |\n",
      "+----------------+--------------------+\n",
      "|       1        | 0.8144724306792755 |\n",
      "|       2        | 0.8139471351090389 |\n",
      "|       3        | 0.8112063622131409 |\n",
      "|       4        | 0.8137747192378866 |\n",
      "|       5        | 0.8219023444392806 |\n",
      "|    Average     | 0.8150605983357245 |\n",
      "+----------------+--------------------+\n",
      "metric EDice\n",
      "time 0:57:21.108390\n",
      "measure Micro Recall\n",
      "+----------------+--------------------+\n",
      "| Experiment No. |      DataSet1      |\n",
      "+----------------+--------------------+\n",
      "|       1        | 0.8428571428571429 |\n",
      "|       2        | 0.8531746031746031 |\n",
      "|       3        | 0.8301587301587302 |\n",
      "|       4        | 0.8428571428571429 |\n",
      "|       5        | 0.8507936507936508 |\n",
      "|    Average     | 0.843968253968254  |\n",
      "+----------------+--------------------+\n",
      "metric EDice\n",
      "time 0:57:21.108390\n",
      "measure F Measure\n",
      "+----------------+--------------------+\n",
      "| Experiment No. |      DataSet1      |\n",
      "+----------------+--------------------+\n",
      "|       1        | 0.8250366386894239 |\n",
      "|       2        | 0.8304715671568027 |\n",
      "|       3        | 0.8214852705383506 |\n",
      "|       4        | 0.8272217458634467 |\n",
      "|       5        | 0.8356200878387785 |\n",
      "|    Average     | 0.8279670620173605 |\n",
      "+----------------+--------------------+\n",
      "metric EDice\n",
      "time 0:57:21.108390\n",
      "measure Micro F Measure\n",
      "+----------------+--------------------+\n",
      "| Experiment No. |      DataSet1      |\n",
      "+----------------+--------------------+\n",
      "|       1        | 0.8428571428571429 |\n",
      "|       2        | 0.853174603174603  |\n",
      "|       3        | 0.8301587301587302 |\n",
      "|       4        | 0.8428571428571429 |\n",
      "|       5        | 0.8507936507936508 |\n",
      "|    Average     | 0.843968253968254  |\n",
      "+----------------+--------------------+\n",
      "metric EDice\n",
      "time 0:57:21.108390\n",
      "measure ROC\n",
      "+----------------+--------------------+\n",
      "| Experiment No. |      DataSet1      |\n",
      "+----------------+--------------------+\n",
      "|       1        | 0.8786611305688825 |\n",
      "|       2        | 0.8801261614563904 |\n",
      "|       3        | 0.8744871545043332 |\n",
      "|       4        | 0.8781690779633016 |\n",
      "|       5        | 0.8835791631339435 |\n",
      "|    Average     | 0.8790045375253703 |\n",
      "+----------------+--------------------+\n",
      "###############\n",
      "###############\n",
      "###############\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dist Mat shape 1260\n",
      "Element shape 2939\n",
      "Dist Mat shape 1260\n",
      "Element shape 2939\n",
      "Dist Mat shape 1260\n",
      "Element shape 2939\n",
      "Dist Mat shape 1260\n",
      "Element shape 2939\n",
      "Dist Mat shape 1260\n",
      "Element shape 2939\n",
      "metric ESP\n",
      "time 10:32:30.895908\n",
      "measure Accuracy\n",
      "+----------------+--------------------+\n",
      "| Experiment No. |      DataSet1      |\n",
      "+----------------+--------------------+\n",
      "|       1        | 0.846031746031746  |\n",
      "|       2        |        0.85        |\n",
      "|       3        | 0.830952380952381  |\n",
      "|       4        | 0.8412698412698413 |\n",
      "|       5        | 0.8468253968253968 |\n",
      "|    Average     | 0.843015873015873  |\n",
      "+----------------+--------------------+\n",
      "metric ESP\n",
      "time 10:32:30.895908\n",
      "measure Macro Precision\n",
      "+----------------+--------------------+\n",
      "| Experiment No. |      DataSet1      |\n",
      "+----------------+--------------------+\n",
      "|       1        | 0.8352668369576601 |\n",
      "|       2        | 0.8570275392765802 |\n",
      "|       3        | 0.829042278707271  |\n",
      "|       4        | 0.8486781698852592 |\n",
      "|       5        | 0.8466040241381179 |\n",
      "|    Average     | 0.8433237697929776 |\n",
      "+----------------+--------------------+\n",
      "metric ESP\n",
      "time 10:32:30.895908\n",
      "measure Micro Precision\n",
      "+----------------+--------------------+\n",
      "| Experiment No. |      DataSet1      |\n",
      "+----------------+--------------------+\n",
      "|       1        | 0.846031746031746  |\n",
      "|       2        |        0.85        |\n",
      "|       3        | 0.830952380952381  |\n",
      "|       4        | 0.8412698412698413 |\n",
      "|       5        | 0.8468253968253968 |\n",
      "|    Average     | 0.843015873015873  |\n",
      "+----------------+--------------------+\n",
      "metric ESP\n",
      "time 10:32:30.895908\n",
      "measure Macro Recall\n",
      "+----------------+--------------------+\n",
      "| Experiment No. |      DataSet1      |\n",
      "+----------------+--------------------+\n",
      "|       1        | 0.8225770842613377 |\n",
      "|       2        | 0.8127404879996136 |\n",
      "|       3        | 0.8165538371000131 |\n",
      "|       4        | 0.8164962007468429 |\n",
      "|       5        | 0.8207249454925392 |\n",
      "|    Average     | 0.8178185111200694 |\n",
      "+----------------+--------------------+\n",
      "metric ESP\n",
      "time 10:32:30.895908\n",
      "measure Micro Recall\n",
      "+----------------+--------------------+\n",
      "| Experiment No. |      DataSet1      |\n",
      "+----------------+--------------------+\n",
      "|       1        | 0.846031746031746  |\n",
      "|       2        |        0.85        |\n",
      "|       3        | 0.830952380952381  |\n",
      "|       4        | 0.8412698412698413 |\n",
      "|       5        | 0.8468253968253968 |\n",
      "|    Average     | 0.843015873015873  |\n",
      "+----------------+--------------------+\n",
      "metric ESP\n",
      "time 10:32:30.895908\n",
      "measure F Measure\n",
      "+----------------+--------------------+\n",
      "| Experiment No. |      DataSet1      |\n",
      "+----------------+--------------------+\n",
      "|       1        | 0.827885600934541  |\n",
      "|       2        | 0.8276592649440352 |\n",
      "|       3        | 0.8219875039025896 |\n",
      "|       4        |  0.82887574786934  |\n",
      "|       5        | 0.8309972492388578 |\n",
      "|    Average     | 0.8274810733778727 |\n",
      "+----------------+--------------------+\n",
      "metric ESP\n",
      "time 10:32:30.895908\n",
      "measure Micro F Measure\n",
      "+----------------+--------------------+\n",
      "| Experiment No. |      DataSet1      |\n",
      "+----------------+--------------------+\n",
      "|       1        | 0.846031746031746  |\n",
      "|       2        |        0.85        |\n",
      "|       3        | 0.830952380952381  |\n",
      "|       4        | 0.8412698412698413 |\n",
      "|       5        | 0.8468253968253968 |\n",
      "|    Average     | 0.843015873015873  |\n",
      "+----------------+--------------------+\n",
      "metric ESP\n",
      "time 10:32:30.895908\n",
      "measure ROC\n",
      "+----------------+--------------------+\n",
      "| Experiment No. |      DataSet1      |\n",
      "+----------------+--------------------+\n",
      "|       1        | 0.8838184191289624 |\n",
      "|       2        | 0.8792567869986293 |\n",
      "|       3        | 0.8777443460903441 |\n",
      "|       4        | 0.879301214323474  |\n",
      "|       5        | 0.8825677922979437 |\n",
      "|    Average     | 0.8805377117678708 |\n",
      "+----------------+--------------------+\n",
      "###############\n",
      "###############\n",
      "###############\n",
      "Dist Mat shape 1260\n",
      "Element shape 2939\n",
      "Dist Mat shape 1260\n",
      "Element shape 2939\n",
      "Dist Mat shape 1260\n",
      "Element shape 2939\n",
      "Dist Mat shape 1260\n",
      "Element shape 2939\n",
      "Dist Mat shape 1260\n",
      "Element shape 2939\n",
      "metric EBLAB_SM\n",
      "time 1:31:48.702953\n",
      "measure Accuracy\n",
      "+----------------+--------------------+\n",
      "| Experiment No. |      DataSet1      |\n",
      "+----------------+--------------------+\n",
      "|       1        | 0.8492063492063492 |\n",
      "|       2        | 0.8531746031746031 |\n",
      "|       3        | 0.8333333333333334 |\n",
      "|       4        | 0.8388888888888889 |\n",
      "|       5        | 0.8476190476190476 |\n",
      "|    Average     | 0.8444444444444444 |\n",
      "+----------------+--------------------+\n",
      "metric EBLAB_SM\n",
      "time 1:31:48.702953\n",
      "measure Macro Precision\n",
      "+----------------+--------------------+\n",
      "| Experiment No. |      DataSet1      |\n",
      "+----------------+--------------------+\n",
      "|       1        | 0.8462399446463388 |\n",
      "|       2        | 0.8666266002739007 |\n",
      "|       3        | 0.8346568480333953 |\n",
      "|       4        | 0.8457067549017244 |\n",
      "|       5        | 0.8533988313199324 |\n",
      "|    Average     | 0.8493257958350584 |\n",
      "+----------------+--------------------+\n",
      "metric EBLAB_SM\n",
      "time 1:31:48.702953\n",
      "measure Micro Precision\n",
      "+----------------+--------------------+\n",
      "| Experiment No. |      DataSet1      |\n",
      "+----------------+--------------------+\n",
      "|       1        | 0.8492063492063492 |\n",
      "|       2        | 0.8531746031746031 |\n",
      "|       3        | 0.8333333333333334 |\n",
      "|       4        | 0.8388888888888889 |\n",
      "|       5        | 0.8476190476190476 |\n",
      "|    Average     | 0.8444444444444444 |\n",
      "+----------------+--------------------+\n",
      "metric EBLAB_SM\n",
      "time 1:31:48.702953\n",
      "measure Macro Recall\n",
      "+----------------+--------------------+\n",
      "| Experiment No. |      DataSet1      |\n",
      "+----------------+--------------------+\n",
      "|       1        | 0.8211598925844843 |\n",
      "|       2        | 0.8130150016116008 |\n",
      "|       3        | 0.8149448091888809 |\n",
      "|       4        | 0.8104544783810197 |\n",
      "|       5        | 0.818021196012374  |\n",
      "|    Average     | 0.8155190755556718 |\n",
      "+----------------+--------------------+\n",
      "metric EBLAB_SM\n",
      "time 1:31:48.702953\n",
      "measure Micro Recall\n",
      "+----------------+--------------------+\n",
      "| Experiment No. |      DataSet1      |\n",
      "+----------------+--------------------+\n",
      "|       1        | 0.8492063492063492 |\n",
      "|       2        | 0.8531746031746031 |\n",
      "|       3        | 0.8333333333333334 |\n",
      "|       4        | 0.8388888888888889 |\n",
      "|       5        | 0.8476190476190476 |\n",
      "|    Average     | 0.8444444444444444 |\n",
      "+----------------+--------------------+\n",
      "metric EBLAB_SM\n",
      "time 1:31:48.702953\n",
      "measure F Measure\n",
      "+----------------+--------------------+\n",
      "| Experiment No. |      DataSet1      |\n",
      "+----------------+--------------------+\n",
      "|       1        | 0.8313790828438961 |\n",
      "|       2        | 0.8303460688101363 |\n",
      "|       3        | 0.8235272099348284 |\n",
      "|       4        | 0.8230654511217053 |\n",
      "|       5        | 0.8315576611665738 |\n",
      "|    Average     | 0.8279750947754281 |\n",
      "+----------------+--------------------+\n",
      "metric EBLAB_SM\n",
      "time 1:31:48.702953\n",
      "measure Micro F Measure\n",
      "+----------------+--------------------+\n",
      "| Experiment No. |      DataSet1      |\n",
      "+----------------+--------------------+\n",
      "|       1        | 0.8492063492063493 |\n",
      "|       2        | 0.853174603174603  |\n",
      "|       3        | 0.8333333333333334 |\n",
      "|       4        | 0.8388888888888889 |\n",
      "|       5        | 0.8476190476190476 |\n",
      "|    Average     | 0.8444444444444444 |\n",
      "+----------------+--------------------+\n",
      "metric EBLAB_SM\n",
      "time 1:31:48.702953\n",
      "measure ROC\n",
      "+----------------+--------------------+\n",
      "| Experiment No. |      DataSet1      |\n",
      "+----------------+--------------------+\n",
      "|       1        | 0.8832046017506574 |\n",
      "|       2        | 0.8795969984177819 |\n",
      "|       3        | 0.8770953856245378 |\n",
      "|       4        | 0.8758913902548866 |\n",
      "|       5        | 0.8810436567905267 |\n",
      "|    Average     | 0.8793664065676781 |\n",
      "+----------------+--------------------+\n",
      "###############\n"
     ]
    }
   ],
   "source": [
    "# importing all the required modules\n",
    "\n",
    "from importlib import reload\n",
    "import nltk\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer\n",
    "import os\n",
    "import errno\n",
    "import string\n",
    "from nltk.corpus import reuters\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import FreqDist\n",
    "from nltk.text import TextCollection\n",
    "import collections\n",
    "import numpy as np\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from prettytable import PrettyTable\n",
    "import time\n",
    "from datetime import timedelta\n",
    "from sklearn.metrics import recall_score,precision_score,average_precision_score,f1_score,accuracy_score,roc_auc_score\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from imblearn.metrics import geometric_mean_score\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics.cluster import homogeneity_score,completeness_score\n",
    "import statistics\n",
    "import math\n",
    "import sklearn.metrics \n",
    "from sklearn.model_selection import KFold\n",
    "import csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "import math\n",
    "from scipy.spatial import distance\n",
    "import statistics\n",
    "from scipy.stats import pearsonr,entropy\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.naive_bayes import MultinomialNB,GaussianNB\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from scipy.io import arff\n",
    "from sklearn.naive_bayes import MultinomialNB,GaussianNB\n",
    "\n",
    "\n",
    "def loadWebKbData(path, documents,labels):\n",
    "    print(path)\n",
    "    for root, dirs, files in os.walk(path):  \n",
    "        for filename in files:\n",
    "            try:\n",
    "                #print root\n",
    "                name = os.path.join(root, filename)\n",
    "                #print name\n",
    "                end=len(name)-len(filename)\n",
    "                test=name[len(path)+1:end]\n",
    "                for i in range(0,len(test)):\n",
    "                    if test[i]=='\\\\':\n",
    "                        labels.append(test[0:i])\n",
    "                        break\n",
    "                f = open(name, \"rb\").read()\n",
    "                f=f.decode('ISO-8859-1', 'ignore')\n",
    "                content=str(f)\n",
    "                rawData.append(f)\n",
    "                soup = BeautifulSoup(content)\n",
    "                content=soup.get_text()\n",
    "                documents.append(content)  \n",
    "            except IOError as exc:\n",
    "                if exc.errno != errno.EISDIR:\n",
    "                       raise\n",
    "\n",
    "\n",
    "\n",
    "def most_common(lst):\n",
    "    return max(set(lst), key=lst.count)\n",
    "def tokenize1(documents):\n",
    "    tokens=[]\n",
    "    content= documents\n",
    "    tokens=(word_tokenize(content))\n",
    "    tokens= [token.lower() for token in tokens ]\n",
    "    tokens = [token for token in tokens if token not in stopwords]\n",
    "    tokens= [token for token in tokens if token.isalpha()]\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "    tokens= [token for token in tokens if len(token)>3 ]\n",
    "    return tokens\n",
    "def count_values_in_range(a, range_min, range_max):\n",
    "\n",
    "    # \"between\" returns a boolean Series equivalent to left <= series <= right.\n",
    "    # NA values will be treated as False.\n",
    "    return ((range_min <= a) & (a <= range_max)).sum()\n",
    "def display_scores(vectorizer, tfidf_result):\n",
    "    scores = zip(vectorizer.get_feature_names(),\n",
    "                 np.asarray(tfidf_result.sum(axis=0)).ravel())\n",
    "def sorted_tfs(tfs,n):\n",
    "    doc,terms=tfs.shape\n",
    "    ind=(np.argsort(-(np.asarray(tfs.sum(axis=0)).ravel())))\n",
    "    scores=np.zeros((doc,n))\n",
    "    for i in range(0,len(documents)):\n",
    "        for j in range(0,n):\n",
    "            if(tfs[i,ind[j]]!=0):\n",
    "                scores[i,j]=tfs[i,ind[j]]\n",
    "    return scores\n",
    "\n",
    "def dislay_tfidf(vectorizer,tfidf_result):\n",
    "    print(vectorizer.get_feature_names())\n",
    "    print(tfidf_result)\n",
    "def Manhattan(doc1,doc2):\n",
    "    return distance.cityblock(doc1,doc2)                       \n",
    "def Euclidean(a, b):#distance\n",
    "    return distance.euclidean(a,b)\n",
    "def Cosine(a, b):#distance\n",
    "    return distance.cosine(a,b)\n",
    "def Jaccard(a, b):#distance\n",
    "    return distance.jaccard(a,b)\n",
    "\n",
    "def bhatta(a,b):\n",
    "\n",
    "    length=len(a)\n",
    "    score = 0;\n",
    "    score=np.sum(np.sqrt( np.multiply(a,b) ))\n",
    "    distance=-1*np.log(score)\n",
    "    return distance;  \n",
    "\n",
    "def EPDSM(doc1,doc2):\n",
    "    a=set(np.nonzero(doc1!=0)[0])  #indices of non zero elements in doc1\n",
    "    b=set(np.nonzero(doc2!=0)[0])  #indices of non zero elements in doc2\n",
    "    intersection=np.sum(np.minimum(doc1,doc2))\n",
    "    union=np.sum(np.maximum(doc1,doc2))\n",
    "    PF=len(a.intersection(b))\n",
    "    M=len(doc1)\n",
    "    AF=M-len(a.union(b))\n",
    "    psdm=(intersection/union)*((PF+1)/(M-AF+1))\n",
    "    return psdm\n",
    "\n",
    "def EPairwise(a,b):\n",
    "    percentage=1 #100 percent\n",
    "    K1=np.count_nonzero(a)\n",
    "    K2=np.count_nonzero(b)\n",
    "    k=percentage*min(K1,K2)\n",
    "    setA=set(np.argpartition(a, len(a)-1 - k)[-k:])\n",
    "    setB=set(np.argpartition(b, len(b) -1- k)[-k:])\n",
    "    union=np.array(list(setA.union(setB)))\n",
    "    elementsA=a[union]\n",
    "    elementsB=b[union]\n",
    "    return distance.cosine(elementsA, elementsB)\n",
    "\n",
    "\n",
    "def Pairwise(a,b):\n",
    "    percentage=1 #100 percent\n",
    "    K1=np.count_nonzero(a)\n",
    "    K2=np.count_nonzero(b)\n",
    "    k=percentage*min(K1,K2)\n",
    "   # setA=set((-a).argsort()[:k])\n",
    "   # setB=set((-b).argsort()[:k])\n",
    "    \n",
    "    setA=set(np.argpartition(a, len(a)-1 - k)[-k:])\n",
    "    setB=set(np.argpartition(b, len(b)-1 - k)[-k:])\n",
    "    union=setA.union(setB)\n",
    "    elementsA=[a[ind] for ind in union]\n",
    "    elementsB=[b[ind] for ind in union]\n",
    "    dist= distance.cosine(elementsA, elementsB)\n",
    "    return dist\n",
    "\n",
    "def Dice(a, b):\n",
    "    a=[(a.astype(bool)).astype(int)]\n",
    "    b=[(b.astype(bool)).astype(int)]\n",
    "    return distance.dice(a,b)\n",
    "\n",
    "def EDice(doc1,doc2):\n",
    "    a=set(list(np.nonzero(doc1!=0)[0]))  #indices of non zero elements in doc1\n",
    "    b=set(list(np.nonzero(doc2!=0)[0]))  #indices of non zero elements in doc2\n",
    "    intr=len(a.intersection(b))\n",
    "    aComp=len(a-b)\n",
    "    bComp=len(b-a)\n",
    "    sim=0\n",
    "    if (intr+aComp+bComp)!=0:\n",
    "        sim=2*(intr/(2*(intr+aComp+bComp)))\n",
    "    return sim\n",
    "\n",
    "def smtp(doc1,doc2,var):\n",
    "    lemda=0.0001\n",
    "    a=set(np.nonzero(doc1)[0])  #indices of non zero elements in doc1\n",
    "    b=set(np.nonzero(doc2)[0])  #indices of non zero elements in doc2\n",
    "    intersection=a.intersection(b) # indices where both docs have non zero elements\n",
    "    union=a.union(b) # indices where either doc has non zero elements\n",
    "    d1=np.array(list(a-intersection)) # doc1 !=0 and doc2=0\n",
    "    d2=np.array(list(b-intersection)) # doc1 =0 and doc2!=0\n",
    "    doc1=np.array(doc1)\n",
    "    doc2=np.array(doc2)\n",
    "    Nstar=0\n",
    "    intersection=np.array(list(intersection))\n",
    "    if (len(intersection)>0):\n",
    "        term1=np.exp(-1*np.square(( doc1[intersection]-doc2[intersection] )/var[intersection]))\n",
    "        Nstar=sum(0.5* (1+term1)) +lemda* -1 *(len(d1)+len(d2))\n",
    "    else:\n",
    "        Nstar=lemda* -1 *(len(d1)+len(d2))   \n",
    "    Nunion=len(intersection)+len(d1)+len(d2)\n",
    "    smtp=0\n",
    "    if Nunion!=0:\n",
    "        smtp=((Nstar/Nunion)+lemda)/(1+lemda)\n",
    "    return smtp\n",
    "def esmtp(doc1,doc2,var):\n",
    "    lemda=1\n",
    "    a=set(list(np.nonzero(doc1 != 0)[0]))  #indices of non zero elements in doc1\n",
    "    b=set(list(np.nonzero(doc2 != 0)[0]))  #indices of non zero elements in doc2\n",
    "    intersection=a.intersection(b) # indices where both docs have non zero elements\n",
    "    union=a.union(b) # indices where either doc has non zero elements\n",
    "    l1=len(a-intersection) # doc1 !=0 and doc2=0\n",
    "    l2=len(b-intersection) # doc1 =0 and doc2!=0\n",
    "    Nstar=0\n",
    "    intersection=np.array(list(intersection))\n",
    "    if (len(intersection)>0):\n",
    "        term1=np.exp(-1*np.square(( doc1[intersection]-doc2[intersection] )/var[intersection]))\n",
    "        Nstar=np.sum(0.5* (1+term1)) +lemda* -1 *(l1+l2)\n",
    "    else:\n",
    "        Nstar=lemda* -1 *(l1+l2)   \n",
    "    Nunion=len(intersection)+l1+l2\n",
    "    smtp=((Nstar/Nunion)+lemda)/(1+lemda)\n",
    "    return smtp\n",
    "\n",
    "\n",
    "\n",
    "def EISC(doc1,doc2): \n",
    "    dot=np.sum(np.sqrt(np.multiply(doc1,doc2)))\n",
    "    isc=dot /( math.sqrt(np.linalg.norm(doc1, ord=1))*math.sqrt(np.linalg.norm(doc2, ord=1)))\n",
    "    return isc\n",
    "def STB_SM_new(doc1,doc2):\n",
    "    a=set(list(np.nonzero(doc1 != 0)[0]))  #indices of non zero elements in doc1\n",
    "    b=set(list(np.nonzero(doc2 != 0)[0]))  #indices of non zero elements in doc2\n",
    "    intersection=np.array(list(a.intersection(b)))\n",
    "    comp1=a-b\n",
    "    comp2=b-a   \n",
    "    comp1=np.array(list(comp1))\n",
    "    comp2=np.array(list(comp2))\n",
    "    X,Y,D1,D2,Z1,Z2,sim=0,0,0,0,0,0,0\n",
    "    if len(intersection)>0:\n",
    "        X=np.sum(doc1[intersection])\n",
    "        Y=np.sum(doc2[intersection])\n",
    "    if len(comp1)>0:\n",
    "        D1=np.sum(doc1[comp1])\n",
    "    if len(comp2)>0:\n",
    "        D2=np.sum(doc2[comp2])\n",
    "    Z1=np.sum(doc1)\n",
    "    Z2=np.sum(doc2) \n",
    "    if Z1!=0 and Z2!=0:\n",
    "        sim=((X*Y)/(Z1*Z2))*(1-((D1*D2)/(Z1*Z2)))\n",
    "    return sim\n",
    "def ECSM_P1(doc1,doc2):\n",
    "    simValue=0\n",
    "    N=len(doc1)#total_features;\n",
    "    a=set(list(np.nonzero(doc1 != 0)[0]))  #indices of non zero elements in doc1\n",
    "    b=set(list(np.nonzero(doc2 != 0)[0]))  #indices of non zero elements in doc2NSMT\n",
    "    Nab=len(a.intersection(b))\n",
    "    F=len(a.union(b))-Nab\n",
    "    simValue=(1-F/N)\n",
    "    return simValue\n",
    "def ECSM_P2(doc1,doc2):\n",
    "    a=set(list(np.nonzero(doc1 != 0)[0]))  #indices of non zero elements in doc1\n",
    "    b=set(list(np.nonzero(doc2 != 0)[0]))  #indices of non zero elements in doc2NSMT\n",
    "    sim=0\n",
    "    if (len(a)+len(b))!=0:\n",
    "        sim=(2*len(a.intersection(b)))/(len(a)+len(b))\n",
    "    return sim\n",
    "\n",
    "def EBLAB_SM(doc1,doc2):\n",
    "    return (0.5*(ECSM_P1(doc1,doc2)+ECSM_P2(doc1,doc2)))\n",
    "\n",
    "def PCC(a, b):\n",
    "    pcc, col=pearsonr(a,b)\n",
    "    return abs(pcc)\n",
    "def ESP(doc1,doc2):\n",
    "    a=set(list(np.nonzero(doc1!=0)[0]))  #indices of non zero elements in doc1\n",
    "    b=set(list(np.nonzero(doc2!=0)[0]))  #indices of non zero elements in doc2\n",
    "    nonzeroTerm=list(a.intersection(b))  #indices where both docs have non zero elemments\n",
    "    d1=doc1[nonzeroTerm] #doc1 values of doc1 intersection  doc2\n",
    "    d2=doc2[nonzeroTerm] #doc2 values of doc1 intersection  doc2\n",
    "    minArr=np.minimum(d1,d2) #minimum values  of d1 and d2\n",
    "    maxArr=np.maximum(d1,d2) #maximum values  of d1 and d2\n",
    "    ln=len(nonzeroTerm)\n",
    "    docCount=np.zeros(ln)\n",
    "    aData=allData[:,nonzeroTerm] #extracting data with only feature indices of doc1 intersection  doc2\n",
    "    for ti in range(0,ln):\n",
    "        docCount[ti]=count_values_in_range(aData[:,ti], minArr[ti], maxArr[ti]) #count values which lies between min and max\n",
    "    #norm factor which is ist part of equation 6 in paper\n",
    "    normFactor= len(a.union(b))#norm factor equal to length of doc1 union doc2\n",
    "    dCount=np.array(docCount[np.nonzero(docCount!=0)[0]])# get all non zero values between min and max\n",
    "    SP_val=0\n",
    "    if(normFactor!=0):\n",
    "        SP_val=np.sum(np.log(totalDocs/dCount)) #2nd part in equation 6 in paper\n",
    "        SP_val = (SP_val/normFactor) #equation 6 in paper\n",
    "    return SP_val\n",
    "\n",
    "class SimMeaure:\n",
    "\n",
    "    #constructor\n",
    "\n",
    "    def __init__(self,k = 1,metric=\"euclidean\",termOccurance=None, docOccurance=None):\n",
    "\n",
    "        \n",
    "        self.k=k\n",
    "        #print (\"KNN\",self.k)\n",
    "        self.metric=metric\n",
    "        self.trainingData=[]\n",
    "        self.trainLabels=[]\n",
    "        self.smtp=None\n",
    "        self.termOccurance=termOccurance\n",
    "        self.docOccurance=docOccurance\n",
    "         \n",
    "    \n",
    "         \n",
    "\n",
    "    def fit(self, training_data, trainLabels ):\n",
    "        self.trainingData=training_data\n",
    "        self.trainLabels=trainLabels\n",
    "        \n",
    "            \n",
    "       \n",
    "    def predict(self, testData):\n",
    "        train=self.trainingData\n",
    "        var=np.zeros(train.shape[1])\n",
    "        if(self.metric==\"smtp\" or  self.metric==\"esmtp\" or  self.metric==\"DSM\"):\n",
    "            var=np.var(train,axis=0)\n",
    "            print(\"Vrainace is\",var)\n",
    "        distList=[\"KL\",\"extendedJaccard\",\"bhatta\",\"Euclidean\",\"Cosine\",\"Jaccard\",\"JS\",\"EJS\",\"Dice\",\n",
    "                  \"Pairwise\",\"EPairwise\",\"Manhattan\",\"EnhancedJaccard\",\"EEnhancedJaccard\",\"eextendedJaccard\",\"EJS\",\"Minkowski\"]#distance\n",
    "        func=globals()[self.metric]\n",
    "        predLabel=[]\n",
    "        kList=[1,3,5,9,15,30,45,70,90,120]\n",
    "        for kk in range(0,len(kList)):\n",
    "            temp=[]\n",
    "            predLabel.append(temp)\n",
    "            ''''''\n",
    "        distMatrix=[]         \n",
    "        for i in(range(0,len(testData))):\n",
    "            #print(i)\n",
    "            dist=[]\n",
    "            for j in(range(0,len(train))):\n",
    "                if ((not np.any(testData[i])) or (not np.any( train[j]))):\n",
    "                    if(self.metric in distList):\n",
    "                        dist.append(-1)\n",
    "                    else:\n",
    "                        dist.append(0)\n",
    "                else:\n",
    "                    if(self.metric==\"smtp\" or self.metric==\"smtp_improved\" or self.metric==\"esmtp\" or self.metric==\"DSM\"):\n",
    "                        dist.append(func(testData[i],train[j],var)) \n",
    "                    \n",
    "                    elif(self.metric==\"SP\"):\n",
    "                        doc1=testData[i]\n",
    "                        doc2=train[j]\n",
    "                        nonzeroDoc1=set(np.nonzero(doc1)[0])\n",
    "                        nonzeroDoc2=set(np.nonzero(doc2)[0])\n",
    "                        nonzeroTerm=list(nonzeroDoc1.intersection(nonzeroDoc2))\n",
    "                        minArr=np.minimum(doc1[nonzeroTerm],doc2[nonzeroTerm])\n",
    "                        maxArr=np.maximum(doc1[nonzeroTerm],doc2[nonzeroTerm])\n",
    "                        ln=len(nonzeroTerm)\n",
    "                        aData=allData[:,nonzeroTerm]\n",
    "                        docCount=np.zeros(ln)\n",
    "                        for ti in range(0,ln):\n",
    "                            tData=pd.Series(aData[:,ti])\n",
    "                            docCount[ti]=count_values_in_range(tData, minArr[ti], maxArr[ti])\n",
    "                        dist.append(SP(testData[i],train[j],docCount,totalDocs))\n",
    "                    else:\n",
    "                        dist.append(func(testData[i], train[j]))\n",
    "            flag=-1\n",
    "            dist=list(dist)\n",
    "            if(self.metric in distList):\n",
    "                dist=[(1/(x+0.0001)) for x in dist]\n",
    "                flag=1\n",
    "            distMatrix.append(dist)\n",
    "        return distMatrix\n",
    "\n",
    "\n",
    "def classify(metric='Cosine',termOccurance=None, docOccurance=None):\n",
    "    time1= time.time()\n",
    "    y_pred =NBCombined(train_data, train_labels,test_data,metric)\n",
    "    time2= time.time()\n",
    "\n",
    "    \n",
    "    for i in range(0,1):\n",
    "        #Accuracy\n",
    "    \n",
    "        accuracy=accuracy_score(test_labels, y_pred)\n",
    "        \n",
    "        #Macro Precision\n",
    "        \n",
    "        macroP=precision_score(test_labels, y_pred,average='macro')\n",
    "        \n",
    "        #Micro Precision\n",
    "        \n",
    "        microP=precision_score(test_labels, y_pred,average='micro')\n",
    "        \n",
    "        #Macro Recall\n",
    "        \n",
    "        macroR=recall_score(test_labels, y_pred,average='macro')\n",
    "        \n",
    "        #Micro Recall\n",
    "        \n",
    "        microR=recall_score(test_labels, y_pred,average='micro')\n",
    "        \n",
    "        \n",
    "        fMeasure=f1_score(test_labels, y_pred,average='macro')\n",
    "       # PrintDetails(metric=metric,time=str(timedelta(seconds=(time2-time1))),measure=\"F Measure\",Arr=fMeasure)\n",
    "        \n",
    "        m_fMeasure=f1_score(test_labels, y_pred,average='micro')\n",
    "       # PrintDetails(metric=metric,time=str(timedelta(seconds=(time2-time1))),measure=\"F Measure\",Arr=fMeasure)\n",
    "        \n",
    "        #PrintDetails(metric=metric,time=str(timedelta(seconds=(time2-time1))),measure=\"g Measure\",Arr=gMeasure)\n",
    "      \n",
    "        test = label_binarize(test_labels, classes=categories)\n",
    "        pred = label_binarize( y_pred, classes=categories)\n",
    "        \n",
    "        #roc\n",
    "        roc=roc_auc_score(test, pred)\n",
    "    #Accuracy\n",
    "    accuracy_avg.append(accuracy)\n",
    "    #Precision\n",
    "    macroP_avg.append(macroP)\n",
    "    microP_avg.append(microP)\n",
    "    #recall\n",
    "    macroR_avg.append(macroR)\n",
    "    microR_avg.append(microR)\n",
    "    #F measure\n",
    "    macroFMeasure_avg.append(fMeasure)\n",
    "    microFMeasure_avg.append( m_fMeasure)\n",
    "    #Roc\n",
    "    roc_avg.append(roc)\n",
    "\n",
    "def PrintDetails(metric=\"smtp\",time=None,measure= \"Accuracy\",Arr=None):\n",
    "    x = PrettyTable()\n",
    "    kList=[1,3,5,9,15,30,45]\n",
    "    x.field_names = [\"Experiment No.\",\"DataSet1\"]\n",
    "    print(\"metric\",metric)\n",
    "    print(\"time\",time)\n",
    "    print(\"measure\",measure)\n",
    "    tables.write(\"metric\\t\"+str(metric)+\"\\n\")\n",
    "    tables.write(\"time\\t\"+str(time)+\"\\n\")\n",
    "    tables.write(\"measure\\t\"+str(measure)+\"\\n\")\n",
    "    average=0\n",
    "    for i in range(0,len(Arr)):\n",
    "        x.add_row([i+1,Arr[i]]) \n",
    "        average+=Arr[i]\n",
    "    x.add_row([\"Average\",average/len(Arr)])   \n",
    "    tables.write(str(x))\n",
    "    print (x)\n",
    "def NBCombined(train_data, train_labels,test_data,metric):\n",
    "    #prediction of NB on test data\n",
    "    nb = MultinomialNB(fit_prior=False).fit(train_data, train_labels)\n",
    "    if metric==\"Base\":\n",
    "        y_pred = nb.predict(test_data)\n",
    "        return y_pred\n",
    "    \n",
    "    prob=nb.predict_proba(test_data)\n",
    "    #y_pred = classifier.predict(test_data)\n",
    "    classifier =SimMeaure(k=1,metric=metric)#,termOccurance=termOccurance,docOccurance=docOccurance)  \n",
    "    classifier.fit(train_data, train_labels)\n",
    "    distMatrix = classifier.predict(test_data) \n",
    "    print(\"Dist Mat shape\", len(distMatrix))\n",
    "    print(\"Element shape\", len(distMatrix[0]))\n",
    "    distList=[]\n",
    "    classes=nb.classes_\n",
    "    predLabels=[]\n",
    "    nn=10\n",
    "    \n",
    "    \n",
    "    for tst in range(0,test_data.shape[0]):\n",
    "        probNb=np.array(prob[tst])\n",
    "        simAvg=[]\n",
    "        simValue=np.array(distMatrix[tst])\n",
    "        neigh= np.argpartition(np.array(simValue), len(simValue) - nn)[-nn:]\n",
    "        neigh_labels=np.array(train_labels)[neigh]\n",
    "        for cl in range(0,len(classes)):\n",
    "            indices=[ii for ii in range(0,len(neigh_labels)) if neigh_labels[ii]==classes[cl]]\n",
    "            avg=0\n",
    "            if len(indices)>0:\n",
    "                avg=np.nanmax(simValue[indices])\n",
    "            simAvg.append(avg)\n",
    "        \n",
    "        simAvg=(simAvg/np.nanmax(simAvg))\n",
    "        totalValue=np.add(probNb, simAvg)\n",
    "       # totalValue=simAvg\n",
    "        #print(\"combined value is\",totalValue)\n",
    "        lblInd=np.where(totalValue == np.max(totalValue))\n",
    "        ind1=0\n",
    "        if len(lblInd[0])>0:\n",
    "            ind1=(lblInd[0])[0]\n",
    "       # print(ind1)\n",
    "        lbl=classes[ind1]\n",
    "       # print(lbl)\n",
    "        predLabels.append(lbl)      \n",
    "\n",
    "    return predLabels\n",
    "dataset='webkb'\n",
    "count=0\n",
    "documents=[]\n",
    "labels=[]\n",
    "rawData=[]\n",
    "token_dict = dict()\n",
    "path = \"webkb-data.gtar\\\\webkb\"\n",
    "loadWebKbData(path=path,documents=documents,labels=labels)\n",
    "print(len(documents))\n",
    "categories=list(set(labels))\n",
    "totalDocs= len(documents)\n",
    "print (totalDocs)\n",
    "stopwords = stopwords.words('english')\n",
    "tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')\n",
    "vocabulary = set()\n",
    "term_docs=[]\n",
    "terms=[]\n",
    "totalDocs= len(documents)\n",
    "print (len(documents))\n",
    "print (\"vectorize\")\n",
    "tfidf = CountVectorizer(tokenizer=tokenize1)\n",
    "print (\"fit transform\")\n",
    "tfs = tfidf.fit_transform(documents)\n",
    "#sorted_scores=display_scores(tfidf, tfs)\n",
    "#groups=groupData(labels,categories) \n",
    "#n=len(sorted_scores)  \n",
    "arr=tfs.todense()\n",
    "n=arr.shape[1]\n",
    "allData=arr\n",
    "#\"Base\",\"Euclidean\",\"Manhattan\",\"Cosine\",\"Jaccard\",\"bhatta\",\"EPairwise\" ,          \"EPDSM\",\n",
    "measures=[\"PCC\",\"STB_SM_new\",\"esmtp\",\"EISC\",\"EDice\",\"ESP\",\"EBLAB_SM\"]\n",
    "global prob\n",
    "prob=[]\n",
    "labels=np.array(labels)\n",
    "\n",
    "k_splits=5\n",
    "for ks in range(0,k_splits):\n",
    "    prob.append([])\n",
    "\n",
    "labels=np.array(labels)\n",
    "var=0\n",
    "categories=list(set(set(labels)))\n",
    "categories.sort()\n",
    "print(categories)\n",
    "global time1\n",
    "global time2\n",
    "time1,time2=0,0\n",
    "split=0\n",
    "\n",
    "for met in measures:\n",
    "    print(\"###############\")\n",
    "    fname='table_'+dataset+'_MNB_'+met+'_BoW_5Exp.txt'\n",
    "    tables = open(fname, 'w')\n",
    "    tables.write(\"No. of features\\t\"+str(n)+\"\\n\")\n",
    "    print(\"###############\")\n",
    "    accuracy_avg=[]\n",
    "    macroP_avg=[]\n",
    "    microP_avg=[]\n",
    "    macroR_avg=[]\n",
    "    microR_avg=[]\n",
    "    macroFMeasure_avg=[]\n",
    "    microFMeasure_avg=[]\n",
    "    roc_avg=[]\n",
    "    split=0\n",
    "    if met==\"smtp\" or met==\"esmtp\" or met==\"DSM\":\n",
    "        var1=np.var(arr,axis=0).reshape(-1,1).ravel()\n",
    "        var=np.asarray(var1).ravel()\n",
    "    rand_state=[0,1,10,42,30]\n",
    "    time1=time.time()\n",
    "    for i in range(0,k_splits):\n",
    "        xTrain, xTest, yTrain, yTest = train_test_split(arr, labels, test_size = 0.3, random_state = rand_state[i],stratify=labels)\n",
    "        train_data=np.array(xTrain)\n",
    "        test_data=np.array(xTest)\n",
    "        train_labels=yTrain\n",
    "        test_labels=yTest\n",
    "        classify(metric=met) \n",
    "        split+=1\n",
    "\n",
    "    time2=time.time()\n",
    "    #Accuracy\n",
    "    PrintDetails(metric=met,time=str(timedelta(seconds=(time2-time1))),measure=\"Accuracy\",Arr=accuracy_avg)\n",
    "    #Precision\n",
    "    PrintDetails(metric=met,time=str(timedelta(seconds=(time2-time1))),measure=\"Macro Precision\",Arr=macroP_avg)\n",
    "    PrintDetails(metric=met,time=str(timedelta(seconds=(time2-time1))),measure=\"Micro Precision\",Arr=microP_avg)\n",
    "    #Recall\n",
    "    PrintDetails(metric=met,time=str(timedelta(seconds=(time2-time1))),measure=\"Macro Recall\",Arr=macroR_avg)\n",
    "    PrintDetails(metric=met,time=str(timedelta(seconds=(time2-time1))),measure=\"Micro Recall\",Arr=microR_avg)\n",
    "    #f measure\n",
    "    PrintDetails(metric=met,time=str(timedelta(seconds=(time2-time1))),measure=\"F Measure\",Arr=macroFMeasure_avg)\n",
    "\n",
    "    #f measure\n",
    "    PrintDetails(metric=met,time=str(timedelta(seconds=(time2-time1))),measure=\"Micro F Measure\",Arr=microFMeasure_avg)\n",
    "\n",
    "    #roc\n",
    "    PrintDetails(metric=met,time=str(timedelta(seconds=(time2-time1))),measure=\"ROC\",Arr=roc_avg)\n",
    "    tables.close()\n",
    "    print(\"###############\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9:11:19.053128\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "print(str(datetime.timedelta(seconds=33079.05312848091)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 3], dtype=int64),)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "totalValue=[0, np.nan, np.nan, 0]\n",
    "np.where(totalValue == np.nanmax(totalValue))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
